use pickle False use_h5 True channel_last True gpu_id 0
gpu id 0
mean [125.307, 122.95, 113.865] std [62.9932, 62.0887, 66.7048] l bounds [-1.99 -1.98 -1.71] h_bounds [2.06 2.13 2.12]
tensorflow 2.4.1
keras 2.4.0
number of seed images 10 (10,)
# samples for RE 3
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 192)       14592     
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 192)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 160)       30880     
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 160)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 32, 96)        15456     
_________________________________________________________________
activation_3 (Activation)    (None, 32, 32, 96)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 96)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 96)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 192)       460992    
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 192)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 16, 16, 192)       37056     
_________________________________________________________________
activation_5 (Activation)    (None, 16, 16, 192)       0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 16, 16, 192)       37056     
_________________________________________________________________
activation_6 (Activation)    (None, 16, 16, 192)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 192)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 8, 192)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    
_________________________________________________________________
activation_7 (Activation)    (None, 8, 8, 192)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     
_________________________________________________________________
activation_8 (Activation)    (None, 8, 8, 192)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 8, 8, 10)          1930      
_________________________________________________________________
activation_9 (Activation)    (None, 8, 8, 10)          0         
_________________________________________________________________
average_pooling2d_1 (Average (None, 1, 1, 10)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 10)                0         
_________________________________________________________________
activation_10 (Activation)   (None, 10)                0         
=================================================================
Total params: 966,986
Trainable params: 966,986
Non-trainable params: 0
_________________________________________________________________
image range -1.9892148 2.126796
0  is the l_in
0  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
0  is the l_in
2  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
0  is the l_in
4  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
0  is the l_in
8  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
0  is the l_in
10  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
0  is the l_in
12  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
0  is the l_in
16  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
0  is the l_in
18  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
0  is the l_in
20  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_9/BiasAdd:0", shape=(None, 8, 8, 10), dtype=float32)
0  is the l_in
23  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
sampling n imgs 10
0  is the l_in
0  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
1  is the l_in
23  is the l_out
Tensor("conv2d_1/BiasAdd:0", shape=(None, 32, 32, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
2  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
3  is the l_in
23  is the l_out
Tensor("conv2d_2/BiasAdd:0", shape=(None, 32, 32, 160), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
4  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
5  is the l_in
23  is the l_out
Tensor("conv2d_3/BiasAdd:0", shape=(None, 32, 32, 96), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
8  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
9  is the l_in
23  is the l_out
Tensor("conv2d_4/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
10  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
11  is the l_in
23  is the l_out
Tensor("conv2d_5/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
12  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
13  is the l_in
23  is the l_out
Tensor("conv2d_6/BiasAdd:0", shape=(None, 16, 16, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
16  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
17  is the l_in
23  is the l_out
Tensor("conv2d_7/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
0  is the l_in
18  is the l_out
Tensor("conv2d_1_input:0", shape=(None, 32, 32, 3), dtype=float32)
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
19  is the l_in
23  is the l_out
Tensor("conv2d_8/BiasAdd:0", shape=(None, 8, 8, 192), dtype=float32)
Tensor("flatten_1/Reshape:0", shape=(None, 10), dtype=float32)
n samples 5 n class 10
min max val across images k ('conv2d_3', 94) label 0 10 value 892.3545
min max val across images k ('conv2d_3', 54) label 0 10 value 779.7078
min max val across images k ('conv2d_2', 97) label 0 10 value 634.588
min max val across images k ('conv2d_3', 20) label 0 10 value 627.43994
min max val across images k ('conv2d_2', 74) label 0 10 value 538.09174
min max val across images k ('conv2d_2', 112) label 0 10 value 382.08102
min max val across images k ('conv2d_4', 110) label 0 10 value 304.39307
min max val across images k ('conv2d_1', 51) label 0 10 value 273.246
min max val across images k ('conv2d_4', 37) label 0 10 value 265.41864
min max val across images k ('conv2d_4', 167) label 4 10 value 255.5508
min max val across images k ('conv2d_1', 44) label 0 10 value 204.08658
min max val across images k ('conv2d_3', 63) label 0 10 value 588.251
min max val across images k ('conv2d_3', 40) label 0 10 value 585.3696
min max val across images k ('conv2d_3', 62) label 0 10 value 580.3948
min max val across images k ('conv2d_3', 64) label 0 10 value 505.90158
min max val across images k ('conv2d_3', 52) label 0 10 value 385.22552
min max val across images k ('conv2d_2', 104) label 0 10 value 340.87433
min max val across images k ('conv2d_2', 157) label 0 10 value 325.5224
min max val across images k ('conv2d_2', 132) label 0 10 value 294.4392
min max val across images k ('conv2d_4', 173) label 5 10 value 220.49791
min max val across images k ('conv2d_4', 69) label 5 10 value 215.60126
Compromised Neuron Candidates (Layer, Neuron, Target_Label) {'./models/nin_trojan_yellow_square_2_3.h5': [('conv2d_3', 94, 0), ('conv2d_3', 54, 0), ('conv2d_2', 97, 0), ('conv2d_3', 20, 0), ('conv2d_2', 74, 0), ('conv2d_2', 112, 0), ('conv2d_4', 110, 0), ('conv2d_1', 51, 0), ('conv2d_4', 37, 0), ('conv2d_4', 167, 4), ('conv2d_1', 44, 0), ('conv2d_3', 63, 0), ('conv2d_3', 40, 0), ('conv2d_3', 62, 0), ('conv2d_3', 64, 0), ('conv2d_3', 52, 0), ('conv2d_2', 104, 0), ('conv2d_2', 157, 0), ('conv2d_2', 132, 0), ('conv2d_4', 173, 5), ('conv2d_4', 69, 5)]}
RE mask conv2d_3 94 Label 0 RE acc 1.0
RE mask conv2d_3 54 Label 0 RE acc 1.0
RE mask conv2d_2 97 Label 0 RE acc 0.6666666666666666
RE mask conv2d_3 20 Label 0 RE acc 1.0
RE mask conv2d_2 74 Label 0 RE acc 1.0
RE mask conv2d_2 112 Label 0 RE acc 0.3333333333333333
RE mask conv2d_4 110 Label 0 RE acc 0.3333333333333333
RE mask conv2d_1 51 Label 0 RE acc 0.3333333333333333
RE mask conv2d_4 37 Label 0 RE acc 1.0
RE mask conv2d_4 167 Label 4 RE acc 0.0
RE mask conv2d_1 44 Label 0 RE acc 0.3333333333333333
RE mask conv2d_3 63 Label 0 RE acc 1.0
RE mask conv2d_3 40 Label 0 RE acc 0.6666666666666666
RE mask conv2d_3 62 Label 0 RE acc 1.0
RE mask conv2d_3 64 Label 0 RE acc 1.0
RE mask conv2d_3 52 Label 0 RE acc 0.6666666666666666
RE mask conv2d_2 104 Label 0 RE acc 1.0
RE mask conv2d_2 157 Label 0 RE acc 0.3333333333333333
RE mask conv2d_2 132 Label 0 RE acc 0.3333333333333333
RE mask conv2d_4 173 Label 5 RE acc 0.0
RE mask conv2d_4 69 Label 5 RE acc 0.0
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
-1.9892148 2.126796
./models/nin_trojan_yellow_square_2_3.h5 mask check 1.0
e 0 loss 7.48304 target loss -3750.245 other loss -203230.25 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -1190.6257 -0.7604091
e 10 loss 7.1491776 target loss -3699.3628 other loss -205739.25 tv loss 4008.9717
next layer loss target loss 0.0 other loss 9515.2295
result 1 [12.37  8.56  1.9 ] neuron -1160.9105 -0.76106715
e 20 loss 6.9463863 target loss -3661.6555 other loss -208555.95 tv loss 4038.3486
next layer loss target loss 0.0 other loss 9859.672
result 1 [12.32  8.7   1.9 ] neuron -1140.4077 -0.768316
e 30 loss 6.8390427 target loss -3631.3901 other loss -211074.44 tv loss 4068.6157
next layer loss target loss 0.0 other loss 10154.022
result 1 [12.3   8.78  1.91] neuron -1124.2998 -0.75525564
e 40 loss 6.772789 target loss -3609.1558 other loss -213240.11 tv loss 4105.9746
next layer loss target loss 0.0 other loss 10385.596
result 1 [12.37  8.86  1.93] neuron -1112.5052 -0.73485744
e 50 loss 6.724367 target loss -3593.8123 other loss -215146.7 tv loss 4144.2188
next layer loss target loss 0.0 other loss 10557.587
result 1 [12.43  8.92  1.96] neuron -1104.1833 -0.7202789
e 60 loss 6.6890907 target loss -3582.1416 other loss -216674.81 tv loss 4173.35
next layer loss target loss 0.0 other loss 10690.836
result 1 [12.48  8.98  2.  ] neuron -1097.7894 -0.70912874
e 70 loss 6.660925 target loss -3571.1436 other loss -217907.34 tv loss 4190.5713
next layer loss target loss 0.0 other loss 10806.446
result 1 [12.52  9.03  2.03] neuron -1092.0421 -0.6995319
e 80 loss 6.6345387 target loss -3558.7246 other loss -219154.12 tv loss 4201.5024
next layer loss target loss 0.0 other loss 10922.567
result 1 [12.59  9.09  2.06] neuron -1085.8724 -0.688928
e 90 loss 6.6087646 target loss -3545.8848 other loss -220448.8 tv loss 4210.5386
next layer loss target loss 0.0 other loss 11037.152
result 1 [12.67  9.16  2.09] neuron -1079.4167 -0.67792684
e 100 loss 6.5848083 target loss -3533.1462 other loss -221749.81 tv loss 4218.371
next layer loss target loss 0.0 other loss 11147.004
result 1 [12.76  9.21  2.13] neuron -1072.8042 -0.6664427
e 110 loss 6.5618973 target loss -3521.2048 other loss -222994.14 tv loss 4225.5225
next layer loss target loss 0.0 other loss 11249.898
result 1 [12.83  9.26  2.18] neuron -1066.6567 -0.657063
e 120 loss 6.541214 target loss -3510.337 other loss -224122.16 tv loss 4231.46
next layer loss target loss 0.0 other loss 11346.41
result 1 [12.88  9.3   2.22] neuron -1061.4019 -0.6498529
e 130 loss 6.5236473 target loss -3501.1724 other loss -225037.55 tv loss 4235.3325
next layer loss target loss 0.0 other loss 11426.211
result 1 [12.92  9.3   2.25] neuron -1057.007 -0.6432383
e 140 loss 6.5057793 target loss -3491.391 other loss -226007.75 tv loss 4238.4355
next layer loss target loss 0.0 other loss 11509.372
result 1 [12.98  9.34  2.29] neuron -1052.3629 -0.63675696
e 150 loss 6.490242 target loss -3481.5708 other loss -226946.53 tv loss 4239.404
next layer loss target loss 0.0 other loss 11593.15
result 1 [13.04  9.37  2.33] neuron -1047.8076 -0.63067365
e 160 loss 6.477846 target loss -3475.402 other loss -227569.1 tv loss 4241.997
next layer loss target loss 0.0 other loss 11650.369
result 1 [13.07  9.37  2.36] neuron -1044.9318 -0.62613887
e 170 loss 6.4675465 target loss -3472.0984 other loss -227949.5 tv loss 4247.2256
next layer loss target loss 0.0 other loss 11684.793
result 1 [13.09  9.36  2.39] neuron -1043.3972 -0.62277937
e 180 loss 6.4592094 target loss -3468.9348 other loss -228279.58 tv loss 4250.3003
next layer loss target loss 0.0 other loss 11715.627
result 1 [13.11  9.34  2.41] neuron -1041.9797 -0.61976767
e 190 loss 6.4522457 target loss -3465.9727 other loss -228589.78 tv loss 4252.106
next layer loss target loss 0.0 other loss 11742.813
result 1 [13.12  9.34  2.43] neuron -1040.5837 -0.6170031
e 200 loss 6.445965 target loss -3462.5415 other loss -228909.45 tv loss 4252.6924
next layer loss target loss 0.0 other loss 11770.609
result 1 [13.14  9.35  2.44] neuron -1038.9473 -0.6138656
e 210 loss 6.440151 target loss -3459.185 other loss -229219.72 tv loss 4252.5728
next layer loss target loss 0.0 other loss 11798.719
result 1 [13.15  9.36  2.47] neuron -1037.4314 -0.6114683
e 220 loss 6.4351406 target loss -3456.7673 other loss -229430.25 tv loss 4253.088
next layer loss target loss 0.0 other loss 11819.4
result 1 [13.15  9.36  2.48] neuron -1036.3284 -0.60952955
e 230 loss 6.430725 target loss -3455.739 other loss -229538.58 tv loss 4254.4277
next layer loss target loss 0.0 other loss 11828.927
result 1 [13.16  9.36  2.49] neuron -1035.854 -0.6082525
e 240 loss 6.4268246 target loss -3454.5283 other loss -229652.5 tv loss 4255.251
next layer loss target loss 0.0 other loss 11838.518
result 1 [13.17  9.36  2.5 ] neuron -1035.2872 -0.60701674
e 250 loss 6.4232483 target loss -3453.3147 other loss -229760.75 tv loss 4255.606
next layer loss target loss 0.0 other loss 11848.705
result 1 [13.17  9.37  2.51] neuron -1034.811 -0.6062838
e 260 loss 6.419964 target loss -3452.0647 other loss -229851.19 tv loss 4254.967
next layer loss target loss 0.0 other loss 11857.902
result 1 [13.17  9.37  2.52] neuron -1034.2744 -0.60541904
e 270 loss 6.4169006 target loss -3451.1995 other loss -229916.1 tv loss 4254.991
next layer loss target loss 0.0 other loss 11864.006
result 1 [13.17  9.37  2.53] neuron -1033.8699 -0.604727
e 280 loss 6.414068 target loss -3450.5242 other loss -229978.44 tv loss 4255.4355
next layer loss target loss 0.0 other loss 11868.729
result 1 [13.17  9.38  2.54] neuron -1033.6001 -0.6042315
e 290 loss 6.411438 target loss -3449.9404 other loss -230014.11 tv loss 4255.375
next layer loss target loss 0.0 other loss 11872.179
result 1 [13.17  9.39  2.54] neuron -1033.3916 -0.6039414
e 300 loss 6.4089775 target loss -3449.3374 other loss -230049.05 tv loss 4254.8525
next layer loss target loss 0.0 other loss 11875.711
result 1 [13.18  9.39  2.55] neuron -1033.1885 -0.6037711
e 310 loss 6.406683 target loss -3448.8596 other loss -230078.81 tv loss 4254.2373
next layer loss target loss 0.0 other loss 11878.244
result 1 [13.18  9.4   2.56] neuron -1033.0287 -0.6036959
e 320 loss 6.404476 target loss -3448.295 other loss -230100.78 tv loss 4253.8193
next layer loss target loss 0.0 other loss 11881.4
result 1 [13.17  9.41  2.56] neuron -1032.8075 -0.6035353
e 330 loss 6.4023952 target loss -3447.7117 other loss -230154.53 tv loss 4254.076
next layer loss target loss 0.0 other loss 11885.345
result 1 [13.17  9.42  2.57] neuron -1032.584 -0.6032974
e 340 loss 6.400442 target loss -3447.285 other loss -230194.88 tv loss 4254.5557
next layer loss target loss 0.0 other loss 11887.967
result 1 [13.17  9.43  2.57] neuron -1032.4353 -0.60309994
e 350 loss 6.398609 target loss -3446.7266 other loss -230227.14 tv loss 4254.0923
next layer loss target loss 0.0 other loss 11891.45
result 1 [13.17  9.43  2.57] neuron -1032.2485 -0.6030142
e 360 loss 6.3968716 target loss -3446.4192 other loss -230253.75 tv loss 4254.066
next layer loss target loss 0.0 other loss 11892.705
result 1 [13.17  9.44  2.58] neuron -1032.1531 -0.60299104
e 370 loss 6.3952007 target loss -3445.68 other loss -230315.31 tv loss 4253.5024
next layer loss target loss 0.0 other loss 11897.509
result 1 [13.17  9.45  2.58] neuron -1031.9064 -0.6030032
e 380 loss 6.39361 target loss -3445.0403 other loss -230359.0 tv loss 4253.1465
next layer loss target loss 0.0 other loss 11901.388
result 1 [13.17  9.46  2.58] neuron -1031.6476 -0.6028216
e 390 loss 6.392128 target loss -3444.7073 other loss -230388.7 tv loss 4253.3633
next layer loss target loss 0.0 other loss 11903.839
result 1 [13.17  9.47  2.59] neuron -1031.5312 -0.60271263
e 400 loss 6.3907433 target loss -3444.3225 other loss -230408.83 tv loss 4253.073
next layer loss target loss 0.0 other loss 11906.405
result 1 [13.17  9.47  2.59] neuron -1031.3984 -0.60264236
e 410 loss 6.3894253 target loss -3444.1719 other loss -230422.1 tv loss 4253.2573
next layer loss target loss 0.0 other loss 11906.968
result 1 [13.17  9.47  2.59] neuron -1031.3555 -0.6026609
e 420 loss 6.3881645 target loss -3443.8838 other loss -230439.62 tv loss 4252.841
next layer loss target loss 0.0 other loss 11908.435
result 1 [13.17  9.48  2.59] neuron -1031.2683 -0.60270464
e 430 loss 6.386978 target loss -3443.7 other loss -230457.84 tv loss 4252.7427
next layer loss target loss 0.0 other loss 11909.1875
result 1 [13.16  9.48  2.59] neuron -1031.2031 -0.60275704
e 440 loss 6.3858547 target loss -3443.4434 other loss -230474.94 tv loss 4252.291
next layer loss target loss 0.0 other loss 11910.531
result 1 [13.16  9.49  2.6 ] neuron -1031.1108 -0.6027645
e 450 loss 6.384794 target loss -3443.15 other loss -230494.22 tv loss 4252.0273
next layer loss target loss 0.0 other loss 11912.301
result 1 [13.16  9.49  2.6 ] neuron -1031.0007 -0.6027066
e 460 loss 6.383789 target loss -3442.9465 other loss -230502.66 tv loss 4251.779
next layer loss target loss 0.0 other loss 11913.496
result 1 [13.16  9.49  2.6 ] neuron -1030.9299 -0.60272145
e 470 loss 6.382845 target loss -3442.6992 other loss -230522.39 tv loss 4251.6445
next layer loss target loss 0.0 other loss 11915.144
result 1 [13.16  9.5   2.6 ] neuron -1030.8219 -0.6026336
e 480 loss 6.3819275 target loss -3442.4148 other loss -230540.4 tv loss 4251.653
next layer loss target loss 0.0 other loss 11917.555
result 1 [13.16  9.5   2.6 ] neuron -1030.7113 -0.6025183
e 490 loss 6.3810787 target loss -3442.2075 other loss -230558.5 tv loss 4251.7573
next layer loss target loss 0.0 other loss 11919.602
result 1 [13.16  9.5   2.6 ] neuron -1030.6047 -0.60238075
e 500 loss 6.3802605 target loss -3442.0413 other loss -230575.42 tv loss 4251.9585
next layer loss target loss 0.0 other loss 11920.989
result 1 [13.15  9.51  2.6 ] neuron -1030.524 -0.6022996
e 510 loss 6.3794746 target loss -3441.798 other loss -230597.0 tv loss 4251.768
next layer loss target loss 0.0 other loss 11922.825
result 1 [13.15  9.51  2.6 ] neuron -1030.4056 -0.6021846
e 520 loss 6.378704 target loss -3441.2012 other loss -230645.33 tv loss 4251.3516
next layer loss target loss 0.0 other loss 11927.662
result 1 [13.15  9.51  2.6 ] neuron -1030.0767 -0.6017808
e 530 loss 6.377962 target loss -3440.9958 other loss -230662.6 tv loss 4251.4907
next layer loss target loss 0.0 other loss 11929.859
result 1 [13.15  9.51  2.6 ] neuron -1029.9666 -0.60154384
e 540 loss 6.3772717 target loss -3440.8105 other loss -230683.36 tv loss 4251.5576
next layer loss target loss 0.0 other loss 11931.635
result 1 [13.15  9.52  2.6 ] neuron -1029.8667 -0.6014088
e 550 loss 6.376585 target loss -3440.588 other loss -230704.17 tv loss 4251.4023
next layer loss target loss 0.0 other loss 11933.505
result 1 [13.15  9.52  2.6 ] neuron -1029.7324 -0.6012693
e 560 loss 6.375952 target loss -3440.4316 other loss -230714.88 tv loss 4251.3516
next layer loss target loss 0.0 other loss 11934.613
result 1 [13.15  9.52  2.6 ] neuron -1029.6439 -0.60115135
e 570 loss 6.375328 target loss -3440.288 other loss -230728.52 tv loss 4251.3496
next layer loss target loss 0.0 other loss 11935.6455
result 1 [13.14  9.53  2.6 ] neuron -1029.5642 -0.60104203
e 580 loss 6.3747387 target loss -3440.1523 other loss -230743.16 tv loss 4251.455
next layer loss target loss 0.0 other loss 11937.082
result 1 [13.14  9.53  2.6 ] neuron -1029.4861 -0.6009593
e 590 loss 6.3741684 target loss -3439.9832 other loss -230757.31 tv loss 4251.3735
next layer loss target loss 0.0 other loss 11938.616
result 1 [13.14  9.53  2.6 ] neuron -1029.3779 -0.60077417
e 600 loss 6.373623 target loss -3439.857 other loss -230759.81 tv loss 4251.3735
next layer loss target loss 0.0 other loss 11939.682
result 1 [13.14  9.53  2.6 ] neuron -1029.2977 -0.6005947
e 610 loss 6.373108 target loss -3439.6802 other loss -230773.02 tv loss 4251.2153
next layer loss target loss 0.0 other loss 11941.2295
result 1 [13.14  9.53  2.6 ] neuron -1029.188 -0.60039496
e 620 loss 6.372616 target loss -3439.6409 other loss -230776.47 tv loss 4251.2095
next layer loss target loss 0.0 other loss 11942.045
result 1 [13.14  9.53  2.6 ] neuron -1029.1372 -0.60031915
e 630 loss 6.372139 target loss -3439.4731 other loss -230790.12 tv loss 4251.1685
next layer loss target loss 0.0 other loss 11943.715
result 1 [13.14  9.54  2.6 ] neuron -1029.0343 -0.6001305
e 640 loss 6.371681 target loss -3439.3389 other loss -230799.69 tv loss 4251.1714
next layer loss target loss 0.0 other loss 11945.024
result 1 [13.14  9.54  2.59] neuron -1028.9321 -0.5998912
e 650 loss 6.37125 target loss -3439.208 other loss -230811.4 tv loss 4251.106
next layer loss target loss 0.0 other loss 11946.655
result 1 [13.13  9.54  2.59] neuron -1028.8486 -0.5997351
e 660 loss 6.370819 target loss -3439.0142 other loss -230818.3 tv loss 4250.9355
next layer loss target loss 0.0 other loss 11948.327
result 1 [13.13  9.54  2.59] neuron -1028.7263 -0.59948635
e 670 loss 6.370428 target loss -3438.891 other loss -230824.52 tv loss 4250.863
next layer loss target loss 0.0 other loss 11949.808
result 1 [13.13  9.54  2.59] neuron -1028.6459 -0.59931946
e 680 loss 6.3700314 target loss -3438.8416 other loss -230837.81 tv loss 4251.071
next layer loss target loss 0.0 other loss 11951.054
result 1 [13.13  9.54  2.59] neuron -1028.5857 -0.5991689
e 690 loss 6.3696556 target loss -3438.711 other loss -230851.77 tv loss 4251.086
next layer loss target loss 0.0 other loss 11952.796
result 1 [13.13  9.54  2.59] neuron -1028.4832 -0.59895825
e 700 loss 6.3692894 target loss -3438.5996 other loss -230855.61 tv loss 4251.167
next layer loss target loss 0.0 other loss 11954.5205
result 1 [13.13  9.54  2.59] neuron -1028.4003 -0.5987238
e 710 loss 6.3689423 target loss -3438.4912 other loss -230868.1 tv loss 4251.3184
next layer loss target loss 0.0 other loss 11956.109
result 1 [13.13  9.54  2.59] neuron -1028.3198 -0.5985433
e 720 loss 6.3686066 target loss -3438.3584 other loss -230877.61 tv loss 4251.413
next layer loss target loss 0.0 other loss 11957.41
result 1 [13.13  9.54  2.59] neuron -1028.2167 -0.5982686
e 730 loss 6.368294 target loss -3438.2913 other loss -230882.14 tv loss 4251.425
next layer loss target loss 0.0 other loss 11958.459
result 1 [13.12  9.54  2.59] neuron -1028.1613 -0.5981212
e 740 loss 6.3679924 target loss -3438.219 other loss -230884.53 tv loss 4251.242
next layer loss target loss 0.0 other loss 11959.326
result 1 [13.12  9.54  2.58] neuron -1028.0989 -0.5979952
e 750 loss 6.367674 target loss -3438.1528 other loss -230888.73 tv loss 4251.1074
next layer loss target loss 0.0 other loss 11960.369
result 1 [13.12  9.54  2.58] neuron -1028.0289 -0.5978546
e 760 loss 6.3673954 target loss -3438.224 other loss -230885.64 tv loss 4251.095
next layer loss target loss 0.0 other loss 11960.605
result 1 [13.12  9.54  2.58] neuron -1028.0474 -0.5978285
e 770 loss 6.3671303 target loss -3438.047 other loss -230894.0 tv loss 4250.858
next layer loss target loss 0.0 other loss 11962.058
result 1 [13.12  9.54  2.58] neuron -1027.9243 -0.59758544
e 780 loss 6.366867 target loss -3438.02 other loss -230898.39 tv loss 4250.8623
next layer loss target loss 0.0 other loss 11963.003
result 1 [13.12  9.54  2.58] neuron -1027.8756 -0.59744906
e 790 loss 6.366623 target loss -3437.9104 other loss -230903.84 tv loss 4250.9077
next layer loss target loss 0.0 other loss 11964.465
result 1 [13.12  9.54  2.58] neuron -1027.7999 -0.5972537
e 800 loss 6.366394 target loss -3437.8591 other loss -230911.9 tv loss 4250.9395
next layer loss target loss 0.0 other loss 11965.649
result 1 [13.12  9.54  2.58] neuron -1027.7429 -0.59712577
e 810 loss 6.3661785 target loss -3437.7578 other loss -230917.73 tv loss 4250.893
next layer loss target loss 0.0 other loss 11966.658
result 1 [13.12  9.54  2.58] neuron -1027.6707 -0.5969576
e 820 loss 6.365959 target loss -3437.7048 other loss -230919.0 tv loss 4250.7896
next layer loss target loss 0.0 other loss 11967.326
result 1 [13.11  9.54  2.58] neuron -1027.6259 -0.596855
e 830 loss 6.365755 target loss -3437.624 other loss -230927.33 tv loss 4250.678
next layer loss target loss 0.0 other loss 11968.326
result 1 [13.11  9.55  2.58] neuron -1027.5576 -0.5967333
e 840 loss 6.3655567 target loss -3437.6062 other loss -230926.6 tv loss 4250.7344
next layer loss target loss 0.0 other loss 11968.86
result 1 [13.11  9.55  2.58] neuron -1027.5388 -0.59665585
e 850 loss 6.36537 target loss -3437.595 other loss -230925.77 tv loss 4250.718
next layer loss target loss 0.0 other loss 11969.182
result 1 [13.11  9.55  2.57] neuron -1027.509 -0.5965348
e 860 loss 6.365204 target loss -3437.525 other loss -230932.14 tv loss 4250.755
next layer loss target loss 0.0 other loss 11970.304
result 1 [13.11  9.55  2.57] neuron -1027.4559 -0.59639776
e 870 loss 6.3650208 target loss -3437.439 other loss -230938.36 tv loss 4250.7417
next layer loss target loss 0.0 other loss 11971.226
result 1 [13.11  9.55  2.57] neuron -1027.3901 -0.5962414
e 880 loss 6.364849 target loss -3437.424 other loss -230939.12 tv loss 4250.797
next layer loss target loss 0.0 other loss 11971.822
result 1 [13.11  9.55  2.57] neuron -1027.3645 -0.5961275
e 890 loss 6.364689 target loss -3437.3376 other loss -230946.12 tv loss 4250.766
next layer loss target loss 0.0 other loss 11972.778
result 1 [13.11  9.55  2.57] neuron -1027.3042 -0.59598213
e 900 loss 6.3645344 target loss -3437.274 other loss -230955.03 tv loss 4250.761
next layer loss target loss 0.0 other loss 11973.954
result 1 [13.11  9.55  2.57] neuron -1027.2501 -0.5958594
e 910 loss 6.364374 target loss -3437.221 other loss -230962.16 tv loss 4250.8613
next layer loss target loss 0.0 other loss 11975.109
result 1 [13.11  9.55  2.57] neuron -1027.2002 -0.5957357
e 920 loss 6.3642235 target loss -3437.0117 other loss -230988.34 tv loss 4250.9556
next layer loss target loss 0.0 other loss 11977.782
result 1 [13.11  9.55  2.57] neuron -1027.0696 -0.5955062
e 930 loss 6.3640785 target loss -3436.838 other loss -231004.55 tv loss 4251.0303
next layer loss target loss 0.0 other loss 11980.005
result 1 [13.11  9.54  2.57] neuron -1026.9609 -0.5952242
e 940 loss 6.363941 target loss -3436.71 other loss -231022.69 tv loss 4251.329
next layer loss target loss 0.0 other loss 11982.0625
result 1 [13.1   9.54  2.57] neuron -1026.864 -0.5949677
e 950 loss 6.363802 target loss -3436.5728 other loss -231033.89 tv loss 4251.356
next layer loss target loss 0.0 other loss 11983.551
result 1 [13.1   9.54  2.57] neuron -1026.7687 -0.59472024
e 960 loss 6.363678 target loss -3436.454 other loss -231044.4 tv loss 4251.492
next layer loss target loss 0.0 other loss 11985.051
result 1 [13.1   9.54  2.57] neuron -1026.6903 -0.5945166
e 970 loss 6.3635597 target loss -3436.389 other loss -231052.67 tv loss 4251.58
next layer loss target loss 0.0 other loss 11986.291
result 1 [13.1   9.54  2.57] neuron -1026.636 -0.59436923
e 980 loss 6.3634377 target loss -3436.3215 other loss -231056.42 tv loss 4251.5825
next layer loss target loss 0.0 other loss 11987.281
result 1 [13.1   9.54  2.56] neuron -1026.583 -0.5942152
e 990 loss 6.3633175 target loss -3436.2175 other loss -231064.92 tv loss 4251.545
next layer loss target loss 0.0 other loss 11988.392
result 1 [13.1   9.54  2.56] neuron -1026.5088 -0.59403306
RE filter conv2d_3 94 RE acc 0.3333333333333333
e 0 loss 1.3502579 target loss -3136.9731 other loss -203843.52 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -969.7303 -0.55154055
e 10 loss 0.88534164 target loss -3066.287 other loss -205183.47 tv loss 3984.5005
next layer loss target loss 0.0 other loss 9504.465
result 1 [12.34  8.43  1.84] neuron -936.329 -0.5405411
e 20 loss 0.6704197 target loss -3022.7556 other loss -206609.6 tv loss 3988.2905
next layer loss target loss 0.0 other loss 9827.981
result 1 [12.23  8.42  1.78] neuron -916.3463 -0.48749012
e 30 loss 0.5745144 target loss -2992.9756 other loss -207765.08 tv loss 4001.2334
next layer loss target loss 0.0 other loss 10059.285
result 1 [12.07  8.39  1.74] neuron -904.07715 -0.4604543
e 40 loss 0.5354099 target loss -2979.9453 other loss -208758.19 tv loss 4024.5068
next layer loss target loss 0.0 other loss 10208.792
result 1 [12.02  8.35  1.71] neuron -899.1775 -0.45127985
e 50 loss 0.5132942 target loss -2975.4604 other loss -209416.19 tv loss 4048.0283
next layer loss target loss 0.0 other loss 10285.634
result 1 [12.01  8.34  1.71] neuron -897.6354 -0.4496435
e 60 loss 0.49846458 target loss -2973.5474 other loss -209852.12 tv loss 4066.2537
next layer loss target loss 0.0 other loss 10321.453
result 1 [12.03  8.35  1.72] neuron -896.9675 -0.44958854
e 70 loss 0.48830414 target loss -2971.7861 other loss -210225.58 tv loss 4079.5444
next layer loss target loss 0.0 other loss 10346.551
result 1 [12.04  8.38  1.74] neuron -896.3875 -0.44773602
e 80 loss 0.48064232 target loss -2969.9775 other loss -210469.39 tv loss 4087.4058
next layer loss target loss 0.0 other loss 10364.379
result 1 [12.03  8.41  1.75] neuron -895.6911 -0.4454829
e 90 loss 0.47390938 target loss -2967.9114 other loss -210574.19 tv loss 4090.8994
next layer loss target loss 0.0 other loss 10375.646
result 1 [12.02  8.43  1.75] neuron -894.87976 -0.44373694
e 100 loss 0.46781158 target loss -2966.0361 other loss -210629.02 tv loss 4092.2134
next layer loss target loss 0.0 other loss 10383.836
result 1 [12.01  8.44  1.75] neuron -894.22284 -0.44218907
e 110 loss 0.46224213 target loss -2964.8186 other loss -210660.19 tv loss 4092.0059
next layer loss target loss 0.0 other loss 10388.278
result 1 [12.    8.44  1.76] neuron -893.8743 -0.44107366
e 120 loss 0.45706177 target loss -2963.792 other loss -210702.06 tv loss 4091.3262
next layer loss target loss 0.0 other loss 10391.851
result 1 [12.    8.45  1.76] neuron -893.6062 -0.43975872
e 130 loss 0.4522953 target loss -2962.958 other loss -210745.95 tv loss 4090.8718
next layer loss target loss 0.0 other loss 10394.04
result 1 [12.    8.45  1.77] neuron -893.4034 -0.43843293
e 140 loss 0.44788742 target loss -2962.1465 other loss -210772.33 tv loss 4090.5566
next layer loss target loss 0.0 other loss 10394.719
result 1 [12.    8.46  1.78] neuron -893.20416 -0.4373983
e 150 loss 0.4438095 target loss -2961.2632 other loss -210811.45 tv loss 4090.477
next layer loss target loss 0.0 other loss 10396.95
result 1 [12.    8.47  1.79] neuron -892.9596 -0.4362673
e 160 loss 0.44005585 target loss -2960.476 other loss -210849.94 tv loss 4090.4624
next layer loss target loss 0.0 other loss 10398.946
result 1 [12.    8.48  1.79] neuron -892.7477 -0.43524957
e 170 loss 0.4365673 target loss -2959.637 other loss -210904.08 tv loss 4090.7114
next layer loss target loss 0.0 other loss 10402.553
result 1 [11.99  8.48  1.8 ] neuron -892.51575 -0.43410292
e 180 loss 0.43335533 target loss -2958.8179 other loss -210960.31 tv loss 4090.843
next layer loss target loss 0.0 other loss 10406.295
result 1 [11.99  8.49  1.81] neuron -892.27954 -0.43295366
e 190 loss 0.43037605 target loss -2957.8982 other loss -211014.77 tv loss 4091.106
next layer loss target loss 0.0 other loss 10409.98
result 1 [11.99  8.5   1.81] neuron -891.98676 -0.4316746
e 200 loss 0.42760658 target loss -2956.9983 other loss -211088.28 tv loss 4091.607
next layer loss target loss 0.0 other loss 10415.386
result 1 [11.99  8.51  1.82] neuron -891.7085 -0.4302032
e 210 loss 0.42502213 target loss -2956.0889 other loss -211161.94 tv loss 4091.9543
next layer loss target loss 0.0 other loss 10421.126
result 1 [11.98  8.51  1.82] neuron -891.41656 -0.42882657
e 220 loss 0.4226017 target loss -2955.0305 other loss -211249.0 tv loss 4092.5654
next layer loss target loss 0.0 other loss 10428.77
result 1 [11.98  8.52  1.83] neuron -891.06287 -0.42722186
e 230 loss 0.4203682 target loss -2953.998 other loss -211330.72 tv loss 4093.3481
next layer loss target loss 0.0 other loss 10435.75
result 1 [11.98  8.53  1.84] neuron -890.692 -0.4257106
e 240 loss 0.41832352 target loss -2953.2344 other loss -211391.06 tv loss 4094.0635
next layer loss target loss 0.0 other loss 10440.633
result 1 [11.97  8.53  1.84] neuron -890.4514 -0.42469442
e 250 loss 0.41646194 target loss -2952.71 other loss -211422.1 tv loss 4094.3083
next layer loss target loss 0.0 other loss 10442.962
result 1 [11.97  8.54  1.84] neuron -890.31226 -0.42411146
e 260 loss 0.41474152 target loss -2952.1167 other loss -211447.28 tv loss 4094.63
next layer loss target loss 0.0 other loss 10444.564
result 1 [11.97  8.54  1.85] neuron -890.12976 -0.42337662
e 270 loss 0.4131527 target loss -2951.557 other loss -211463.88 tv loss 4094.667
next layer loss target loss 0.0 other loss 10446.137
result 1 [11.96  8.54  1.85] neuron -889.9558 -0.4227814
e 280 loss 0.41166687 target loss -2950.9941 other loss -211479.23 tv loss 4094.8801
next layer loss target loss 0.0 other loss 10448.012
result 1 [11.96  8.55  1.85] neuron -889.77686 -0.42235112
e 290 loss 0.41028976 target loss -2950.4634 other loss -211512.25 tv loss 4095.516
next layer loss target loss 0.0 other loss 10451.096
result 1 [11.95  8.55  1.85] neuron -889.5941 -0.42182037
e 300 loss 0.40901375 target loss -2949.91 other loss -211556.1 tv loss 4096.36
next layer loss target loss 0.0 other loss 10454.493
result 1 [11.95  8.55  1.86] neuron -889.38745 -0.42109448
e 310 loss 0.40781975 target loss -2949.516 other loss -211594.86 tv loss 4096.9585
next layer loss target loss 0.0 other loss 10457.171
result 1 [11.94  8.56  1.86] neuron -889.25977 -0.4205165
e 320 loss 0.40670776 target loss -2949.1985 other loss -211621.52 tv loss 4097.354
next layer loss target loss 0.0 other loss 10458.979
result 1 [11.94  8.56  1.86] neuron -889.17505 -0.42018676
e 330 loss 0.40565872 target loss -2948.759 other loss -211653.06 tv loss 4097.6104
next layer loss target loss 0.0 other loss 10461.295
result 1 [11.94  8.56  1.87] neuron -889.0276 -0.4195783
e 340 loss 0.40466118 target loss -2948.3198 other loss -211692.3 tv loss 4097.8535
next layer loss target loss 0.0 other loss 10464.431
result 1 [11.94  8.56  1.87] neuron -888.87646 -0.4188649
e 350 loss 0.40372276 target loss -2947.9702 other loss -211723.11 tv loss 4098.136
next layer loss target loss 0.0 other loss 10466.893
result 1 [11.94  8.56  1.87] neuron -888.7634 -0.41839695
e 360 loss 0.40283012 target loss -2947.412 other loss -211772.23 tv loss 4099.0127
next layer loss target loss 0.0 other loss 10471.184
result 1 [11.93  8.57  1.88] neuron -888.5247 -0.41768083
e 370 loss 0.40198708 target loss -2947.04 other loss -211824.97 tv loss 4100.1577
next layer loss target loss 0.0 other loss 10475.172
result 1 [11.93  8.57  1.88] neuron -888.3638 -0.4171511
e 380 loss 0.4011917 target loss -2946.6738 other loss -211868.69 tv loss 4100.955
next layer loss target loss 0.0 other loss 10478.498
result 1 [11.93  8.57  1.88] neuron -888.2015 -0.4166305
e 390 loss 0.4004326 target loss -2946.3135 other loss -211891.88 tv loss 4101.3813
next layer loss target loss 0.0 other loss 10480.59
result 1 [11.93  8.57  1.88] neuron -888.0652 -0.41628677
e 400 loss 0.3997097 target loss -2946.0205 other loss -211904.92 tv loss 4101.4014
next layer loss target loss 0.0 other loss 10482.011
result 1 [11.93  8.57  1.88] neuron -887.96216 -0.41602293
e 410 loss 0.39902306 target loss -2945.6997 other loss -211932.72 tv loss 4101.547
next layer loss target loss 0.0 other loss 10483.994
result 1 [11.93  8.58  1.88] neuron -887.84424 -0.41542786
e 420 loss 0.39837646 target loss -2945.5273 other loss -211960.1 tv loss 4101.8945
next layer loss target loss 0.0 other loss 10485.684
result 1 [11.93  8.58  1.89] neuron -887.78125 -0.41505006
e 430 loss 0.39775658 target loss -2945.3987 other loss -211976.81 tv loss 4102.2383
next layer loss target loss 0.0 other loss 10486.799
result 1 [11.93  8.58  1.89] neuron -887.7395 -0.4149893
e 440 loss 0.3971634 target loss -2945.18 other loss -211995.77 tv loss 4102.594
next layer loss target loss 0.0 other loss 10488.381
result 1 [11.93  8.58  1.89] neuron -887.6422 -0.41479227
e 450 loss 0.39661217 target loss -2944.9333 other loss -212017.14 tv loss 4102.95
next layer loss target loss 0.0 other loss 10490.176
result 1 [11.92  8.58  1.89] neuron -887.52795 -0.4145188
e 460 loss 0.39606857 target loss -2944.7012 other loss -212039.03 tv loss 4103.1733
next layer loss target loss 0.0 other loss 10492.415
result 1 [11.92  8.58  1.89] neuron -887.4339 -0.414291
e 470 loss 0.3955536 target loss -2944.4558 other loss -212059.88 tv loss 4103.371
next layer loss target loss 0.0 other loss 10494.405
result 1 [11.92  8.58  1.89] neuron -887.3336 -0.4139954
e 480 loss 0.39504814 target loss -2944.175 other loss -212077.52 tv loss 4103.644
next layer loss target loss 0.0 other loss 10496.037
result 1 [11.92  8.58  1.89] neuron -887.2081 -0.4137172
e 490 loss 0.3945713 target loss -2943.897 other loss -212095.16 tv loss 4104.013
next layer loss target loss 0.0 other loss 10497.576
result 1 [11.92  8.59  1.89] neuron -887.08044 -0.41345936
e 500 loss 0.39411354 target loss -2943.7412 other loss -212109.94 tv loss 4104.376
next layer loss target loss 0.0 other loss 10498.474
result 1 [11.92  8.59  1.89] neuron -887.0145 -0.41331592
e 510 loss 0.3936596 target loss -2943.591 other loss -212125.38 tv loss 4104.566
next layer loss target loss 0.0 other loss 10499.51
result 1 [11.92  8.59  1.9 ] neuron -886.9596 -0.41311377
e 520 loss 0.39321136 target loss -2943.3323 other loss -212140.98 tv loss 4104.711
next layer loss target loss 0.0 other loss 10500.894
result 1 [11.92  8.59  1.9 ] neuron -886.8457 -0.412817
e 530 loss 0.39280128 target loss -2943.0813 other loss -212155.67 tv loss 4104.8154
next layer loss target loss 0.0 other loss 10502.581
result 1 [11.92  8.59  1.9 ] neuron -886.744 -0.41260946
e 540 loss 0.39239502 target loss -2942.984 other loss -212173.31 tv loss 4105.1035
next layer loss target loss 0.0 other loss 10503.621
result 1 [11.92  8.59  1.9 ] neuron -886.70154 -0.41243017
e 550 loss 0.39201164 target loss -2942.881 other loss -212184.45 tv loss 4105.3125
next layer loss target loss 0.0 other loss 10504.41
result 1 [11.92  8.59  1.9 ] neuron -886.6501 -0.41234154
e 560 loss 0.3916359 target loss -2942.788 other loss -212195.86 tv loss 4105.554
next layer loss target loss 0.0 other loss 10505.294
result 1 [11.92  8.59  1.9 ] neuron -886.6134 -0.41229543
e 570 loss 0.3912773 target loss -2942.7036 other loss -212207.61 tv loss 4105.684
next layer loss target loss 0.0 other loss 10506.033
result 1 [11.92  8.59  1.9 ] neuron -886.5786 -0.41218382
e 580 loss 0.39093018 target loss -2942.5151 other loss -212219.12 tv loss 4105.7856
next layer loss target loss 0.0 other loss 10507.3
result 1 [11.91  8.59  1.9 ] neuron -886.49274 -0.4120313
e 590 loss 0.39059067 target loss -2942.2769 other loss -212233.72 tv loss 4105.962
next layer loss target loss 0.0 other loss 10508.964
result 1 [11.91  8.59  1.9 ] neuron -886.39215 -0.41183102
e 600 loss 0.39027405 target loss -2942.0889 other loss -212244.55 tv loss 4106.171
next layer loss target loss 0.0 other loss 10510.14
result 1 [11.91  8.59  1.9 ] neuron -886.3128 -0.41173154
e 610 loss 0.38993263 target loss -2941.9075 other loss -212247.78 tv loss 4106.4814
next layer loss target loss 0.0 other loss 10510.832
result 1 [11.91  8.6   1.9 ] neuron -886.22925 -0.41173807
e 620 loss 0.38961983 target loss -2941.8105 other loss -212250.22 tv loss 4106.651
next layer loss target loss 0.0 other loss 10510.92
result 1 [11.91  8.6   1.9 ] neuron -886.18396 -0.4117453
e 630 loss 0.38931084 target loss -2941.702 other loss -212259.97 tv loss 4106.7124
next layer loss target loss 0.0 other loss 10511.7705
result 1 [11.91  8.6   1.9 ] neuron -886.12744 -0.41163343
e 640 loss 0.38900375 target loss -2941.5105 other loss -212273.88 tv loss 4106.8857
next layer loss target loss 0.0 other loss 10513.371
result 1 [11.9  8.6  1.9] neuron -886.03735 -0.41147032
e 650 loss 0.3887081 target loss -2941.3862 other loss -212280.42 tv loss 4107.143
next layer loss target loss 0.0 other loss 10513.994
result 1 [11.9  8.6  1.9] neuron -885.97797 -0.41146818
e 660 loss 0.388422 target loss -2941.2573 other loss -212288.33 tv loss 4107.2197
next layer loss target loss 0.0 other loss 10515.016
result 1 [11.9  8.6  1.9] neuron -885.9193 -0.4113765
e 670 loss 0.3881321 target loss -2941.081 other loss -212288.39 tv loss 4107.412
next layer loss target loss 0.0 other loss 10515.722
result 1 [11.9  8.6  1.9] neuron -885.83234 -0.41140443
e 680 loss 0.3878746 target loss -2941.03 other loss -212291.02 tv loss 4107.681
next layer loss target loss 0.0 other loss 10515.919
result 1 [11.9  8.6  1.9] neuron -885.80286 -0.4115025
e 690 loss 0.38759232 target loss -2940.9902 other loss -212295.06 tv loss 4107.639
next layer loss target loss 0.0 other loss 10516.317
result 1 [11.9  8.6  1.9] neuron -885.7864 -0.4115091
e 700 loss 0.38733482 target loss -2940.9429 other loss -212297.1 tv loss 4107.5645
next layer loss target loss 0.0 other loss 10516.638
result 1 [11.9  8.6  1.9] neuron -885.76025 -0.41151452
e 710 loss 0.38707352 target loss -2940.8872 other loss -212299.28 tv loss 4107.4814
next layer loss target loss 0.0 other loss 10517.021
result 1 [11.9  8.6  1.9] neuron -885.73254 -0.4115036
e 720 loss 0.38682556 target loss -2940.8213 other loss -212303.03 tv loss 4107.5
next layer loss target loss 0.0 other loss 10517.402
result 1 [11.9  8.6  1.9] neuron -885.7011 -0.41147184
e 730 loss 0.38657188 target loss -2940.834 other loss -212299.27 tv loss 4107.535
next layer loss target loss 0.0 other loss 10517.224
result 1 [11.89  8.6   1.9 ] neuron -885.7053 -0.41166568
e 740 loss 0.3863392 target loss -2940.7659 other loss -212303.2 tv loss 4107.5645
next layer loss target loss 0.0 other loss 10517.752
result 1 [11.89  8.6   1.9 ] neuron -885.6676 -0.41165924
e 750 loss 0.3861065 target loss -2940.6875 other loss -212309.83 tv loss 4107.549
next layer loss target loss 0.0 other loss 10518.593
result 1 [11.89  8.6   1.9 ] neuron -885.6287 -0.41161418
e 760 loss 0.38585663 target loss -2940.5806 other loss -212315.36 tv loss 4107.6743
next layer loss target loss 0.0 other loss 10519.441
result 1 [11.89  8.6   1.9 ] neuron -885.5752 -0.41158366
e 770 loss 0.38562775 target loss -2940.4834 other loss -212318.53 tv loss 4107.7466
next layer loss target loss 0.0 other loss 10520.154
result 1 [11.89  8.6   1.9 ] neuron -885.5305 -0.41159505
e 780 loss 0.38541794 target loss -2940.423 other loss -212322.53 tv loss 4107.895
next layer loss target loss 0.0 other loss 10520.758
result 1 [11.89  8.6   1.9 ] neuron -885.5009 -0.41160506
e 790 loss 0.3851967 target loss -2940.3564 other loss -212325.84 tv loss 4108.0645
next layer loss target loss 0.0 other loss 10521.322
result 1 [11.89  8.6   1.9 ] neuron -885.46436 -0.41164345
e 800 loss 0.38498306 target loss -2940.2578 other loss -212336.95 tv loss 4108.2476
next layer loss target loss 0.0 other loss 10522.489
result 1 [11.89  8.6   1.9 ] neuron -885.40967 -0.411539
e 810 loss 0.38476562 target loss -2940.1062 other loss -212343.38 tv loss 4108.5117
next layer loss target loss 0.0 other loss 10523.601
result 1 [11.89  8.6   1.9 ] neuron -885.3285 -0.41155624
e 820 loss 0.38456535 target loss -2940.0461 other loss -212350.77 tv loss 4108.901
next layer loss target loss 0.0 other loss 10524.428
result 1 [11.89  8.6   1.9 ] neuron -885.2945 -0.41160706
e 830 loss 0.38435936 target loss -2940.001 other loss -212355.95 tv loss 4109.016
next layer loss target loss 0.0 other loss 10524.809
result 1 [11.89  8.6   1.9 ] neuron -885.26587 -0.41158414
e 840 loss 0.3841591 target loss -2939.92 other loss -212353.48 tv loss 4108.953
next layer loss target loss 0.0 other loss 10524.971
result 1 [11.88  8.6   1.89] neuron -885.2249 -0.41162658
e 850 loss 0.3839569 target loss -2939.8616 other loss -212358.14 tv loss 4108.9937
next layer loss target loss 0.0 other loss 10525.436
result 1 [11.88  8.6   1.89] neuron -885.19763 -0.4115864
e 860 loss 0.38376617 target loss -2939.8235 other loss -212364.25 tv loss 4109.1367
next layer loss target loss 0.0 other loss 10525.96
result 1 [11.88  8.6   1.89] neuron -885.17615 -0.41160733
e 870 loss 0.38357544 target loss -2939.732 other loss -212369.45 tv loss 4109.275
next layer loss target loss 0.0 other loss 10526.53
result 1 [11.88  8.6   1.89] neuron -885.1278 -0.4115719
e 880 loss 0.38339233 target loss -2939.687 other loss -212372.11 tv loss 4109.4
next layer loss target loss 0.0 other loss 10526.873
result 1 [11.88  8.6   1.89] neuron -885.10645 -0.41162726
e 890 loss 0.3832035 target loss -2939.6067 other loss -212366.8 tv loss 4109.471
next layer loss target loss 0.0 other loss 10526.941
result 1 [11.88  8.6   1.89] neuron -885.06836 -0.4118116
e 900 loss 0.38301277 target loss -2939.5261 other loss -212375.1 tv loss 4109.578
next layer loss target loss 0.0 other loss 10527.783
result 1 [11.88  8.6   1.89] neuron -885.0292 -0.41173315
e 910 loss 0.38283348 target loss -2939.4785 other loss -212380.69 tv loss 4109.7695
next layer loss target loss 0.0 other loss 10528.219
result 1 [11.88  8.6   1.89] neuron -885.00476 -0.41176143
e 920 loss 0.38266563 target loss -2939.4438 other loss -212382.31 tv loss 4109.8257
next layer loss target loss 0.0 other loss 10528.434
result 1 [11.88  8.6   1.89] neuron -884.9901 -0.41182527
e 930 loss 0.38248825 target loss -2939.3384 other loss -212385.14 tv loss 4109.792
next layer loss target loss 0.0 other loss 10528.904
result 1 [11.88  8.6   1.89] neuron -884.94165 -0.41176018
e 940 loss 0.38232422 target loss -2939.2693 other loss -212388.97 tv loss 4109.8477
next layer loss target loss 0.0 other loss 10529.367
result 1 [11.88  8.6   1.89] neuron -884.9158 -0.4117416
e 950 loss 0.38215637 target loss -2939.2004 other loss -212392.33 tv loss 4109.9336
next layer loss target loss 0.0 other loss 10529.699
result 1 [11.88  8.6   1.89] neuron -884.8866 -0.41174036
e 960 loss 0.3819828 target loss -2939.1743 other loss -212396.84 tv loss 4109.966
next layer loss target loss 0.0 other loss 10530.0
result 1 [11.88  8.6   1.89] neuron -884.8805 -0.4117275
e 970 loss 0.38180733 target loss -2939.1113 other loss -212401.73 tv loss 4110.0234
next layer loss target loss 0.0 other loss 10530.511
result 1 [11.87  8.6   1.89] neuron -884.84973 -0.4117051
e 980 loss 0.38166046 target loss -2939.0493 other loss -212408.66 tv loss 4110.182
next layer loss target loss 0.0 other loss 10531.109
result 1 [11.87  8.61  1.89] neuron -884.81256 -0.4116751
e 990 loss 0.38149834 target loss -2938.9175 other loss -212412.36 tv loss 4110.2764
next layer loss target loss 0.0 other loss 10531.971
result 1 [11.87  8.61  1.89] neuron -884.75305 -0.4116742
RE filter conv2d_3 54 RE acc 0.3333333333333333
e 0 loss 1.0502262 target loss -3104.293 other loss -27060.602 tv loss 3976.1335
next layer loss target loss 0.0 other loss 100022.91
result 1 [12.2   8.22  1.93] neuron -914.62354 -0.38708642
e 10 loss -1.5538349 target loss -2677.4053 other loss -25294.23 tv loss 3852.0444
next layer loss target loss 0.0 other loss 97523.49
result 1 [11.43  7.59  1.71] neuron -762.0353 -0.10861564
e 20 loss -3.9187279 target loss -2276.4546 other loss -24917.736 tv loss 3723.9504
next layer loss target loss 0.024833202 other loss 97205.79
result 1 [10.12  6.02  1.74] neuron -611.5196 0.015338242
e 30 loss -6.1079006 target loss -1901.4476 other loss -25417.459 tv loss 3611.2686
next layer loss target loss 3.9052637 other loss 99544.91
result 1 [8.74 5.25 1.87] neuron -467.22595 0.11916071
e 40 loss -8.3850975 target loss -1560.4626 other loss -26647.54 tv loss 3488.4521
next layer loss target loss 30.040123 other loss 103567.92
result 0 [7.36 4.7  2.1 ] neuron -342.29303 0.26961935
e 50 loss -10.755175 target loss -1261.9358 other loss -28076.043 tv loss 3337.4536
next layer loss target loss 84.39975 other loss 107823.82
result 0 [6.67 4.17 2.41] neuron -237.33615 0.37329227
e 60 loss -12.87197 target loss -1017.159 other loss -29256.838 tv loss 3197.2102
next layer loss target loss 142.69049 other loss 111578.83
result 0 [6.44 3.67 2.63] neuron -151.5401 0.3902493
e 70 loss -14.57534 target loss -822.07385 other loss -30089.906 tv loss 3070.7593
next layer loss target loss 194.37196 other loss 114667.125
result 1 [6.51 3.42 2.74] neuron -86.20238 0.43210596
e 80 loss -15.901583 target loss -670.63367 other loss -30764.176 tv loss 2967.958
next layer loss target loss 232.90616 other loss 117211.0
result 1 [6.86 3.23 2.76] neuron -40.534355 0.4412815
e 90 loss -16.045708 target loss -638.5624 other loss -30685.43 tv loss 2950.2312
next layer loss target loss 232.47008 other loss 117247.34
result 1 [6.96 3.13 2.76] neuron -33.9597 0.46157652
e 100 loss -15.202333 target loss -770.56445 other loss -31558.572 tv loss 3119.8018
next layer loss target loss 198.12425 other loss 116360.77
result 1 [6.8  3.41 2.84] neuron -71.12169 0.42512053
e 110 loss -14.670377 target loss -813.3206 other loss -32073.588 tv loss 3185.4705
next layer loss target loss 188.13556 other loss 116407.85
result 1 [6.83 3.52 2.86] neuron -82.77872 0.4248249
e 120 loss -14.490871 target loss -825.28357 other loss -32264.518 tv loss 3207.676
next layer loss target loss 185.65674 other loss 116514.55
result 1 [6.86 3.55 2.87] neuron -85.523506 0.42482942
e 130 loss -14.4767 target loss -825.657 other loss -32334.371 tv loss 3213.4597
next layer loss target loss 186.06166 other loss 116638.7
result 1 [6.88 3.56 2.86] neuron -84.804276 0.42524534
e 140 loss -14.526567 target loss -821.7332 other loss -32360.525 tv loss 3213.1006
next layer loss target loss 187.52663 other loss 116768.93
result 1 [6.9  3.55 2.86] neuron -82.79138 0.42579442
e 150 loss -14.601158 target loss -816.19135 other loss -32371.756 tv loss 3210.433
next layer loss target loss 189.38492 other loss 116902.734
result 1 [6.91 3.53 2.86] neuron -80.2818 0.4263838
e 160 loss -14.685812 target loss -810.00525 other loss -32378.584 tv loss 3206.8826
next layer loss target loss 191.4139 other loss 117039.44
result 1 [6.94 3.52 2.85] neuron -77.57446 0.42698437
e 170 loss -14.774662 target loss -803.5388 other loss -32384.63 tv loss 3202.9614
next layer loss target loss 193.51816 other loss 117178.13
result 1 [6.96 3.51 2.84] neuron -74.7892 0.42758566
e 180 loss -14.8660755 target loss -796.9087 other loss -32391.627 tv loss 3198.829
next layer loss target loss 195.68549 other loss 117319.42
result 1 [6.97 3.49 2.84] neuron -71.95592 0.42818505
e 190 loss -14.959127 target loss -790.1651 other loss -32400.111 tv loss 3194.628
next layer loss target loss 197.87837 other loss 117463.36
result 1 [6.99 3.48 2.83] neuron -69.07016 0.4287824
e 200 loss -15.052851 target loss -783.3653 other loss -32409.988 tv loss 3190.2822
next layer loss target loss 200.08511 other loss 117608.28
result 1 [7.01 3.46 2.83] neuron -66.1514 0.42937547
e 210 loss -15.147806 target loss -776.49774 other loss -32421.482 tv loss 3185.7854
next layer loss target loss 202.34407 other loss 117754.625
result 1 [7.04 3.45 2.82] neuron -63.19817 0.42983586
e 220 loss -15.242724 target loss -769.5962 other loss -32434.39 tv loss 3181.189
next layer loss target loss 204.6104 other loss 117901.72
result 1 [7.06 3.43 2.81] neuron -60.22621 0.43244606
e 230 loss -15.337429 target loss -762.6789 other loss -32448.74 tv loss 3176.549
next layer loss target loss 206.89314 other loss 118049.73
result 1 [7.08 3.42 2.81] neuron -57.23614 0.4351837
e 240 loss -15.431834 target loss -755.7666 other loss -32464.604 tv loss 3171.9167
next layer loss target loss 209.15585 other loss 118198.22
result 1 [7.11 3.4  2.8 ] neuron -54.22946 0.4379633
e 250 loss -15.525717 target loss -748.86096 other loss -32481.879 tv loss 3167.1997
next layer loss target loss 211.39311 other loss 118346.95
result 1 [7.13 3.39 2.79] neuron -51.211422 0.44078618
e 260 loss -15.619424 target loss -741.9198 other loss -32501.016 tv loss 3162.3628
next layer loss target loss 213.66722 other loss 118497.21
result 1 [7.15 3.37 2.79] neuron -48.17697 0.4436502
e 270 loss -15.713019 target loss -734.9655 other loss -32521.947 tv loss 3157.4492
next layer loss target loss 215.96582 other loss 118648.0
result 1 [7.18 3.36 2.78] neuron -45.133415 0.44673008
e 280 loss -15.806616 target loss -727.94385 other loss -32545.082 tv loss 3152.4443
next layer loss target loss 218.30629 other loss 118800.91
result 1 [7.2  3.35 2.77] neuron -42.063606 0.44990808
e 290 loss -15.900092 target loss -720.8539 other loss -32570.475 tv loss 3147.335
next layer loss target loss 220.68196 other loss 118956.08
result 1 [7.23 3.33 2.76] neuron -38.96178 0.45314652
e 300 loss -15.993588 target loss -713.68976 other loss -32598.172 tv loss 3142.1335
next layer loss target loss 223.08273 other loss 119113.51
result 1 [7.26 3.32 2.76] neuron -35.82912 0.45644623
e 310 loss -16.087116 target loss -706.4812 other loss -32628.035 tv loss 3136.8645
next layer loss target loss 225.46234 other loss 119272.66
result 1 [7.29 3.3  2.75] neuron -32.70039 0.45953506
e 320 loss -16.180643 target loss -699.2279 other loss -32660.17 tv loss 3131.478
next layer loss target loss 227.85536 other loss 119433.93
result 1 [7.31 3.29 2.75] neuron -29.567795 0.46263975
e 330 loss -16.273525 target loss -691.9513 other loss -32694.258 tv loss 3125.9778
next layer loss target loss 230.23273 other loss 119595.99
result 1 [7.34 3.28 2.74] neuron -26.435705 0.46579403
e 340 loss -16.366028 target loss -684.6421 other loss -32730.27 tv loss 3120.4846
next layer loss target loss 232.6296 other loss 119759.625
result 1 [7.37 3.27 2.74] neuron -23.328203 0.46899146
e 350 loss -16.4588 target loss -677.271 other loss -32768.363 tv loss 3114.9275
next layer loss target loss 235.05302 other loss 119925.56
result 1 [7.41 3.26 2.73] neuron -20.223654 0.47224468
e 360 loss -16.551516 target loss -669.81616 other loss -32808.824 tv loss 3109.2847
next layer loss target loss 237.53972 other loss 120094.39
result 1 [7.44 3.25 2.73] neuron -17.080614 0.47555846
e 370 loss -16.643959 target loss -662.309 other loss -32851.047 tv loss 3103.5293
next layer loss target loss 240.0868 other loss 120264.61
result 1 [7.48 3.24 2.72] neuron -13.915829 0.47902554
e 380 loss -16.736864 target loss -654.7107 other loss -32895.5 tv loss 3097.6265
next layer loss target loss 242.75136 other loss 120437.8
result 1 [7.51 3.22 2.72] neuron -10.701149 0.4825924
e 390 loss -16.829845 target loss -647.04504 other loss -32942.055 tv loss 3091.6538
next layer loss target loss 245.49188 other loss 120614.28
result 1 [7.55 3.21 2.72] neuron -7.454685 0.4860993
e 400 loss -16.922428 target loss -639.38556 other loss -32990.023 tv loss 3085.545
next layer loss target loss 248.25914 other loss 120790.91
result 1 [7.58 3.2  2.71] neuron -4.2198124 0.48912102
e 410 loss -17.014395 target loss -631.7128 other loss -33039.367 tv loss 3079.3584
next layer loss target loss 251.06592 other loss 120968.89
result 1 [7.62 3.19 2.71] neuron -0.9909477 0.49218196
e 420 loss -17.106033 target loss -624.05676 other loss -33089.418 tv loss 3073.2158
next layer loss target loss 253.88031 other loss 121147.39
result 1 [7.65 3.18 2.71] neuron 2.2030373 0.49528283
e 430 loss -17.197582 target loss -616.3778 other loss -33140.402 tv loss 3067.0298
next layer loss target loss 256.7101 other loss 121326.94
result 1 [7.68 3.17 2.7 ] neuron 5.3782196 0.49843234
e 440 loss -17.288359 target loss -608.69446 other loss -33191.9 tv loss 3060.7563
next layer loss target loss 259.54767 other loss 121506.21
result 1 [7.71 3.16 2.7 ] neuron 8.532682 0.5016226
e 450 loss -17.377893 target loss -601.0188 other loss -33243.508 tv loss 3054.3335
next layer loss target loss 262.4047 other loss 121684.4
result 1 [7.74 3.16 2.7 ] neuron 11.6647835 0.5048495
e 460 loss -17.46651 target loss -593.3841 other loss -33294.996 tv loss 3047.9111
next layer loss target loss 265.27884 other loss 121861.36
result 1 [7.77 3.15 2.7 ] neuron 14.75424 0.5080977
e 470 loss -17.554108 target loss -585.8111 other loss -33346.09 tv loss 3041.4194
next layer loss target loss 268.16498 other loss 122036.61
result 1 [7.79 3.14 2.69] neuron 17.795135 0.5113178
e 480 loss -17.641266 target loss -578.2506 other loss -33397.23 tv loss 3034.9104
next layer loss target loss 271.0597 other loss 122211.945
result 1 [7.82 3.13 2.69] neuron 20.819256 0.5134377
e 490 loss -17.728054 target loss -570.71735 other loss -33448.027 tv loss 3028.4111
next layer loss target loss 273.9613 other loss 122385.57
result 1 [7.84 3.12 2.69] neuron 23.808413 0.5151058
e 500 loss -17.81467 target loss -563.1719 other loss -33498.637 tv loss 3021.8623
next layer loss target loss 276.87384 other loss 122559.1
result 1 [7.87 3.11 2.69] neuron 26.781109 0.51679987
e 510 loss -17.89984 target loss -555.6904 other loss -33548.363 tv loss 3015.3916
next layer loss target loss 279.76096 other loss 122730.58
result 1 [7.89 3.1  2.69] neuron 29.7107 0.51849717
e 520 loss -17.983952 target loss -548.2648 other loss -33597.164 tv loss 3008.9414
next layer loss target loss 282.63333 other loss 122900.19
result 1 [7.92 3.09 2.69] neuron 32.60196 0.5201953
e 530 loss -18.068403 target loss -540.8899 other loss -33645.27 tv loss 3002.635
next layer loss target loss 285.49164 other loss 123068.375
result 1 [7.94 3.09 2.68] neuron 35.438965 0.5219148
e 540 loss -18.153793 target loss -533.4758 other loss -33693.293 tv loss 2996.3916
next layer loss target loss 288.35696 other loss 123238.16
result 1 [7.97 3.08 2.68] neuron 38.24227 0.5236533
e 550 loss -18.239948 target loss -526.00885 other loss -33741.473 tv loss 2990.2397
next layer loss target loss 291.23807 other loss 123410.01
result 1 [7.99 3.07 2.68] neuron 41.044266 0.52541226
e 560 loss -18.326138 target loss -518.5133 other loss -33789.48 tv loss 2984.0776
next layer loss target loss 294.1366 other loss 123582.76
result 1 [8.02 3.07 2.68] neuron 43.851223 0.52719325
e 570 loss -18.41159 target loss -511.0243 other loss -33836.777 tv loss 2977.8555
next layer loss target loss 297.04553 other loss 123754.6
result 1 [8.04 3.06 2.68] neuron 46.649605 0.5289925
e 580 loss -18.496864 target loss -503.51245 other loss -33883.63 tv loss 2971.564
next layer loss target loss 299.9897 other loss 123926.54
result 1 [8.06 3.06 2.68] neuron 49.443977 0.5308148
e 590 loss -18.581657 target loss -495.99023 other loss -33930.156 tv loss 2965.2852
next layer loss target loss 302.928 other loss 124098.88
result 1 [8.09 3.05 2.68] neuron 52.212425 0.53265005
e 600 loss -18.666105 target loss -488.45258 other loss -33976.457 tv loss 2959.058
next layer loss target loss 305.8667 other loss 124272.63
result 1 [8.11 3.05 2.68] neuron 54.953484 0.53422457
e 610 loss -18.749512 target loss -480.95074 other loss -34022.05 tv loss 2952.92
next layer loss target loss 308.7737 other loss 124446.055
result 1 [8.13 3.05 2.68] neuron 57.626045 0.5354031
e 620 loss -18.83202 target loss -473.51202 other loss -34066.78 tv loss 2947.002
next layer loss target loss 311.67432 other loss 124619.24
result 1 [8.15 3.05 2.69] neuron 60.222824 0.53656846
e 630 loss -18.914463 target loss -466.07306 other loss -34111.35 tv loss 2941.2324
next layer loss target loss 314.6015 other loss 124794.73
result 1 [8.17 3.04 2.69] neuron 62.7807 0.5377242
e 640 loss -18.996717 target loss -458.6388 other loss -34155.6 tv loss 2935.5916
next layer loss target loss 317.52322 other loss 124970.97
result 1 [8.2  3.04 2.69] neuron 65.28664 0.53887624
e 650 loss -19.077864 target loss -451.2408 other loss -34199.305 tv loss 2930.0383
next layer loss target loss 320.40012 other loss 125147.266
result 1 [8.22 3.04 2.69] neuron 67.72667 0.5400204
e 660 loss -19.158813 target loss -443.83673 other loss -34242.906 tv loss 2924.6313
next layer loss target loss 323.28302 other loss 125325.51
result 1 [8.24 3.04 2.69] neuron 70.12804 0.5411524
e 670 loss -19.238922 target loss -436.48526 other loss -34285.63 tv loss 2919.4084
next layer loss target loss 326.145 other loss 125503.57
result 1 [8.26 3.04 2.69] neuron 72.463844 0.54227287
e 680 loss -19.319271 target loss -429.1413 other loss -34327.848 tv loss 2914.253
next layer loss target loss 329.01633 other loss 125681.93
result 1 [8.28 3.04 2.69] neuron 74.74622 0.54338616
e 690 loss -19.400127 target loss -421.78574 other loss -34369.84 tv loss 2909.1162
next layer loss target loss 331.9212 other loss 125861.34
result 1 [8.3  3.04 2.69] neuron 77.00171 0.54450077
e 700 loss -19.480438 target loss -414.44833 other loss -34410.992 tv loss 2903.989
next layer loss target loss 334.81125 other loss 126041.26
result 1 [8.32 3.05 2.69] neuron 79.199295 0.5456063
e 710 loss -19.560274 target loss -407.1606 other loss -34451.285 tv loss 2898.8975
next layer loss target loss 337.66382 other loss 126220.3
result 1 [8.34 3.06 2.69] neuron 81.34298 0.5467016
e 720 loss -19.639853 target loss -399.93008 other loss -34490.88 tv loss 2893.954
next layer loss target loss 340.474 other loss 126398.21
result 1 [8.36 3.06 2.69] neuron 83.41362 0.54778475
e 730 loss -19.719555 target loss -392.70758 other loss -34530.184 tv loss 2889.1016
next layer loss target loss 343.27704 other loss 126577.25
result 1 [8.38 3.07 2.69] neuron 85.42131 0.5488556
e 740 loss -19.79953 target loss -385.48502 other loss -34569.168 tv loss 2884.3027
next layer loss target loss 346.0927 other loss 126757.17
result 1 [8.4  3.08 2.69] neuron 87.37208 0.5499225
e 750 loss -19.878963 target loss -378.29364 other loss -34607.445 tv loss 2879.5444
next layer loss target loss 348.88287 other loss 126936.74
result 1 [8.42 3.09 2.69] neuron 89.255424 0.550983
e 760 loss -19.95809 target loss -371.13605 other loss -34645.086 tv loss 2874.8467
next layer loss target loss 351.65048 other loss 127116.336
result 1 [8.44 3.1  2.69] neuron 91.0824 0.55202836
e 770 loss -20.038021 target loss -363.99973 other loss -34682.414 tv loss 2870.3022
next layer loss target loss 354.42197 other loss 127296.1
result 1 [8.46 3.11 2.69] neuron 92.849434 0.5530718
e 780 loss -20.118595 target loss -356.81824 other loss -34719.86 tv loss 2865.7651
next layer loss target loss 357.24304 other loss 127477.87
result 1 [8.48 3.13 2.69] neuron 94.595276 0.5541164
e 790 loss -20.199066 target loss -349.65692 other loss -34756.727 tv loss 2861.2224
next layer loss target loss 360.04767 other loss 127659.2
result 1 [8.5  3.14 2.69] neuron 96.30899 0.55516094
e 800 loss -20.27843 target loss -342.57034 other loss -34793.02 tv loss 2856.8987
next layer loss target loss 362.79944 other loss 127839.88
result 1 [8.52 3.16 2.69] neuron 97.95596 0.5561865
e 810 loss -20.357069 target loss -335.55396 other loss -34828.71 tv loss 2852.7761
next layer loss target loss 365.521 other loss 128020.02
result 1 [8.54 3.17 2.7 ] neuron 99.53959 0.5571732
e 820 loss -20.435476 target loss -328.57352 other loss -34863.902 tv loss 2848.7126
next layer loss target loss 368.22806 other loss 128199.48
result 1 [8.55 3.19 2.7 ] neuron 101.078896 0.5581096
e 830 loss -20.51329 target loss -321.66095 other loss -34898.332 tv loss 2844.72
next layer loss target loss 370.90094 other loss 128376.125
result 1 [8.57 3.21 2.7 ] neuron 102.550446 0.55903655
e 840 loss -20.591383 target loss -314.7619 other loss -34932.54 tv loss 2840.8467
next layer loss target loss 373.58167 other loss 128552.72
result 1 [8.59 3.22 2.71] neuron 103.96624 0.5598751
e 850 loss -19767.9 target loss -408.0232 other loss -34204.4 tv loss 2911.191
next layer loss target loss 331.95483 other loss 126164.8
result 1 [8.3  3.01 2.69] neuron 76.17554 0.5335813
e 860 loss -18.089348 target loss -532.29785 other loss -36724.586 tv loss 3185.6304
next layer loss target loss 302.06244 other loss 127986.17
result 1 [8.29 3.2  2.66] neuron 55.84758 0.5442664
e 870 loss -17.197815 target loss -573.58875 other loss -37627.617 tv loss 3280.603
next layer loss target loss 293.8697 other loss 128788.95
result 1 [8.33 3.33 2.61] neuron 49.3789 0.54311746
e 880 loss -13.846312 target loss -864.30774 other loss -34751.85 tv loss 3426.235
next layer loss target loss 207.58267 other loss 123728.6
result 1 [7.91 3.22 1.93] neuron -22.096903 0.46442443
e 890 loss -14.559408 target loss -934.0192 other loss -34856.926 tv loss 3493.1472
next layer loss target loss 209.91516 other loss 124223.7
result 1 [8.1  3.43 1.57] neuron -20.69603 0.45388204
e 900 loss -15.2691765 target loss -934.776 other loss -35417.605 tv loss 3515.6455
next layer loss target loss 225.40263 other loss 125433.42
result 1 [8.27 3.55 1.42] neuron -7.27623 0.45697016
e 910 loss -15.204425 target loss -930.7081 other loss -35689.26 tv loss 3518.7368
next layer loss target loss 232.26318 other loss 125973.42
result 1 [8.33 3.59 1.38] neuron -1.0625839 0.45519036
e 920 loss -15.194141 target loss -925.2646 other loss -35829.79 tv loss 3515.004
next layer loss target loss 235.96509 other loss 126229.516
result 1 [8.35 3.6  1.36] neuron 2.5808792 0.4566682
e 930 loss -15.231661 target loss -919.53345 other loss -35912.434 tv loss 3508.982
next layer loss target loss 238.43945 other loss 126373.96
result 1 [8.36 3.6  1.36] neuron 5.2267838 0.4592541
e 940 loss -15.2893505 target loss -913.7943 other loss -35969.914 tv loss 3502.1992
next layer loss target loss 240.44292 other loss 126475.39
result 1 [8.36 3.59 1.35] neuron 7.4769135 0.46221787
e 950 loss -15.354115 target loss -908.11847 other loss -36016.31 tv loss 3495.2476
next layer loss target loss 242.24393 other loss 126559.45
result 1 [8.35 3.57 1.35] neuron 9.54388 0.46530885
e 960 loss -15.421427 target loss -902.48376 other loss -36057.664 tv loss 3488.2043
next layer loss target loss 243.97888 other loss 126636.51
result 1 [8.35 3.56 1.35] neuron 11.536245 0.46844715
e 970 loss -15.489497 target loss -896.8817 other loss -36096.395 tv loss 3481.0642
next layer loss target loss 245.6868 other loss 126710.03
result 1 [8.34 3.54 1.35] neuron 13.483601 0.4711601
e 980 loss -15.557871 target loss -891.2969 other loss -36133.535 tv loss 3473.9058
next layer loss target loss 247.3833 other loss 126782.25
result 1 [8.34 3.52 1.35] neuron 15.39744 0.47378713
e 990 loss -15.626068 target loss -885.719 other loss -36169.438 tv loss 3466.7363
next layer loss target loss 249.08101 other loss 126853.766
result 1 [8.34 3.51 1.35] neuron 17.287907 0.47642213
RE filter conv2d_2 97 RE acc 0.3333333333333333
e 0 loss -4.5468616 target loss -2547.267 other loss -204433.23 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -824.0687 -0.32594568
e 10 loss -4.833687 target loss -2501.5698 other loss -205292.1 tv loss 3981.0308
next layer loss target loss 0.0 other loss 9450.598
result 1 [12.27  8.29  1.84] neuron -803.71643 -0.32128453
e 20 loss -4.9679623 target loss -2477.8496 other loss -205929.23 tv loss 3974.578
next layer loss target loss 0.0 other loss 9681.558
result 1 [12.19  8.19  1.78] neuron -793.923 -0.32767174
e 30 loss -5.0209904 target loss -2464.2717 other loss -206395.0 tv loss 3981.787
next layer loss target loss 0.0 other loss 9830.692
result 1 [12.08  8.04  1.74] neuron -788.90393 -0.33105186
e 40 loss -5.0454407 target loss -2456.8262 other loss -206630.3 tv loss 3996.2056
next layer loss target loss 0.0 other loss 9913.718
result 1 [12.02  7.94  1.7 ] neuron -785.8007 -0.32215804
e 50 loss -5.060623 target loss -2454.0398 other loss -206765.12 tv loss 4008.695
next layer loss target loss 0.0 other loss 9945.652
result 1 [12.    7.89  1.69] neuron -784.5642 -0.31844658
e 60 loss -5.0709534 target loss -2453.3416 other loss -207061.3 tv loss 4021.5146
next layer loss target loss 0.0 other loss 9966.34
result 1 [12.    7.89  1.7 ] neuron -784.358 -0.3158843
e 70 loss -5.078127 target loss -2451.934 other loss -207306.16 tv loss 4029.3647
next layer loss target loss 0.0 other loss 9985.942
result 1 [11.99  7.91  1.7 ] neuron -783.6634 -0.314556
e 80 loss -5.083536 target loss -2450.5796 other loss -207435.16 tv loss 4033.7354
next layer loss target loss 0.0 other loss 9999.428
result 1 [11.98  7.92  1.69] neuron -783.03705 -0.31353694
e 90 loss -5.0880165 target loss -2449.6648 other loss -207456.5 tv loss 4035.0037
next layer loss target loss 0.0 other loss 10004.632
result 1 [11.97  7.91  1.69] neuron -782.64355 -0.31265765
e 100 loss -5.091942 target loss -2448.7368 other loss -207444.06 tv loss 4033.7852
next layer loss target loss 0.0 other loss 10007.553
result 1 [11.96  7.9   1.69] neuron -782.2708 -0.31205335
e 110 loss -5.0953865 target loss -2448.0916 other loss -207439.72 tv loss 4032.0857
next layer loss target loss 0.0 other loss 10008.784
result 1 [11.96  7.9   1.69] neuron -782.106 -0.3117032
e 120 loss -5.098421 target loss -2447.473 other loss -207449.62 tv loss 4030.663
next layer loss target loss 0.0 other loss 10010.474
result 1 [11.96  7.9   1.7 ] neuron -781.9438 -0.31137887
e 130 loss -5.1011086 target loss -2446.9382 other loss -207477.95 tv loss 4029.6528
next layer loss target loss 0.0 other loss 10012.627
result 1 [11.96  7.9   1.7 ] neuron -781.8202 -0.31105962
e 140 loss -5.1035004 target loss -2446.583 other loss -207476.03 tv loss 4028.9307
next layer loss target loss 0.0 other loss 10011.659
result 1 [11.96  7.9   1.7 ] neuron -781.73694 -0.31087086
e 150 loss -5.1056347 target loss -2446.3342 other loss -207457.38 tv loss 4028.2263
next layer loss target loss 0.0 other loss 10008.764
result 1 [11.96  7.9   1.7 ] neuron -781.6998 -0.3108703
e 160 loss -5.1075535 target loss -2446.0889 other loss -207453.62 tv loss 4027.2544
next layer loss target loss 0.0 other loss 10006.735
result 1 [11.96  7.9   1.71] neuron -781.6946 -0.31093574
e 170 loss -5.109249 target loss -2445.7915 other loss -207447.17 tv loss 4026.3198
next layer loss target loss 0.0 other loss 10005.176
result 1 [11.96  7.91  1.71] neuron -781.63586 -0.31094262
e 180 loss -5.1107674 target loss -2445.5623 other loss -207434.56 tv loss 4025.6135
next layer loss target loss 0.0 other loss 10003.408
result 1 [11.96  7.9   1.71] neuron -781.6045 -0.31096226
e 190 loss -5.1121235 target loss -2445.277 other loss -207436.06 tv loss 4025.3071
next layer loss target loss 0.0 other loss 10002.73
result 1 [11.96  7.91  1.71] neuron -781.5313 -0.3109253
e 200 loss -5.113373 target loss -2445.0261 other loss -207456.84 tv loss 4025.0796
next layer loss target loss 0.0 other loss 10003.066
result 1 [11.96  7.91  1.72] neuron -781.48236 -0.310912
e 210 loss -5.114506 target loss -2444.7642 other loss -207477.23 tv loss 4024.9514
next layer loss target loss 0.0 other loss 10003.878
result 1 [11.96  7.91  1.72] neuron -781.4275 -0.31077504
e 220 loss -5.1155453 target loss -2444.625 other loss -207483.44 tv loss 4024.7036
next layer loss target loss 0.0 other loss 10003.222
result 1 [11.97  7.91  1.72] neuron -781.4158 -0.31074613
e 230 loss -5.1164837 target loss -2444.4614 other loss -207495.05 tv loss 4024.5547
next layer loss target loss 0.0 other loss 10003.249
result 1 [11.97  7.92  1.73] neuron -781.38696 -0.31067556
e 240 loss -5.117384 target loss -2444.249 other loss -207511.95 tv loss 4024.355
next layer loss target loss 0.0 other loss 10004.122
result 1 [11.97  7.92  1.73] neuron -781.33826 -0.31057054
e 250 loss -5.1182117 target loss -2444.0554 other loss -207526.34 tv loss 4024.18
next layer loss target loss 0.0 other loss 10004.742
result 1 [11.97  7.92  1.73] neuron -781.2895 -0.3104853
e 260 loss -5.1190033 target loss -2443.9072 other loss -207542.22 tv loss 4024.0693
next layer loss target loss 0.0 other loss 10005.358
result 1 [11.97  7.92  1.74] neuron -781.2645 -0.31037286
e 270 loss -5.119732 target loss -2443.8008 other loss -207555.38 tv loss 4024.0168
next layer loss target loss 0.0 other loss 10005.713
result 1 [11.97  7.92  1.74] neuron -781.25525 -0.3102639
e 280 loss -5.1204166 target loss -2443.6533 other loss -207560.9 tv loss 4024.065
next layer loss target loss 0.0 other loss 10005.8125
result 1 [11.97  7.92  1.74] neuron -781.2065 -0.31018475
e 290 loss -5.1210575 target loss -2443.484 other loss -207565.16 tv loss 4024.006
next layer loss target loss 0.0 other loss 10005.972
result 1 [11.97  7.92  1.74] neuron -781.1487 -0.31017202
e 300 loss -5.1216545 target loss -2443.3394 other loss -207566.7 tv loss 4024.0217
next layer loss target loss 0.0 other loss 10005.828
result 1 [11.97  7.92  1.74] neuron -781.09045 -0.3101766
e 310 loss -5.122219 target loss -2443.268 other loss -207574.66 tv loss 4024.04
next layer loss target loss 0.0 other loss 10005.789
result 1 [11.97  7.92  1.74] neuron -781.0858 -0.31015792
e 320 loss -5.122761 target loss -2443.207 other loss -207578.97 tv loss 4024.0632
next layer loss target loss 0.0 other loss 10005.619
result 1 [11.97  7.92  1.75] neuron -781.06824 -0.31011716
e 330 loss -5.123266 target loss -2443.1096 other loss -207584.5 tv loss 4024.082
next layer loss target loss 0.0 other loss 10005.721
result 1 [11.97  7.92  1.75] neuron -781.03314 -0.3100819
e 340 loss -5.123749 target loss -2442.9788 other loss -207595.27 tv loss 4024.1597
next layer loss target loss 0.0 other loss 10006.408
result 1 [11.97  7.92  1.75] neuron -780.98706 -0.31001353
e 350 loss -5.1242046 target loss -2442.9001 other loss -207605.56 tv loss 4024.359
next layer loss target loss 0.0 other loss 10006.8
result 1 [11.97  7.92  1.75] neuron -780.96234 -0.30995786
e 360 loss -5.124645 target loss -2442.7659 other loss -207615.64 tv loss 4024.575
next layer loss target loss 0.0 other loss 10007.727
result 1 [11.97  7.92  1.75] neuron -780.9049 -0.3098455
e 370 loss -5.1250534 target loss -2442.7246 other loss -207622.64 tv loss 4024.7368
next layer loss target loss 0.0 other loss 10007.701
result 1 [11.97  7.92  1.75] neuron -780.8961 -0.3098365
e 380 loss -5.125456 target loss -2442.7017 other loss -207622.05 tv loss 4024.6865
next layer loss target loss 0.0 other loss 10006.909
result 1 [11.97  7.92  1.75] neuron -780.8974 -0.30986574
e 390 loss -5.125824 target loss -2442.6526 other loss -207624.92 tv loss 4024.6948
next layer loss target loss 0.0 other loss 10006.723
result 1 [11.97  7.92  1.76] neuron -780.88354 -0.30987424
e 400 loss -5.1261806 target loss -2442.569 other loss -207628.75 tv loss 4024.6895
next layer loss target loss 0.0 other loss 10006.963
result 1 [11.97  7.92  1.76] neuron -780.8539 -0.30981904
e 410 loss -5.12652 target loss -2442.468 other loss -207633.94 tv loss 4024.6094
next layer loss target loss 0.0 other loss 10007.51
result 1 [11.97  7.92  1.76] neuron -780.8181 -0.30978072
e 420 loss -5.126848 target loss -2442.426 other loss -207632.42 tv loss 4024.6445
next layer loss target loss 0.0 other loss 10007.206
result 1 [11.97  7.92  1.76] neuron -780.80835 -0.30977648
e 430 loss -5.1271553 target loss -2442.3923 other loss -207640.89 tv loss 4024.7454
next layer loss target loss 0.0 other loss 10007.351
result 1 [11.97  7.92  1.76] neuron -780.8036 -0.30975503
e 440 loss -5.127449 target loss -2442.3484 other loss -207652.42 tv loss 4024.934
next layer loss target loss 0.0 other loss 10007.913
result 1 [11.97  7.92  1.76] neuron -780.79266 -0.3096969
e 450 loss -5.1277275 target loss -2442.279 other loss -207660.12 tv loss 4024.9321
next layer loss target loss 0.0 other loss 10008.4795
result 1 [11.97  7.92  1.76] neuron -780.7703 -0.3096596
e 460 loss -5.128002 target loss -2442.2139 other loss -207664.38 tv loss 4025.0498
next layer loss target loss 0.0 other loss 10008.814
result 1 [11.97  7.92  1.76] neuron -780.7447 -0.30960283
e 470 loss -5.1282578 target loss -2442.1506 other loss -207669.88 tv loss 4025.208
next layer loss target loss 0.0 other loss 10009.223
result 1 [11.97  7.92  1.76] neuron -780.71875 -0.3095515
e 480 loss -5.1285114 target loss -2442.0571 other loss -207678.5 tv loss 4025.3896
next layer loss target loss 0.0 other loss 10010.155
result 1 [11.97  7.92  1.76] neuron -780.68036 -0.3094848
e 490 loss -5.1287575 target loss -2441.9434 other loss -207683.58 tv loss 4025.5112
next layer loss target loss 0.0 other loss 10011.051
result 1 [11.97  7.92  1.76] neuron -780.6267 -0.30942062
e 500 loss -5.128992 target loss -2441.8608 other loss -207683.19 tv loss 4025.6814
next layer loss target loss 0.0 other loss 10011.358
result 1 [11.97  7.92  1.76] neuron -780.5792 -0.30938596
e 510 loss -5.1292133 target loss -2441.7534 other loss -207699.25 tv loss 4026.0696
next layer loss target loss 0.0 other loss 10012.596
result 1 [11.97  7.93  1.76] neuron -780.52795 -0.30931813
e 520 loss -5.129448 target loss -2441.6948 other loss -207712.03 tv loss 4026.4294
next layer loss target loss 0.0 other loss 10013.546
result 1 [11.97  7.93  1.76] neuron -780.5019 -0.30923036
e 530 loss -5.12965 target loss -2441.6392 other loss -207719.22 tv loss 4026.5398
next layer loss target loss 0.0 other loss 10014.182
result 1 [11.97  7.93  1.77] neuron -780.4855 -0.30917284
e 540 loss -5.1298504 target loss -2441.5955 other loss -207719.88 tv loss 4026.4392
next layer loss target loss 0.0 other loss 10014.253
result 1 [11.96  7.93  1.77] neuron -780.47217 -0.30919075
e 550 loss -5.1300488 target loss -2441.589 other loss -207722.17 tv loss 4026.3777
next layer loss target loss 0.0 other loss 10014.086
result 1 [11.97  7.93  1.77] neuron -780.4766 -0.309213
e 560 loss -5.1302376 target loss -2441.58 other loss -207723.14 tv loss 4026.3447
next layer loss target loss 0.0 other loss 10014.021
result 1 [11.97  7.93  1.77] neuron -780.4802 -0.30920392
e 570 loss -5.1304207 target loss -2441.5479 other loss -207725.33 tv loss 4026.2957
next layer loss target loss 0.0 other loss 10014.188
result 1 [11.97  7.93  1.77] neuron -780.4752 -0.30919442
e 580 loss -5.130598 target loss -2441.5198 other loss -207731.27 tv loss 4026.4075
next layer loss target loss 0.0 other loss 10014.5
result 1 [11.97  7.93  1.77] neuron -780.4619 -0.30916625
e 590 loss -5.1307716 target loss -2441.4805 other loss -207735.86 tv loss 4026.4993
next layer loss target loss 0.0 other loss 10014.846
result 1 [11.97  7.93  1.77] neuron -780.44446 -0.3091323
e 600 loss -5.130934 target loss -2441.4385 other loss -207738.67 tv loss 4026.5122
next layer loss target loss 0.0 other loss 10015.183
result 1 [11.96  7.93  1.77] neuron -780.4246 -0.3091023
e 610 loss -5.131098 target loss -2441.3872 other loss -207740.05 tv loss 4026.5002
next layer loss target loss 0.0 other loss 10015.478
result 1 [11.96  7.93  1.77] neuron -780.39734 -0.30908567
e 620 loss -5.131254 target loss -2441.3408 other loss -207740.12 tv loss 4026.5596
next layer loss target loss 0.0 other loss 10015.745
result 1 [11.96  7.93  1.77] neuron -780.3655 -0.30905694
e 630 loss -5.131403 target loss -2441.2905 other loss -207745.58 tv loss 4026.608
next layer loss target loss 0.0 other loss 10016.253
result 1 [11.96  7.93  1.77] neuron -780.3415 -0.30903062
e 640 loss -5.131548 target loss -2441.2578 other loss -207746.11 tv loss 4026.6123
next layer loss target loss 0.0 other loss 10016.287
result 1 [11.96  7.93  1.77] neuron -780.3262 -0.30902258
e 650 loss -5.131691 target loss -2441.219 other loss -207752.52 tv loss 4026.7437
next layer loss target loss 0.0 other loss 10016.849
result 1 [11.96  7.93  1.77] neuron -780.31244 -0.3089744
e 660 loss -5.1318245 target loss -2441.1748 other loss -207755.66 tv loss 4026.8162
next layer loss target loss 0.0 other loss 10017.19
result 1 [11.96  7.93  1.77] neuron -780.2878 -0.3089533
e 670 loss -5.1319675 target loss -2441.1216 other loss -207757.44 tv loss 4026.8083
next layer loss target loss 0.0 other loss 10017.662
result 1 [11.96  7.93  1.77] neuron -780.26044 -0.30893183
e 680 loss -5.132105 target loss -2441.0989 other loss -207760.0 tv loss 4026.8926
next layer loss target loss 0.0 other loss 10017.893
result 1 [11.96  7.93  1.77] neuron -780.24475 -0.30891448
e 690 loss -5.132242 target loss -2441.0635 other loss -207764.06 tv loss 4026.9536
next layer loss target loss 0.0 other loss 10018.327
result 1 [11.96  7.93  1.77] neuron -780.2261 -0.3088974
e 700 loss -5.1323624 target loss -2441.0366 other loss -207764.95 tv loss 4027.004
next layer loss target loss 0.0 other loss 10018.489
result 1 [11.96  7.93  1.77] neuron -780.2084 -0.30888215
e 710 loss -5.1324806 target loss -2440.9878 other loss -207767.84 tv loss 4027.046
next layer loss target loss 0.0 other loss 10019.033
result 1 [11.96  7.93  1.77] neuron -780.1858 -0.30884033
e 720 loss -5.132593 target loss -2440.9595 other loss -207769.77 tv loss 4027.074
next layer loss target loss 0.0 other loss 10019.296
result 1 [11.96  7.93  1.77] neuron -780.1693 -0.30881798
e 730 loss -5.132715 target loss -2440.9248 other loss -207771.8 tv loss 4027.1025
next layer loss target loss 0.0 other loss 10019.705
result 1 [11.96  7.93  1.77] neuron -780.15283 -0.3087886
e 740 loss -5.1328278 target loss -2440.9026 other loss -207771.38 tv loss 4027.1619
next layer loss target loss 0.0 other loss 10019.773
result 1 [11.96  7.93  1.77] neuron -780.13824 -0.30877534
e 750 loss -5.1329384 target loss -2440.8691 other loss -207768.67 tv loss 4027.0393
next layer loss target loss 0.0 other loss 10019.839
result 1 [11.96  7.93  1.77] neuron -780.12317 -0.30878612
e 760 loss -5.133047 target loss -2440.8577 other loss -207766.64 tv loss 4026.9556
next layer loss target loss 0.0 other loss 10019.779
result 1 [11.96  7.93  1.77] neuron -780.1207 -0.3087906
e 770 loss -5.1331596 target loss -2440.8499 other loss -207766.16 tv loss 4026.9004
next layer loss target loss 0.0 other loss 10019.815
result 1 [11.96  7.93  1.77] neuron -780.11475 -0.30878767
e 780 loss -5.1332664 target loss -2440.817 other loss -207766.34 tv loss 4026.8667
next layer loss target loss 0.0 other loss 10020.046
result 1 [11.96  7.93  1.77] neuron -780.0963 -0.30878305
e 790 loss -5.133358 target loss -2440.7988 other loss -207770.1 tv loss 4026.933
next layer loss target loss 0.0 other loss 10020.288
result 1 [11.96  7.93  1.77] neuron -780.0879 -0.308771
e 800 loss -5.133457 target loss -2440.7932 other loss -207772.88 tv loss 4027.0225
next layer loss target loss 0.0 other loss 10020.4795
result 1 [11.96  7.93  1.77] neuron -780.08545 -0.30874822
e 810 loss -5.1335506 target loss -2440.767 other loss -207775.34 tv loss 4027.035
next layer loss target loss 0.0 other loss 10020.774
result 1 [11.96  7.93  1.77] neuron -780.07086 -0.3087511
e 820 loss -5.1336575 target loss -2440.7378 other loss -207777.72 tv loss 4027.1055
next layer loss target loss 0.0 other loss 10021.05
result 1 [11.96  7.93  1.77] neuron -780.05396 -0.30873904
e 830 loss -5.1337414 target loss -2440.729 other loss -207773.33 tv loss 4027.105
next layer loss target loss 0.0 other loss 10020.879
result 1 [11.96  7.93  1.77] neuron -780.0442 -0.30873042
e 840 loss -5.133833 target loss -2440.706 other loss -207776.0 tv loss 4027.116
next layer loss target loss 0.0 other loss 10021.178
result 1 [11.96  7.93  1.77] neuron -780.0314 -0.30873206
e 850 loss -5.1339283 target loss -2440.6921 other loss -207775.11 tv loss 4027.1465
next layer loss target loss 0.0 other loss 10021.165
result 1 [11.96  7.93  1.77] neuron -780.0221 -0.30874372
e 860 loss -5.134014 target loss -2440.672 other loss -207778.36 tv loss 4027.1982
next layer loss target loss 0.0 other loss 10021.483
result 1 [11.96  7.93  1.77] neuron -780.0113 -0.3087422
e 870 loss -5.1340885 target loss -2440.647 other loss -207781.72 tv loss 4027.2786
next layer loss target loss 0.0 other loss 10021.887
result 1 [11.96  7.93  1.77] neuron -779.9962 -0.3087238
e 880 loss -5.13418 target loss -2440.618 other loss -207781.98 tv loss 4027.3513
next layer loss target loss 0.0 other loss 10022.136
result 1 [11.95  7.93  1.76] neuron -779.9765 -0.30870318
e 890 loss -5.134262 target loss -2440.5747 other loss -207784.73 tv loss 4027.3481
next layer loss target loss 0.0 other loss 10022.712
result 1 [11.95  7.93  1.76] neuron -779.95917 -0.30868155
e 900 loss -5.134348 target loss -2440.5254 other loss -207789.92 tv loss 4027.441
next layer loss target loss 0.0 other loss 10023.501
result 1 [11.95  7.93  1.76] neuron -779.93414 -0.30862305
e 910 loss -5.1344204 target loss -2440.4678 other loss -207792.19 tv loss 4027.4277
next layer loss target loss 0.0 other loss 10024.129
result 1 [11.95  7.93  1.76] neuron -779.9072 -0.3085958
e 920 loss -5.1344986 target loss -2440.4675 other loss -207792.81 tv loss 4027.464
next layer loss target loss 0.0 other loss 10024.193
result 1 [11.95  7.93  1.76] neuron -779.9061 -0.30860093
e 930 loss -5.134573 target loss -2440.439 other loss -207797.66 tv loss 4027.554
next layer loss target loss 0.0 other loss 10024.749
result 1 [11.95  7.93  1.76] neuron -779.888 -0.30856076
e 940 loss -5.1346436 target loss -2440.4302 other loss -207799.27 tv loss 4027.5806
next layer loss target loss 0.0 other loss 10024.951
result 1 [11.95  7.93  1.76] neuron -779.8828 -0.3085457
e 950 loss -5.134712 target loss -2440.4036 other loss -207800.61 tv loss 4027.5525
next layer loss target loss 0.0 other loss 10025.223
result 1 [11.95  7.93  1.76] neuron -779.8711 -0.3085336
e 960 loss -5.134783 target loss -2440.392 other loss -207799.8 tv loss 4027.5615
next layer loss target loss 0.0 other loss 10025.276
result 1 [11.95  7.93  1.76] neuron -779.8626 -0.3085312
e 970 loss -5.1348457 target loss -2440.342 other loss -207802.42 tv loss 4027.5645
next layer loss target loss 0.0 other loss 10025.867
result 1 [11.95  7.93  1.76] neuron -779.83716 -0.3085044
e 980 loss -5.1349106 target loss -2440.3284 other loss -207804.52 tv loss 4027.6108
next layer loss target loss 0.0 other loss 10026.275
result 1 [11.95  7.93  1.76] neuron -779.82806 -0.3084844
e 990 loss -5.1349792 target loss -2440.2917 other loss -207806.94 tv loss 4027.687
next layer loss target loss 0.0 other loss 10026.749
result 1 [11.95  7.93  1.76] neuron -779.8021 -0.3084359
RE filter conv2d_3 20 RE acc 0.3333333333333333
e 0 loss 0.628788 target loss -3062.1497 other loss -27102.744 tv loss 3976.1335
next layer loss target loss 0.0 other loss 100022.91
result 1 [12.2   8.22  1.93] neuron -968.2983 -0.38476205
e 10 loss -1.866087 target loss -2642.9448 other loss -25023.32 tv loss 3851.6685
next layer loss target loss 0.0 other loss 97216.17
result 1 [11.35  7.5   1.7 ] neuron -827.7055 -0.15376997
e 20 loss -3.8747234 target loss -2274.629 other loss -23867.05 tv loss 3728.506
next layer loss target loss 0.08092624 other loss 96678.53
result 1 [10.    5.95  1.69] neuron -685.67255 0.04391694
e 30 loss -5.3951836 target loss -1975.0082 other loss -23856.117 tv loss 3625.7239
next layer loss target loss 2.406104 other loss 98834.67
result 1 [8.46 5.29 1.77] neuron -565.781 0.18114018
e 40 loss -6.742674 target loss -1706.5183 other loss -24168.764 tv loss 3530.7297
next layer loss target loss 11.132404 other loss 102514.28
result 0 [7.07 4.8  1.93] neuron -462.5033 0.28542608
e 50 loss -8.115684 target loss -1469.6174 other loss -24828.771 tv loss 3423.8643
next layer loss target loss 31.481405 other loss 106705.44
result 0 [6.31 4.18 2.19] neuron -376.83008 0.31601435
e 60 loss -9.39644 target loss -1267.7488 other loss -25478.482 tv loss 3307.7292
next layer loss target loss 54.61692 other loss 110492.92
result 0 [5.94 3.76 2.46] neuron -307.4466 0.33546704
e 70 loss -10.497389 target loss -1099.4146 other loss -26049.28 tv loss 3201.291
next layer loss target loss 74.736404 other loss 113708.06
result 0 [5.86 3.39 2.67] neuron -253.09174 0.35615677
e 80 loss -11.381048 target loss -961.90894 other loss -26551.803 tv loss 3102.7256
next layer loss target loss 92.30809 other loss 116317.07
result 0 [6.06 3.11 2.8 ] neuron -212.78577 0.36831957
e 90 loss -19944.805 target loss -1116.7863 other loss -29623.258 tv loss 3195.7559
next layer loss target loss 54.244957 other loss 115766.484
result 1 [6.78 3.63 2.74] neuron -265.41675 0.32192653
e 100 loss -9.254533 target loss -1222.093 other loss -26056.666 tv loss 3353.6685
next layer loss target loss 52.30217 other loss 112159.51
result 0 [6.03 3.22 2.54] neuron -286.70795 0.32538688
e 110 loss -8.515927 target loss -1261.779 other loss -24935.066 tv loss 3399.6743
next layer loss target loss 51.523945 other loss 111024.58
result 0 [5.83 3.22 2.44] neuron -295.5979 0.33713406
e 120 loss -8.289528 target loss -1273.688 other loss -24570.695 tv loss 3414.8596
next layer loss target loss 51.48119 other loss 110699.42
result 0 [5.77 3.22 2.41] neuron -297.9441 0.34043747
e 130 loss -8.25028 target loss -1275.0648 other loss -24469.295 tv loss 3419.0537
next layer loss target loss 51.80412 other loss 110665.08
result 0 [5.75 3.21 2.4 ] neuron -297.67014 0.34196728
e 140 loss -8.279883 target loss -1272.5009 other loss -24462.96 tv loss 3419.1555
next layer loss target loss 52.26271 other loss 110737.33
result 0 [5.75 3.21 2.4 ] neuron -296.38974 0.3429594
e 150 loss -8.335593 target loss -1268.4376 other loss -24492.424 tv loss 3417.7334
next layer loss target loss 52.777767 other loss 110850.83
result 0 [5.76 3.2  2.4 ] neuron -294.71594 0.34375352
e 160 loss -8.401943 target loss -1263.7668 other loss -24536.36 tv loss 3415.6787
next layer loss target loss 53.32305 other loss 110982.03
result 0 [5.76 3.19 2.4 ] neuron -292.87445 0.34447193
e 170 loss -8.473147 target loss -1258.8242 other loss -24587.0 tv loss 3413.3716
next layer loss target loss 53.88562 other loss 111122.08
result 0 [5.77 3.18 2.4 ] neuron -290.95752 0.3451584
e 180 loss -8.546797 target loss -1253.761 other loss -24641.297 tv loss 3410.935
next layer loss target loss 54.450565 other loss 111266.66
result 0 [5.78 3.17 2.4 ] neuron -289.00482 0.34580308
e 190 loss -8.622096 target loss -1248.6233 other loss -24698.059 tv loss 3408.4238
next layer loss target loss 55.016396 other loss 111414.53
result 0 [5.79 3.17 2.41] neuron -287.0338 0.34639955
e 200 loss -8.698849 target loss -1243.4279 other loss -24757.121 tv loss 3405.8643
next layer loss target loss 55.57768 other loss 111565.33
result 0 [5.8  3.16 2.41] neuron -285.04413 0.3468336
e 210 loss -8.776735 target loss -1238.1907 other loss -24818.441 tv loss 3403.2766
next layer loss target loss 56.133312 other loss 111719.06
result 0 [5.81 3.15 2.41] neuron -283.04236 0.34696478
e 220 loss -8.855638 target loss -1232.9177 other loss -24881.803 tv loss 3400.6514
next layer loss target loss 56.687386 other loss 111875.516
result 0 [5.82 3.14 2.41] neuron -281.03564 0.34678203
e 230 loss -8.935838 target loss -1227.6101 other loss -24947.281 tv loss 3397.961
next layer loss target loss 57.239986 other loss 112034.484
result 0 [5.83 3.13 2.41] neuron -279.0247 0.34656936
e 240 loss -9.017214 target loss -1222.2721 other loss -25014.91 tv loss 3395.2412
next layer loss target loss 57.786533 other loss 112196.0
result 0 [5.84 3.12 2.42] neuron -277.00104 0.34632707
e 250 loss -9.09942 target loss -1216.9011 other loss -25084.762 tv loss 3392.4827
next layer loss target loss 58.340214 other loss 112360.516
result 0 [5.85 3.11 2.42] neuron -274.96277 0.3460551
e 260 loss -9.182198 target loss -1211.5103 other loss -25156.676 tv loss 3389.683
next layer loss target loss 58.89105 other loss 112527.5
result 0 [5.85 3.11 2.42] neuron -272.92804 0.34571224
e 270 loss -9.265551 target loss -1206.1055 other loss -25230.646 tv loss 3386.8652
next layer loss target loss 59.44531 other loss 112696.77
result 0 [5.86 3.1  2.43] neuron -270.89667 0.345338
e 280 loss -9.349592 target loss -1200.6854 other loss -25306.742 tv loss 3383.9927
next layer loss target loss 59.995853 other loss 112868.09
result 0 [5.87 3.1  2.43] neuron -268.8687 0.3449365
e 290 loss -9.434007 target loss -1195.2573 other loss -25384.922 tv loss 3381.1006
next layer loss target loss 60.551617 other loss 113041.35
result 0 [5.89 3.09 2.44] neuron -266.83923 0.34450763
e 300 loss -9.5187435 target loss -1189.8262 other loss -25465.117 tv loss 3378.1523
next layer loss target loss 61.108505 other loss 113216.59
result 0 [5.9  3.09 2.44] neuron -264.82153 0.34405345
e 310 loss -9.604079 target loss -1184.377 other loss -25547.35 tv loss 3375.1733
next layer loss target loss 61.662464 other loss 113394.4
result 0 [5.91 3.09 2.45] neuron -262.80255 0.34357387
e 320 loss -9.689546 target loss -1178.9124 other loss -25631.566 tv loss 3372.0732
next layer loss target loss 62.22492 other loss 113574.15
result 0 [5.92 3.08 2.45] neuron -260.77676 0.3430702
e 330 loss -9.77516 target loss -1173.4316 other loss -25717.617 tv loss 3368.8716
next layer loss target loss 62.78423 other loss 113755.46
result 0 [5.94 3.08 2.46] neuron -258.7483 0.34254247
e 340 loss -9.86056 target loss -1167.9543 other loss -25805.584 tv loss 3365.6145
next layer loss target loss 63.344364 other loss 113937.95
result 0 [5.96 3.08 2.46] neuron -256.71814 0.341994
e 350 loss -9.946269 target loss -1162.4673 other loss -25895.676 tv loss 3362.316
next layer loss target loss 63.91708 other loss 114122.44
result 0 [5.98 3.08 2.47] neuron -254.69032 0.34142703
e 360 loss -10.032031 target loss -1156.9585 other loss -25987.984 tv loss 3359.0298
next layer loss target loss 64.48592 other loss 114309.3
result 0 [6.   3.08 2.47] neuron -252.65837 0.34084147
e 370 loss -10.117489 target loss -1151.4465 other loss -26082.346 tv loss 3355.6465
next layer loss target loss 65.06229 other loss 114497.94
result 0 [6.02 3.07 2.47] neuron -250.62207 0.340239
e 380 loss -10.202847 target loss -1145.9431 other loss -26178.346 tv loss 3352.1929
next layer loss target loss 65.63053 other loss 114687.016
result 0 [6.05 3.07 2.48] neuron -248.59879 0.33962065
e 390 loss -10.287415 target loss -1140.4481 other loss -26275.94 tv loss 3348.6868
next layer loss target loss 66.19345 other loss 114877.41
result 0 [6.07 3.07 2.48] neuron -246.57982 0.33898693
e 400 loss -10.370712 target loss -1134.9934 other loss -26374.566 tv loss 3345.099
next layer loss target loss 66.748856 other loss 115067.17
result 0 [6.1  3.07 2.48] neuron -244.59258 0.33939475
e 410 loss -10.452725 target loss -1129.5737 other loss -26474.254 tv loss 3341.4548
next layer loss target loss 67.29477 other loss 115256.69
result 0 [6.12 3.07 2.49] neuron -242.62033 0.34100825
e 420 loss -10.533552 target loss -1124.1548 other loss -26575.207 tv loss 3337.7107
next layer loss target loss 67.84888 other loss 115446.53
result 1 [6.15 3.07 2.49] neuron -240.65262 0.34264272
e 430 loss -10.612754 target loss -1118.7498 other loss -26677.078 tv loss 3333.7905
next layer loss target loss 68.40207 other loss 115635.76
result 1 [6.17 3.07 2.49] neuron -238.7018 0.34430122
e 440 loss -10.690679 target loss -1113.3488 other loss -26779.672 tv loss 3329.6785
next layer loss target loss 68.95617 other loss 115824.42
result 1 [6.2  3.08 2.49] neuron -236.77031 0.3461926
e 450 loss -10.767336 target loss -1107.9376 other loss -26882.904 tv loss 3325.3333
next layer loss target loss 69.51907 other loss 116012.66
result 1 [6.22 3.08 2.5 ] neuron -234.84415 0.34811842
e 460 loss -10.842568 target loss -1102.5035 other loss -26986.662 tv loss 3320.7642
next layer loss target loss 70.07373 other loss 116201.19
result 1 [6.25 3.08 2.5 ] neuron -232.91014 0.3500737
e 470 loss -10.915505 target loss -1097.065 other loss -27090.332 tv loss 3316.0457
next layer loss target loss 70.62682 other loss 116390.086
result 1 [6.27 3.08 2.5 ] neuron -230.97548 0.35205048
e 480 loss -10.985219 target loss -1091.6672 other loss -27192.82 tv loss 3311.2617
next layer loss target loss 71.17487 other loss 116577.89
result 1 [6.3  3.09 2.5 ] neuron -229.0513 0.35404104
e 490 loss -11.051492 target loss -1086.3296 other loss -27293.258 tv loss 3306.503
next layer loss target loss 71.71606 other loss 116763.29
result 1 [6.32 3.09 2.5 ] neuron -227.15039 0.35604227
e 500 loss -11.1138315 target loss -1081.0559 other loss -27391.043 tv loss 3301.795
next layer loss target loss 72.25497 other loss 116946.22
result 1 [6.35 3.1  2.5 ] neuron -225.27255 0.35805398
e 510 loss -11.172174 target loss -1075.8392 other loss -27485.383 tv loss 3297.1099
next layer loss target loss 72.79733 other loss 117125.96
result 1 [6.38 3.1  2.5 ] neuron -223.4076 0.3600725
e 520 loss -11.226699 target loss -1070.6865 other loss -27575.625 tv loss 3292.4485
next layer loss target loss 73.35048 other loss 117301.37
result 1 [6.4 3.1 2.5] neuron -221.55705 0.36210185
e 530 loss -11.277887 target loss -1065.5879 other loss -27661.52 tv loss 3287.7773
next layer loss target loss 73.90918 other loss 117472.39
result 1 [6.43 3.1  2.5 ] neuron -219.71448 0.36414653
e 540 loss -11.326416 target loss -1060.5052 other loss -27743.049 tv loss 3283.145
next layer loss target loss 74.48382 other loss 117640.28
result 1 [6.45 3.11 2.5 ] neuron -217.86327 0.36622053
e 550 loss -11.372535 target loss -1055.4252 other loss -27820.094 tv loss 3278.5452
next layer loss target loss 75.085175 other loss 117805.56
result 1 [6.48 3.11 2.5 ] neuron -215.99655 0.36832613
e 560 loss -11.416179 target loss -1050.3818 other loss -27892.314 tv loss 3274.0059
next layer loss target loss 75.69272 other loss 117966.516
result 1 [6.5  3.11 2.5 ] neuron -214.12643 0.3704517
e 570 loss -11.458678 target loss -1045.3477 other loss -27960.145 tv loss 3269.5122
next layer loss target loss 76.308945 other loss 118124.3
result 1 [6.53 3.11 2.5 ] neuron -212.24167 0.37260395
e 580 loss -11.500025 target loss -1040.3116 other loss -28023.773 tv loss 3265.029
next layer loss target loss 76.93614 other loss 118279.31
result 1 [6.55 3.1  2.5 ] neuron -210.34506 0.37479192
e 590 loss -11.540622 target loss -1035.2903 other loss -28083.451 tv loss 3260.5662
next layer loss target loss 77.56485 other loss 118431.08
result 1 [6.57 3.1  2.5 ] neuron -208.44003 0.37700588
e 600 loss -11.580625 target loss -1030.2661 other loss -28139.771 tv loss 3256.122
next layer loss target loss 78.20159 other loss 118580.94
result 1 [6.59 3.09 2.49] neuron -206.52649 0.37920535
e 610 loss -11.620275 target loss -1025.2345 other loss -28193.094 tv loss 3251.6934
next layer loss target loss 78.86126 other loss 118729.12
result 1 [6.61 3.09 2.49] neuron -204.60777 0.38126075
e 620 loss -11.659151 target loss -1020.21906 other loss -28243.59 tv loss 3247.2903
next layer loss target loss 79.52023 other loss 118875.06
result 1 [6.63 3.08 2.49] neuron -202.69197 0.3833292
e 630 loss -11.69729 target loss -1015.2459 other loss -28291.408 tv loss 3242.9138
next layer loss target loss 80.17085 other loss 119018.09
result 1 [6.65 3.08 2.49] neuron -200.79633 0.38539934
e 640 loss -11.735159 target loss -1010.30457 other loss -28336.953 tv loss 3238.5483
next layer loss target loss 80.81662 other loss 119158.734
result 1 [6.66 3.07 2.49] neuron -198.91571 0.3874756
e 650 loss -11.77311 target loss -1005.3622 other loss -28380.748 tv loss 3234.1921
next layer loss target loss 81.47534 other loss 119298.39
result 1 [6.68 3.06 2.49] neuron -197.03653 0.3895691
e 660 loss -11.810506 target loss -1000.4526 other loss -28422.738 tv loss 3229.8345
next layer loss target loss 82.12093 other loss 119435.8
result 1 [6.69 3.05 2.49] neuron -195.18341 0.39167
e 670 loss -11.847262 target loss -995.5825 other loss -28462.938 tv loss 3225.495
next layer loss target loss 82.76604 other loss 119570.625
result 1 [6.71 3.05 2.48] neuron -193.35983 0.39376783
e 680 loss -11.883564 target loss -990.7379 other loss -28501.734 tv loss 3221.1667
next layer loss target loss 83.41937 other loss 119703.734
result 1 [6.73 3.04 2.48] neuron -191.5515 0.39586198
e 690 loss -11.919661 target loss -985.9049 other loss -28539.398 tv loss 3216.8716
next layer loss target loss 84.07432 other loss 119835.805
result 1 [6.74 3.03 2.48] neuron -189.75168 0.3979593
e 700 loss -11.955565 target loss -981.06824 other loss -28576.271 tv loss 3212.5845
next layer loss target loss 84.728645 other loss 119967.625
result 1 [6.76 3.02 2.48] neuron -187.95834 0.40006268
e 710 loss -11.990914 target loss -976.2569 other loss -28612.203 tv loss 3208.3032
next layer loss target loss 85.36009 other loss 120097.76
result 1 [6.78 3.02 2.48] neuron -186.18103 0.40156305
e 720 loss -12.026186 target loss -971.46436 other loss -28647.281 tv loss 3204.062
next layer loss target loss 85.97518 other loss 120226.484
result 1 [6.79 3.01 2.48] neuron -184.4116 0.40319508
e 730 loss -12.061315 target loss -966.6731 other loss -28681.857 tv loss 3199.8777
next layer loss target loss 86.58935 other loss 120355.016
result 1 [6.81 3.   2.48] neuron -182.64142 0.4047861
e 740 loss -12.096241 target loss -961.9061 other loss -28715.77 tv loss 3195.7559
next layer loss target loss 87.193054 other loss 120482.11
result 1 [6.83 2.99 2.48] neuron -180.88336 0.40637332
e 750 loss -12.131075 target loss -957.1451 other loss -28749.166 tv loss 3191.6746
next layer loss target loss 87.80279 other loss 120608.695
result 1 [6.85 2.98 2.48] neuron -179.13477 0.407964
e 760 loss -12.165841 target loss -952.3925 other loss -28782.068 tv loss 3187.6
next layer loss target loss 88.41782 other loss 120734.99
result 1 [6.86 2.97 2.48] neuron -177.39326 0.40968013
e 770 loss -12.200145 target loss -947.66907 other loss -28814.191 tv loss 3183.5137
next layer loss target loss 89.01335 other loss 120859.63
result 1 [6.88 2.96 2.48] neuron -175.66992 0.41154408
e 780 loss -12.233929 target loss -942.9717 other loss -28845.73 tv loss 3179.459
next layer loss target loss 89.604355 other loss 120983.16
result 1 [6.9  2.95 2.48] neuron -173.9639 0.41339856
e 790 loss -12.267407 target loss -938.29175 other loss -28876.688 tv loss 3175.4133
next layer loss target loss 90.19443 other loss 121105.96
result 1 [6.92 2.93 2.48] neuron -172.27612 0.41520345
e 800 loss -12.300752 target loss -933.6372 other loss -28907.105 tv loss 3171.3782
next layer loss target loss 90.76698 other loss 121227.195
result 1 [6.93 2.92 2.48] neuron -170.61835 0.4153151
e 810 loss -12.33394 target loss -928.9989 other loss -28936.992 tv loss 3167.298
next layer loss target loss 91.33051 other loss 121347.234
result 1 [6.95 2.91 2.48] neuron -168.98398 0.4153639
e 820 loss -12.366848 target loss -924.3843 other loss -28966.4 tv loss 3163.2188
next layer loss target loss 91.8849 other loss 121466.29
result 1 [6.97 2.9  2.48] neuron -167.37094 0.41540986
e 830 loss -12.399443 target loss -919.801 other loss -28995.264 tv loss 3159.1685
next layer loss target loss 92.42926 other loss 121583.92
result 1 [6.99 2.89 2.48] neuron -165.79053 0.41545254
e 840 loss -12.431962 target loss -915.231 other loss -29023.75 tv loss 3155.1406
next layer loss target loss 92.97676 other loss 121701.02
result 1 [7.01 2.88 2.48] neuron -164.22583 0.41549194
e 850 loss -12.464358 target loss -910.66315 other loss -29051.988 tv loss 3151.135
next layer loss target loss 93.51936 other loss 121817.65
result 1 [7.02 2.88 2.48] neuron -162.67017 0.41552967
e 860 loss -12.496491 target loss -906.11096 other loss -29079.875 tv loss 3147.1265
next layer loss target loss 94.051544 other loss 121933.55
result 1 [7.04 2.87 2.48] neuron -161.12273 0.4156708
e 870 loss -12.52891 target loss -901.55286 other loss -29107.623 tv loss 3143.1348
next layer loss target loss 94.578445 other loss 122049.72
result 1 [7.06 2.86 2.48] neuron -159.58276 0.41581953
e 880 loss -12.561261 target loss -896.99805 other loss -29135.057 tv loss 3139.0945
next layer loss target loss 95.09445 other loss 122165.06
result 1 [7.08 2.85 2.48] neuron -158.05255 0.4159664
e 890 loss -12.593936 target loss -892.4235 other loss -29162.44 tv loss 3135.046
next layer loss target loss 95.60809 other loss 122280.66
result 1 [7.1  2.84 2.48] neuron -156.52429 0.4161117
e 900 loss -12.62664 target loss -887.82275 other loss -29189.744 tv loss 3130.9685
next layer loss target loss 96.13432 other loss 122396.945
result 1 [7.11 2.83 2.48] neuron -154.98978 0.41625744
e 910 loss -12.6590805 target loss -883.2234 other loss -29216.676 tv loss 3126.8552
next layer loss target loss 96.66426 other loss 122512.67
result 1 [7.13 2.82 2.48] neuron -153.46109 0.41638553
e 920 loss -12.691299 target loss -878.65186 other loss -29243.133 tv loss 3122.749
next layer loss target loss 97.185776 other loss 122626.875
result 1 [7.15 2.81 2.48] neuron -151.95526 0.41650695
e 930 loss -12.723626 target loss -874.09595 other loss -29269.504 tv loss 3118.6777
next layer loss target loss 97.69826 other loss 122740.766
result 1 [7.17 2.8  2.48] neuron -150.45828 0.4166268
e 940 loss -12.755955 target loss -869.56067 other loss -29295.586 tv loss 3114.6523
next layer loss target loss 98.20208 other loss 122853.94
result 1 [7.19 2.79 2.48] neuron -148.97157 0.41674572
e 950 loss -12.788164 target loss -865.03046 other loss -29321.266 tv loss 3110.6216
next layer loss target loss 98.70297 other loss 122966.21
result 1 [7.21 2.78 2.48] neuron -147.4926 0.41686332
e 960 loss -12.820257 target loss -860.50494 other loss -29346.607 tv loss 3106.608
next layer loss target loss 99.199585 other loss 123077.89
result 1 [7.23 2.77 2.49] neuron -146.02495 0.41697168
e 970 loss -12.852165 target loss -855.9773 other loss -29371.742 tv loss 3102.5925
next layer loss target loss 99.69463 other loss 123189.4
result 1 [7.25 2.76 2.49] neuron -144.56436 0.4171459
e 980 loss -12.883881 target loss -851.44666 other loss -29396.615 tv loss 3098.588
next layer loss target loss 100.19014 other loss 123300.58
result 1 [7.27 2.76 2.49] neuron -143.11295 0.4175139
e 990 loss -12.915606 target loss -846.8977 other loss -29421.234 tv loss 3094.5713
next layer loss target loss 100.6982 other loss 123412.05
result 1 [7.29 2.75 2.49] neuron -141.66533 0.4179144
RE filter conv2d_2 74 RE acc 0.3333333333333333
e 0 loss -29.196297 target loss -556.25256 other loss -29608.64 tv loss 3976.1335
next layer loss target loss 476.5815 other loss 99546.33
result 1 [12.2   8.22  1.93] neuron -168.436 2.3229957
e 10 loss -30.717905 target loss -402.21185 other loss -30689.121 tv loss 4078.2822
next layer loss target loss 547.139 other loss 101792.57
result 1 [12.26  8.6   1.85] neuron -110.20529 2.5003128
e 20 loss -31.87078 target loss -302.70874 other loss -32315.418 tv loss 4169.0254
next layer loss target loss 595.51843 other loss 104347.78
result 1 [12.03  8.86  1.76] neuron -73.357735 2.6404746
e 30 loss -32.740135 target loss -205.70155 other loss -33822.7 tv loss 4246.4355
next layer loss target loss 644.77844 other loss 106857.25
result 1 [11.66  9.02  1.71] neuron -37.253963 2.7822933
e 40 loss -33.46695 target loss -116.83053 other loss -35235.53 tv loss 4315.613
next layer loss target loss 691.1522 other loss 109310.66
result 1 [11.37  9.15  1.68] neuron -4.163887 2.914831
e 50 loss -34.106926 target loss -37.022453 other loss -36439.312 tv loss 4377.6113
next layer loss target loss 733.75195 other loss 111616.54
result 1 [11.05  9.23  1.65] neuron 25.747974 3.0184278
e 60 loss -34.667095 target loss 32.317383 other loss -37445.375 tv loss 4434.505
next layer loss target loss 771.0598 other loss 113747.93
result 1 [10.84  9.16  1.62] neuron 52.10624 3.1012836
e 70 loss -35.159904 target loss 90.98338 other loss -38317.85 tv loss 4488.1284
next layer loss target loss 803.6355 other loss 115714.375
result 1 [10.65  8.97  1.6 ] neuron 74.849945 3.175522
e 80 loss -35.595665 target loss 141.70886 other loss -39082.242 tv loss 4539.041
next layer loss target loss 832.5379 other loss 117529.61
result 1 [10.51  8.79  1.59] neuron 94.643616 3.2457056
e 90 loss -35.992638 target loss 189.21237 other loss -39855.477 tv loss 4585.8887
next layer loss target loss 859.8109 other loss 119282.5
result 1 [10.46  8.61  1.58] neuron 112.73355 3.3007314
e 100 loss -36.351387 target loss 231.1525 other loss -40582.65 tv loss 4631.3916
next layer loss target loss 884.69183 other loss 120903.25
result 1 [10.52  8.45  1.57] neuron 128.39618 3.3437793
e 110 loss -36.680664 target loss 268.94055 other loss -41153.203 tv loss 4675.3594
next layer loss target loss 907.6212 other loss 122311.84
result 1 [10.56  8.26  1.55] neuron 142.26132 3.3817613
e 120 loss -36.981422 target loss 301.78876 other loss -41522.117 tv loss 4721.2095
next layer loss target loss 928.46497 other loss 123469.28
result 1 [10.56  8.09  1.55] neuron 154.20212 3.4217951
e 130 loss -37.26614 target loss 330.9965 other loss -41698.613 tv loss 4769.6787
next layer loss target loss 947.82263 other loss 124405.93
result 1 [10.52  7.93  1.55] neuron 164.67096 3.4615834
e 140 loss -37.54235 target loss 358.39545 other loss -41879.12 tv loss 4816.359
next layer loss target loss 966.2743 other loss 125292.78
result 1 [10.49  7.79  1.55] neuron 174.28857 3.4979675
e 150 loss -37.811016 target loss 385.34116 other loss -42155.85 tv loss 4861.0557
next layer loss target loss 984.4453 other loss 126232.836
result 1 [10.47  7.7   1.55] neuron 183.53119 3.53319
e 160 loss -38.065704 target loss 410.8462 other loss -42520.523 tv loss 4904.788
next layer loss target loss 1001.99817 other loss 127187.16
result 1 [10.48  7.66  1.55] neuron 192.00705 3.5667531
e 170 loss -38.31126 target loss 435.52615 other loss -42978.434 tv loss 4945.298
next layer loss target loss 1019.17694 other loss 128153.92
result 1 [10.54  7.65  1.56] neuron 199.83401 3.5981925
e 180 loss -38.546593 target loss 458.19907 other loss -43456.258 tv loss 4986.806
next layer loss target loss 1035.567 other loss 129087.99
result 1 [10.62  7.67  1.56] neuron 206.93698 3.6313384
e 190 loss -38.77082 target loss 479.4569 other loss -43843.832 tv loss 5028.7397
next layer loss target loss 1051.2804 other loss 129931.63
result 1 [10.67  7.69  1.56] neuron 213.46562 3.6585896
e 200 loss -38.986504 target loss 500.5792 other loss -44199.113 tv loss 5067.4624
next layer loss target loss 1066.4989 other loss 130733.47
result 1 [10.7   7.67  1.56] neuron 219.79251 3.6833022
e 210 loss -39.196747 target loss 520.58636 other loss -44541.023 tv loss 5106.21
next layer loss target loss 1081.4012 other loss 131493.53
result 1 [10.75  7.67  1.58] neuron 225.61389 3.7074516
e 220 loss -39.39792 target loss 539.327 other loss -44864.812 tv loss 5146.205
next layer loss target loss 1095.7699 other loss 132211.95
result 1 [10.81  7.68  1.58] neuron 231.12125 3.728845
e 230 loss -39.58908 target loss 559.5745 other loss -45167.824 tv loss 5180.2246
next layer loss target loss 1110.1609 other loss 132928.66
result 1 [10.85  7.66  1.59] neuron 236.87476 3.7486627
e 240 loss -39.77561 target loss 578.19434 other loss -45535.242 tv loss 5215.415
next layer loss target loss 1124.2761 other loss 133660.34
result 1 [10.94  7.67  1.6 ] neuron 242.30997 3.774708
e 250 loss -39.9565 target loss 596.63104 other loss -45864.54 tv loss 5250.3047
next layer loss target loss 1138.2716 other loss 134364.53
result 1 [11.01  7.66  1.6 ] neuron 247.86043 3.799958
e 260 loss -40.132492 target loss 614.88055 other loss -46209.426 tv loss 5282.131
next layer loss target loss 1152.0144 other loss 135069.34
result 1 [11.1   7.64  1.61] neuron 253.27393 3.8258984
e 270 loss -40.300877 target loss 632.9621 other loss -46485.133 tv loss 5313.881
next layer loss target loss 1165.4388 other loss 135733.66
result 1 [11.16  7.6   1.6 ] neuron 258.75552 3.8494923
e 280 loss -40.462 target loss 648.70154 other loss -46807.06 tv loss 5345.968
next layer loss target loss 1177.9192 other loss 136384.52
result 1 [11.26  7.6   1.6 ] neuron 263.68805 3.8715317
e 290 loss -40.61801 target loss 666.01575 other loss -47010.742 tv loss 5376.461
next layer loss target loss 1190.5718 other loss 136977.53
result 1 [11.3   7.55  1.59] neuron 268.98535 3.8892019
e 300 loss -40.769783 target loss 682.13715 other loss -47200.4 tv loss 5408.454
next layer loss target loss 1202.8124 other loss 137538.19
result 1 [11.35  7.53  1.58] neuron 273.9599 3.9051511
e 310 loss -40.920815 target loss 697.5688 other loss -47508.242 tv loss 5438.69
next layer loss target loss 1215.1334 other loss 138155.86
result 1 [11.43  7.55  1.57] neuron 278.49268 3.9216082
e 320 loss -41.0699 target loss 713.9582 other loss -47731.523 tv loss 5471.0
next layer loss target loss 1227.8461 other loss 138733.75
result 1 [11.48  7.56  1.56] neuron 283.23172 3.9365008
e 330 loss -41.216377 target loss 728.0234 other loss -47991.81 tv loss 5504.6045
next layer loss target loss 1239.5652 other loss 139291.78
result 1 [11.55  7.59  1.56] neuron 287.38715 3.951546
e 340 loss -41.35823 target loss 742.8577 other loss -48165.02 tv loss 5536.828
next layer loss target loss 1251.2386 other loss 139797.84
result 1 [11.6   7.58  1.56] neuron 291.5331 3.9670293
e 350 loss -41.497726 target loss 756.7188 other loss -48356.21 tv loss 5568.713
next layer loss target loss 1262.3995 other loss 140302.28
result 1 [11.65  7.58  1.56] neuron 295.52127 3.9820364
e 360 loss -41.633152 target loss 768.83655 other loss -48522.83 tv loss 5602.167
next layer loss target loss 1272.7518 other loss 140763.75
result 1 [11.69  7.6   1.57] neuron 299.15344 3.994704
e 370 loss -41.76296 target loss 782.76227 other loss -48663.062 tv loss 5631.731
next layer loss target loss 1283.4729 other loss 141233.94
result 1 [11.72  7.58  1.57] neuron 303.19666 4.0096416
e 380 loss -41.88996 target loss 795.58 other loss -48837.492 tv loss 5662.934
next layer loss target loss 1293.7845 other loss 141721.23
result 1 [11.76  7.59  1.58] neuron 307.20035 4.023003
e 390 loss -42.015198 target loss 809.65735 other loss -49002.83 tv loss 5693.2075
next layer loss target loss 1304.4362 other loss 142226.8
result 1 [11.77  7.58  1.58] neuron 311.59503 4.036857
e 400 loss -42.13939 target loss 823.69995 other loss -49148.656 tv loss 5723.698
next layer loss target loss 1315.0963 other loss 142721.28
result 1 [11.78  7.57  1.59] neuron 315.89474 4.0494456
e 410 loss -42.263752 target loss 837.8551 other loss -49270.848 tv loss 5756.368
next layer loss target loss 1325.8668 other loss 143194.6
result 1 [11.77  7.55  1.59] neuron 320.27487 4.0606613
e 420 loss -42.38819 target loss 852.1558 other loss -49428.727 tv loss 5788.7266
next layer loss target loss 1336.8766 other loss 143684.88
result 1 [11.77  7.54  1.59] neuron 324.56955 4.071845
e 430 loss -42.51023 target loss 866.23065 other loss -49620.156 tv loss 5819.4966
next layer loss target loss 1347.714 other loss 144194.28
result 1 [11.79  7.53  1.6 ] neuron 328.79398 4.082654
e 440 loss -42.628242 target loss 881.4398 other loss -49978.273 tv loss 5842.555
next layer loss target loss 1359.0542 other loss 144832.0
result 1 [11.86  7.52  1.61] neuron 333.26385 4.0982614
e 450 loss -42.745796 target loss 896.24426 other loss -50309.562 tv loss 5868.2856
next layer loss target loss 1370.2689 other loss 145457.64
result 1 [11.91  7.53  1.62] neuron 337.77368 4.1141577
e 460 loss -42.479065 target loss 845.1843 other loss -49718.0 tv loss 5900.413
next layer loss target loss 1350.1578 other loss 144788.34
result 1 [11.81  8.16  1.61] neuron 320.3227 4.1978555
e 470 loss -39.313892 target loss 639.3156 other loss -47492.59 tv loss 5915.883
next layer loss target loss 1247.0276 other loss 142496.67
result 1 [11.75  8.65  1.66] neuron 252.35233 4.2415915
e 480 loss -37.908783 target loss 560.25836 other loss -46921.74 tv loss 5909.819
next layer loss target loss 1205.1464 other loss 141933.9
result 1 [11.78  8.49  1.72] neuron 225.87076 4.2267823
e 490 loss -37.535828 target loss 538.5197 other loss -46710.06 tv loss 5907.722
next layer loss target loss 1192.939 other loss 141665.38
result 1 [11.75  8.42  1.74] neuron 218.65039 4.2196593
e 500 loss -37.57939 target loss 538.6903 other loss -46586.566 tv loss 5907.9795
next layer loss target loss 1192.1704 other loss 141462.39
result 1 [11.72  8.44  1.73] neuron 218.7024 4.218065
e 510 loss -37.77108 target loss 546.6147 other loss -46496.645 tv loss 5908.4844
next layer loss target loss 1195.4823 other loss 141286.0
result 1 [11.69  8.48  1.71] neuron 221.3498 4.21905
e 520 loss -38.009567 target loss 557.119 other loss -46426.79 tv loss 5908.759
next layer loss target loss 1200.1407 other loss 141127.92
result 1 [11.66  8.52  1.69] neuron 224.84186 4.220858
e 530 loss -38.259056 target loss 568.31696 other loss -46368.914 tv loss 5908.3965
next layer loss target loss 1205.1592 other loss 140981.88
result 1 [11.62  8.55  1.67] neuron 228.618 4.2227116
e 540 loss -38.50186 target loss 579.36414 other loss -46330.07 tv loss 5907.3984
next layer loss target loss 1210.0415 other loss 140852.77
result 1 [11.58  8.58  1.65] neuron 232.42638 4.2240696
e 550 loss -38.73458 target loss 590.09875 other loss -46313.85 tv loss 5905.6636
next layer loss target loss 1214.7196 other loss 140745.81
result 1 [11.57  8.59  1.64] neuron 236.14072 4.2226367
e 560 loss -38.958046 target loss 600.603 other loss -46318.117 tv loss 5903.363
next layer loss target loss 1219.29 other loss 140661.06
result 1 [11.56  8.59  1.62] neuron 239.74667 4.2210994
e 570 loss -39.17479 target loss 610.9243 other loss -46338.305 tv loss 5900.674
next layer loss target loss 1223.7195 other loss 140589.84
result 1 [11.55  8.58  1.61] neuron 243.29077 4.219829
e 580 loss -39.38398 target loss 621.0244 other loss -46368.715 tv loss 5897.7876
next layer loss target loss 1227.9929 other loss 140529.44
result 1 [11.55  8.56  1.6 ] neuron 246.7257 4.218395
e 590 loss -39.58634 target loss 630.8818 other loss -46409.195 tv loss 5894.546
next layer loss target loss 1232.1398 other loss 140478.42
result 1 [11.54  8.54  1.59] neuron 250.0793 4.2153754
e 600 loss -39.78421 target loss 640.572 other loss -46457.51 tv loss 5891.0234
next layer loss target loss 1236.1985 other loss 140436.12
result 1 [11.54  8.53  1.58] neuron 253.42471 4.212146
e 610 loss -39.975563 target loss 650.0859 other loss -46514.754 tv loss 5887.5767
next layer loss target loss 1240.1968 other loss 140410.1
result 1 [11.53  8.52  1.57] neuron 256.7292 4.2088714
e 620 loss -40.15995 target loss 659.3261 other loss -46585.03 tv loss 5884.0586
next layer loss target loss 1244.0731 other loss 140399.73
result 1 [11.52  8.51  1.56] neuron 259.96176 4.205798
e 630 loss -40.338417 target loss 668.35846 other loss -46668.773 tv loss 5880.582
next layer loss target loss 1247.8721 other loss 140405.88
result 1 [11.53  8.49  1.55] neuron 263.1168 4.2019114
e 640 loss -40.512535 target loss 677.28345 other loss -46768.55 tv loss 5877.209
next layer loss target loss 1251.6724 other loss 140431.61
result 1 [11.53  8.46  1.54] neuron 266.24402 4.1978855
e 650 loss -40.68122 target loss 686.0767 other loss -46886.637 tv loss 5873.8516
next layer loss target loss 1255.4714 other loss 140480.36
result 1 [11.53  8.43  1.53] neuron 269.31546 4.1940646
e 660 loss -40.84261 target loss 694.6135 other loss -47020.48 tv loss 5870.649
next layer loss target loss 1259.1986 other loss 140548.94
result 1 [11.54  8.39  1.52] neuron 272.32147 4.1907215
e 670 loss -40.99733 target loss 702.9167 other loss -47166.246 tv loss 5867.546
next layer loss target loss 1262.8762 other loss 140635.22
result 1 [11.56  8.35  1.51] neuron 275.29047 4.187615
e 680 loss -41.146877 target loss 711.0395 other loss -47324.945 tv loss 5864.5786
next layer loss target loss 1266.5538 other loss 140739.72
result 1 [11.58  8.31  1.51] neuron 278.2323 4.1848493
e 690 loss -41.291245 target loss 718.9914 other loss -47496.664 tv loss 5861.6885
next layer loss target loss 1270.223 other loss 140860.5
result 1 [11.61  8.27  1.5 ] neuron 281.14325 4.182355
e 700 loss -41.428566 target loss 726.7624 other loss -47674.816 tv loss 5859.0044
next layer loss target loss 1273.896 other loss 140995.05
result 1 [11.63  8.23  1.5 ] neuron 283.99908 4.1801934
e 710 loss -41.555542 target loss 734.3113 other loss -47854.438 tv loss 5856.7676
next layer loss target loss 1277.585 other loss 141141.75
result 1 [11.66  8.2   1.5 ] neuron 286.77832 4.177236
e 720 loss -41.66929 target loss 741.60223 other loss -48026.08 tv loss 5855.3613
next layer loss target loss 1281.2885 other loss 141296.44
result 1 [11.69  8.16  1.5 ] neuron 289.4385 4.173568
e 730 loss -41.769615 target loss 748.5705 other loss -48178.234 tv loss 5854.8833
next layer loss target loss 1284.9489 other loss 141450.88
result 1 [11.72  8.13  1.5 ] neuron 291.95117 4.170088
e 740 loss -41.858334 target loss 755.1552 other loss -48309.01 tv loss 5855.416
next layer loss target loss 1288.5454 other loss 141601.5
result 1 [11.74  8.11  1.5 ] neuron 294.29608 4.167192
e 750 loss -41.93831 target loss 761.3873 other loss -48421.89 tv loss 5856.783
next layer loss target loss 1292.0948 other loss 141749.28
result 1 [11.77  8.09  1.51] neuron 296.4952 4.1651125
e 760 loss -42.01158 target loss 767.3375 other loss -48520.535 tv loss 5858.801
next layer loss target loss 1295.6138 other loss 141895.86
result 1 [11.79  8.07  1.51] neuron 298.58386 4.163664
e 770 loss -42.07926 target loss 773.0154 other loss -48606.773 tv loss 5861.373
next layer loss target loss 1299.0867 other loss 142040.03
result 1 [11.81  8.04  1.51] neuron 300.56998 4.1627326
e 780 loss -42.142212 target loss 778.4654 other loss -48681.984 tv loss 5864.454
next layer loss target loss 1302.509 other loss 142182.27
result 1 [11.82  8.02  1.51] neuron 302.47818 4.1621885
e 790 loss -42.201035 target loss 783.7224 other loss -48746.45 tv loss 5868.0625
next layer loss target loss 1305.8901 other loss 142322.16
result 1 [11.84  8.    1.52] neuron 304.31927 4.161839
e 800 loss -42.256546 target loss 788.8166 other loss -48802.414 tv loss 5872.0693
next layer loss target loss 1309.2268 other loss 142459.92
result 1 [11.85  7.97  1.52] neuron 306.1106 4.1618147
e 810 loss -42.308365 target loss 793.74115 other loss -48853.023 tv loss 5876.2627
next layer loss target loss 1312.479 other loss 142596.25
result 1 [11.86  7.96  1.52] neuron 307.84906 4.162718
e 820 loss -42.356346 target loss 798.4603 other loss -48900.133 tv loss 5880.505
next layer loss target loss 1315.6338 other loss 142730.73
result 1 [11.87  7.94  1.53] neuron 309.50046 4.1637716
e 830 loss -42.400715 target loss 802.9703 other loss -48946.04 tv loss 5884.736
next layer loss target loss 1318.7034 other loss 142864.86
result 1 [11.88  7.92  1.53] neuron 311.06934 4.165006
e 840 loss -42.43638 target loss 806.9772 other loss -49024.07 tv loss 5885.9824
next layer loss target loss 1321.189 other loss 142981.84
result 1 [11.89  7.91  1.54] neuron 312.3609 4.164741
e 850 loss -42.46251 target loss 810.31384 other loss -49114.25 tv loss 5885.243
next layer loss target loss 1323.1003 other loss 143074.08
result 1 [11.92  7.89  1.54] neuron 313.35455 4.163411
e 860 loss -42.485123 target loss 813.3962 other loss -49191.566 tv loss 5884.713
next layer loss target loss 1324.8896 other loss 143158.02
result 1 [11.94  7.88  1.54] neuron 314.25003 4.1623526
e 870 loss -42.505367 target loss 816.29736 other loss -49256.637 tv loss 5884.4204
next layer loss target loss 1326.5897 other loss 143235.33
result 1 [11.96  7.86  1.54] neuron 315.07007 4.161583
e 880 loss -42.52401 target loss 819.05505 other loss -49312.195 tv loss 5884.303
next layer loss target loss 1328.2262 other loss 143308.17
result 1 [11.97  7.85  1.54] neuron 315.83066 4.1611857
e 890 loss -42.541435 target loss 821.6831 other loss -49359.504 tv loss 5884.3467
next layer loss target loss 1329.8038 other loss 143377.02
result 1 [11.99  7.83  1.54] neuron 316.54074 4.160665
e 900 loss -42.55793 target loss 824.19745 other loss -49399.61 tv loss 5884.537
next layer loss target loss 1331.3333 other loss 143442.69
result 1 [11.99  7.82  1.54] neuron 317.2045 4.160235
e 910 loss -42.573685 target loss 826.6134 other loss -49433.688 tv loss 5884.8574
next layer loss target loss 1332.8213 other loss 143505.53
result 1 [12.    7.81  1.55] neuron 317.8301 4.159956
e 920 loss -42.588894 target loss 828.9467 other loss -49463.85 tv loss 5885.287
next layer loss target loss 1334.2711 other loss 143566.72
result 1 [12.01  7.8   1.55] neuron 318.4243 4.1598105
e 930 loss -42.603577 target loss 831.20447 other loss -49491.78 tv loss 5885.793
next layer loss target loss 1335.6875 other loss 143627.06
result 1 [12.02  7.79  1.55] neuron 318.9884 4.15977
e 940 loss -42.617752 target loss 833.3895 other loss -49516.312 tv loss 5886.396
next layer loss target loss 1337.0654 other loss 143685.56
result 1 [12.02  7.77  1.55] neuron 319.52972 4.159825
e 950 loss -42.631607 target loss 835.51965 other loss -49535.234 tv loss 5887.1123
next layer loss target loss 1338.4028 other loss 143740.6
result 1 [12.03  7.76  1.55] neuron 320.05408 4.159941
e 960 loss -42.64531 target loss 837.6163 other loss -49551.816 tv loss 5887.892
next layer loss target loss 1339.7207 other loss 143794.53
result 1 [12.03  7.75  1.55] neuron 320.56982 4.160099
e 970 loss -42.65886 target loss 839.69165 other loss -49567.805 tv loss 5888.716
next layer loss target loss 1341.0295 other loss 143848.72
result 1 [12.03  7.74  1.56] neuron 321.0827 4.1603146
e 980 loss -42.672287 target loss 841.7483 other loss -49583.82 tv loss 5889.576
next layer loss target loss 1342.3318 other loss 143903.38
result 1 [12.03  7.73  1.56] neuron 321.59488 4.160575
e 990 loss -42.68557 target loss 843.79126 other loss -49599.664 tv loss 5890.4736
next layer loss target loss 1343.6234 other loss 143958.27
result 1 [12.03  7.72  1.56] neuron 322.10648 4.160855
RE filter conv2d_2 112 RE acc 0.3333333333333333
e 0 loss -23.076904 target loss -704.1873 other loss -97808.055 tv loss 3976.1335
next layer loss target loss 11.078263 other loss 17872.773
result 1 [12.2   8.22  1.93] neuron -187.71014 0.5481526
e 10 loss -23.575481 target loss -635.1251 other loss -94338.34 tv loss 3860.8745
next layer loss target loss 14.380957 other loss 17638.691
result 1 [12.17  8.73  2.13] neuron -162.52321 0.56697845
e 20 loss -23.82705 target loss -596.5357 other loss -91516.81 tv loss 3760.0825
next layer loss target loss 15.238443 other loss 17397.71
result 1 [11.97  9.02  2.19] neuron -150.92377 0.5375188
e 30 loss -23.94465 target loss -569.4606 other loss -89834.65 tv loss 3687.308
next layer loss target loss 16.119373 other loss 17255.684
result 1 [11.76  9.19  2.22] neuron -143.83385 0.504905
e 40 loss -23.97502 target loss -555.8462 other loss -89269.84 tv loss 3650.0962
next layer loss target loss 16.666138 other loss 17222.85
result 1 [11.66  9.35  2.24] neuron -140.36417 0.5229598
e 50 loss -23.985764 target loss -552.87476 other loss -89356.516 tv loss 3645.8767
next layer loss target loss 16.845545 other loss 17243.072
result 1 [11.65  9.38  2.25] neuron -139.54749 0.532673
e 60 loss -23.995152 target loss -553.9556 other loss -89612.516 tv loss 3658.0366
next layer loss target loss 16.918537 other loss 17275.094
result 1 [11.66  9.35  2.26] neuron -139.20804 0.5330137
e 70 loss -24.001713 target loss -555.697 other loss -89893.0 tv loss 3672.6304
next layer loss target loss 16.908272 other loss 17312.031
result 1 [11.67  9.33  2.26] neuron -139.39041 0.53238195
e 80 loss -24.006283 target loss -555.7966 other loss -90106.61 tv loss 3682.2153
next layer loss target loss 17.011597 other loss 17345.154
result 1 [11.68  9.35  2.27] neuron -139.21753 0.5348537
e 90 loss -24.01037 target loss -555.2689 other loss -90219.484 tv loss 3686.0564
next layer loss target loss 17.095545 other loss 17361.156
result 1 [11.7   9.38  2.28] neuron -139.00476 0.53703254
e 100 loss -24.014118 target loss -554.33044 other loss -90238.234 tv loss 3685.6514
next layer loss target loss 17.179619 other loss 17366.387
result 1 [11.71  9.4   2.29] neuron -138.60466 0.53875417
e 110 loss -24.017376 target loss -554.2296 other loss -90272.45 tv loss 3686.9978
next layer loss target loss 17.190092 other loss 17372.867
result 1 [11.72  9.4   2.29] neuron -138.59558 0.5386355
e 120 loss -24.020239 target loss -553.82214 other loss -90299.56 tv loss 3687.8325
next layer loss target loss 17.237244 other loss 17378.033
result 1 [11.73  9.41  2.3 ] neuron -138.40022 0.53939104
e 130 loss -24.022884 target loss -553.2262 other loss -90330.95 tv loss 3688.503
next layer loss target loss 17.296844 other loss 17381.633
result 1 [11.74  9.42  2.31] neuron -138.15417 0.54061943
e 140 loss -24.025337 target loss -552.4951 other loss -90359.09 tv loss 3688.6016
next layer loss target loss 17.36453 other loss 17385.502
result 1 [11.75  9.44  2.31] neuron -137.8866 0.54194325
e 150 loss -24.027737 target loss -551.1935 other loss -90385.4 tv loss 3687.792
next layer loss target loss 17.467325 other loss 17397.135
result 1 [11.76  9.47  2.32] neuron -137.51685 0.54506564
e 160 loss -24.029835 target loss -550.8956 other loss -90434.23 tv loss 3689.5684
next layer loss target loss 17.489475 other loss 17403.797
result 1 [11.77  9.48  2.32] neuron -137.466 0.54585576
e 170 loss -24.031723 target loss -550.6327 other loss -90488.06 tv loss 3691.293
next layer loss target loss 17.54865 other loss 17412.777
result 1 [11.78  9.48  2.33] neuron -137.28561 0.5466385
e 180 loss -24.033476 target loss -550.2898 other loss -90509.695 tv loss 3692.0132
next layer loss target loss 17.591434 other loss 17414.422
result 1 [11.78  9.48  2.33] neuron -137.13007 0.5470149
e 190 loss -24.035091 target loss -549.97095 other loss -90511.914 tv loss 3692.1118
next layer loss target loss 17.616999 other loss 17415.027
result 1 [11.79  9.49  2.33] neuron -137.00809 0.5471449
e 200 loss -24.036621 target loss -549.6445 other loss -90522.914 tv loss 3692.5088
next layer loss target loss 17.645142 other loss 17417.867
result 1 [11.79  9.49  2.33] neuron -136.91165 0.54751414
e 210 loss -24.038034 target loss -549.3966 other loss -90528.67 tv loss 3692.6787
next layer loss target loss 17.660385 other loss 17419.555
result 1 [11.8   9.5   2.34] neuron -136.86337 0.5476377
e 220 loss -24.039352 target loss -549.12646 other loss -90537.64 tv loss 3692.6616
next layer loss target loss 17.688728 other loss 17421.422
result 1 [11.8   9.5   2.34] neuron -136.77466 0.5477055
e 230 loss -24.040604 target loss -548.91113 other loss -90530.97 tv loss 3692.3926
next layer loss target loss 17.693695 other loss 17421.932
result 1 [11.8   9.51  2.34] neuron -136.7446 0.54758674
e 240 loss -24.041786 target loss -548.70013 other loss -90530.59 tv loss 3692.2495
next layer loss target loss 17.716309 other loss 17422.688
result 1 [11.81  9.51  2.34] neuron -136.6662 0.54751194
e 250 loss -24.042938 target loss -548.46045 other loss -90541.84 tv loss 3692.2395
next layer loss target loss 17.75774 other loss 17421.174
result 1 [11.82  9.51  2.34] neuron -136.50177 0.5475849
e 260 loss -24.04402 target loss -548.23926 other loss -90534.234 tv loss 3691.89
next layer loss target loss 17.76595 other loss 17422.64
result 1 [11.82  9.51  2.34] neuron -136.4833 0.547562
e 270 loss -24.04506 target loss -548.06964 other loss -90541.11 tv loss 3692.024
next layer loss target loss 17.782276 other loss 17424.145
result 1 [11.82  9.51  2.34] neuron -136.43845 0.54751587
e 280 loss -24.04605 target loss -547.931 other loss -90555.49 tv loss 3692.4126
next layer loss target loss 17.804266 other loss 17425.426
result 1 [11.82  9.52  2.35] neuron -136.37631 0.5476172
e 290 loss -24.047022 target loss -547.81433 other loss -90556.984 tv loss 3692.4077
next layer loss target loss 17.81078 other loss 17426.812
result 1 [11.82  9.52  2.35] neuron -136.36285 0.547539
e 300 loss -24.047953 target loss -547.7116 other loss -90560.75 tv loss 3692.4697
next layer loss target loss 17.819832 other loss 17427.572
result 1 [11.83  9.52  2.35] neuron -136.35306 0.5474426
e 310 loss -24.048857 target loss -547.60266 other loss -90570.625 tv loss 3692.712
next layer loss target loss 17.834095 other loss 17428.98
result 1 [11.83  9.52  2.35] neuron -136.33292 0.5474787
e 320 loss -24.049717 target loss -547.4415 other loss -90579.15 tv loss 3692.9011
next layer loss target loss 17.852276 other loss 17430.588
result 1 [11.83  9.53  2.35] neuron -136.28381 0.5477436
e 330 loss -24.05055 target loss -547.37476 other loss -90587.27 tv loss 3693.0894
next layer loss target loss 17.860445 other loss 17431.535
result 1 [11.83  9.53  2.35] neuron -136.26837 0.5476394
e 340 loss -24.0513 target loss -547.259 other loss -90587.266 tv loss 3693.041
next layer loss target loss 17.873615 other loss 17431.422
result 1 [11.83  9.53  2.35] neuron -136.21811 0.5475838
e 350 loss -24.051994 target loss -547.1893 other loss -90588.484 tv loss 3692.9937
next layer loss target loss 17.876976 other loss 17432.9
result 1 [11.84  9.53  2.35] neuron -136.22272 0.5473273
e 360 loss -24.052643 target loss -547.10284 other loss -90585.47 tv loss 3692.7407
next layer loss target loss 17.88072 other loss 17432.676
result 1 [11.84  9.53  2.35] neuron -136.2263 0.5470895
e 370 loss -24.053257 target loss -547.0747 other loss -90581.55 tv loss 3692.669
next layer loss target loss 17.876575 other loss 17433.268
result 1 [11.84  9.53  2.35] neuron -136.24734 0.546841
e 380 loss -24.053856 target loss -546.9219 other loss -90583.35 tv loss 3692.691
next layer loss target loss 17.892643 other loss 17433.867
result 1 [11.84  9.53  2.35] neuron -136.20468 0.54698247
e 390 loss -24.05443 target loss -546.97217 other loss -90592.766 tv loss 3693.188
next layer loss target loss 17.893808 other loss 17434.523
result 1 [11.84  9.53  2.35] neuron -136.22859 0.5465714
e 400 loss -24.054977 target loss -546.9429 other loss -90593.05 tv loss 3693.2295
next layer loss target loss 17.899315 other loss 17434.865
result 1 [11.84  9.53  2.35] neuron -136.21631 0.5463387
e 410 loss -24.055523 target loss -546.8911 other loss -90589.1 tv loss 3693.1863
next layer loss target loss 17.90029 other loss 17435.701
result 1 [11.84  9.53  2.35] neuron -136.21797 0.54626477
e 420 loss -24.056034 target loss -546.67566 other loss -90592.39 tv loss 3693.039
next layer loss target loss 17.923365 other loss 17435.375
result 1 [11.84  9.53  2.35] neuron -136.13629 0.5465861
e 430 loss -24.056538 target loss -546.58875 other loss -90612.27 tv loss 3693.658
next layer loss target loss 17.94188 other loss 17437.9
result 1 [11.84  9.53  2.35] neuron -136.10634 0.54674935
e 440 loss -24.057009 target loss -546.48804 other loss -90618.43 tv loss 3693.7524
next layer loss target loss 17.955286 other loss 17438.309
result 1 [11.84  9.53  2.35] neuron -136.06506 0.5467506
e 450 loss -24.05746 target loss -546.3939 other loss -90619.08 tv loss 3693.7095
next layer loss target loss 17.965565 other loss 17438.205
result 1 [11.84  9.53  2.36] neuron -136.02924 0.5467954
e 460 loss -24.057884 target loss -546.3063 other loss -90627.9 tv loss 3693.971
next layer loss target loss 17.98233 other loss 17439.445
result 1 [11.84  9.53  2.36] neuron -135.98001 0.54686993
e 470 loss -24.05828 target loss -546.0799 other loss -90627.9 tv loss 3693.8276
next layer loss target loss 18.0077 other loss 17437.004
result 1 [11.85  9.53  2.36] neuron -135.867 0.5473735
e 480 loss -24.058643 target loss -545.9088 other loss -90643.23 tv loss 3694.231
next layer loss target loss 18.038322 other loss 17437.521
result 1 [11.85  9.53  2.36] neuron -135.77675 0.54788685
e 490 loss -24.059006 target loss -546.1103 other loss -90646.23 tv loss 3694.5
next layer loss target loss 18.021578 other loss 17437.895
result 1 [11.85  9.53  2.36] neuron -135.84245 0.5471556
e 500 loss -24.059378 target loss -546.02014 other loss -90641.91 tv loss 3694.3484
next layer loss target loss 18.024982 other loss 17437.512
result 1 [11.85  9.53  2.36] neuron -135.82954 0.54706115
e 510 loss -24.059723 target loss -545.8162 other loss -90653.56 tv loss 3694.4575
next layer loss target loss 18.055916 other loss 17439.293
result 1 [11.85  9.53  2.36] neuron -135.7504 0.54742026
e 520 loss -24.060062 target loss -545.78235 other loss -90652.3 tv loss 3694.396
next layer loss target loss 18.058199 other loss 17439.545
result 1 [11.85  9.53  2.36] neuron -135.73874 0.5472832
e 530 loss -24.060387 target loss -545.735 other loss -90656.34 tv loss 3694.4253
next layer loss target loss 18.066105 other loss 17440.31
result 1 [11.85  9.53  2.36] neuron -135.72244 0.54714966
e 540 loss -24.06069 target loss -545.643 other loss -90655.164 tv loss 3694.2651
next layer loss target loss 18.073484 other loss 17441.277
result 1 [11.85  9.53  2.36] neuron -135.71411 0.5470642
e 550 loss -24.060978 target loss -545.6083 other loss -90657.09 tv loss 3694.2124
next layer loss target loss 18.079086 other loss 17442.307
result 1 [11.85  9.54  2.36] neuron -135.7144 0.5468512
e 560 loss -24.061237 target loss -545.46967 other loss -90663.37 tv loss 3694.5405
next layer loss target loss 18.103682 other loss 17442.346
result 1 [11.86  9.53  2.37] neuron -135.61652 0.5473478
e 570 loss -24.061502 target loss -545.5527 other loss -90661.45 tv loss 3694.6616
next layer loss target loss 18.097992 other loss 17441.205
result 1 [11.86  9.53  2.37] neuron -135.62982 0.5467956
e 580 loss -24.06176 target loss -545.3385 other loss -90667.94 tv loss 3694.6064
next layer loss target loss 18.12237 other loss 17443.105
result 1 [11.86  9.53  2.37] neuron -135.5684 0.547339
e 590 loss -24.062008 target loss -545.4507 other loss -90662.51 tv loss 3694.6355
next layer loss target loss 18.110628 other loss 17441.887
result 1 [11.86  9.53  2.37] neuron -135.58835 0.54676783
e 600 loss -24.06223 target loss -545.3856 other loss -90667.56 tv loss 3694.7866
next layer loss target loss 18.123749 other loss 17442.068
result 1 [11.86  9.53  2.37] neuron -135.5625 0.5466475
e 610 loss -24.062456 target loss -545.33264 other loss -90672.07 tv loss 3694.877
next layer loss target loss 18.13356 other loss 17442.402
result 1 [11.86  9.53  2.37] neuron -135.53235 0.5468122
e 620 loss -24.06264 target loss -545.3308 other loss -90668.34 tv loss 3694.843
next layer loss target loss 18.134731 other loss 17441.621
result 1 [11.86  9.53  2.37] neuron -135.50897 0.54667115
e 630 loss -24.06285 target loss -545.2466 other loss -90675.36 tv loss 3695.0195
next layer loss target loss 18.149805 other loss 17443.715
result 1 [11.86  9.53  2.37] neuron -135.47186 0.5469367
e 640 loss -24.063011 target loss -545.0077 other loss -90677.42 tv loss 3694.85
next layer loss target loss 18.179625 other loss 17444.383
result 1 [11.86  9.53  2.37] neuron -135.36917 0.5476274
e 650 loss -24.063187 target loss -545.1341 other loss -90667.34 tv loss 3694.6646
next layer loss target loss 18.162636 other loss 17442.695
result 1 [11.86  9.53  2.37] neuron -135.40381 0.54674065
e 660 loss -24.06337 target loss -545.1198 other loss -90674.84 tv loss 3694.9517
next layer loss target loss 18.170727 other loss 17444.58
result 1 [11.86  9.53  2.37] neuron -135.40654 0.54684347
e 670 loss -24.063509 target loss -545.1583 other loss -90669.49 tv loss 3694.9458
next layer loss target loss 18.164747 other loss 17442.854
result 1 [11.86  9.53  2.37] neuron -135.4166 0.546354
e 680 loss -24.06367 target loss -544.8341 other loss -90679.93 tv loss 3694.8235
next layer loss target loss 18.206182 other loss 17444.912
result 1 [11.86  9.53  2.37] neuron -135.29669 0.54759145
e 690 loss -24.063824 target loss -544.9573 other loss -90679.19 tv loss 3695.0205
next layer loss target loss 18.193295 other loss 17444.977
result 1 [11.86  9.53  2.37] neuron -135.3453 0.54697126
e 700 loss -24.063744 target loss -545.2788 other loss -90671.39 tv loss 3695.2083
next layer loss target loss 18.159554 other loss 17441.783
result 1 [11.86  9.53  2.37] neuron -135.4385 0.545353
e 710 loss -24.063925 target loss -544.5431 other loss -90688.78 tv loss 3695.0283
next layer loss target loss 18.246292 other loss 17448.723
result 1 [11.86  9.53  2.37] neuron -135.16689 0.54850197
e 720 loss -24.06415 target loss -544.6377 other loss -90685.26 tv loss 3694.9111
next layer loss target loss 18.229645 other loss 17448.309
result 1 [11.86  9.54  2.37] neuron -135.21552 0.54801226
e 730 loss -24.0643 target loss -544.8917 other loss -90683.336 tv loss 3695.0586
next layer loss target loss 18.209686 other loss 17444.684
result 1 [11.86  9.53  2.37] neuron -135.29102 0.54627866
e 740 loss -24.064444 target loss -544.8408 other loss -90693.44 tv loss 3695.4011
next layer loss target loss 18.220371 other loss 17446.543
result 1 [11.86  9.53  2.37] neuron -135.27399 0.5468058
e 750 loss -24.064516 target loss -544.83154 other loss -90700.55 tv loss 3696.1084
next layer loss target loss 18.236698 other loss 17448.086
result 1 [11.86  9.53  2.37] neuron -135.18698 0.5477165
e 760 loss -24.06472 target loss -545.35376 other loss -90655.95 tv loss 3695.1665
next layer loss target loss 18.17609 other loss 17440.215
result 1 [11.86  9.52  2.37] neuron -135.37747 0.5448375
e 770 loss -24.064682 target loss -545.46643 other loss -90641.68 tv loss 3694.548
next layer loss target loss 18.159176 other loss 17436.086
result 1 [11.87  9.52  2.37] neuron -135.4205 0.5438092
e 780 loss -24.064646 target loss -544.8842 other loss -90667.2 tv loss 3694.7847
next layer loss target loss 18.24124 other loss 17443.576
result 1 [11.87  9.52  2.37] neuron -135.2076 0.54664344
e 790 loss -24.064991 target loss -545.22925 other loss -90663.94 tv loss 3695.1536
next layer loss target loss 18.196743 other loss 17442.709
result 1 [11.86  9.52  2.37] neuron -135.33624 0.5454953
e 800 loss -24.065083 target loss -545.30133 other loss -90648.4 tv loss 3694.7266
next layer loss target loss 18.188444 other loss 17437.033
result 1 [11.87  9.52  2.37] neuron -135.33636 0.5442669
e 810 loss -24.065191 target loss -544.96136 other loss -90658.195 tv loss 3694.6313
next layer loss target loss 18.231981 other loss 17440.746
result 1 [11.87  9.52  2.37] neuron -135.2056 0.5457468
e 820 loss -24.065308 target loss -545.14795 other loss -90658.84 tv loss 3694.8577
next layer loss target loss 18.21142 other loss 17439.68
result 1 [11.87  9.52  2.37] neuron -135.27525 0.54502726
e 830 loss -24.065346 target loss -544.856 other loss -90654.25 tv loss 3694.4463
next layer loss target loss 18.243584 other loss 17440.105
result 1 [11.87  9.52  2.37] neuron -135.15381 0.54590344
e 840 loss -24.065435 target loss -544.9646 other loss -90653.03 tv loss 3694.5874
next layer loss target loss 18.237143 other loss 17438.062
result 1 [11.87  9.52  2.37] neuron -135.1724 0.5450729
e 850 loss -24.065483 target loss -544.79364 other loss -90662.0 tv loss 3694.706
next layer loss target loss 18.258415 other loss 17441.023
result 1 [11.87  9.52  2.37] neuron -135.12238 0.54594946
e 860 loss -24.065557 target loss -545.0357 other loss -90660.0 tv loss 3694.738
next layer loss target loss 18.22491 other loss 17441.053
result 1 [11.87  9.52  2.37] neuron -135.2418 0.54498506
e 870 loss -24.065506 target loss -545.11145 other loss -90662.805 tv loss 3695.2192
next layer loss target loss 18.232077 other loss 17437.887
result 1 [11.87  9.52  2.37] neuron -135.20114 0.54430187
e 880 loss -24.065685 target loss -544.6628 other loss -90668.28 tv loss 3694.849
next layer loss target loss 18.279724 other loss 17442.16
result 1 [11.87  9.52  2.37] neuron -135.04901 0.54632276
e 890 loss -24.06569 target loss -545.09033 other loss -90667.57 tv loss 3695.1594
next layer loss target loss 18.233206 other loss 17439.277
result 1 [11.87  9.52  2.37] neuron -135.22015 0.5442597
e 900 loss -24.065865 target loss -544.776 other loss -90667.97 tv loss 3694.8833
next layer loss target loss 18.26949 other loss 17439.305
result 1 [11.87  9.52  2.37] neuron -135.0889 0.54523367
e 910 loss -24.065933 target loss -544.6804 other loss -90667.94 tv loss 3694.7854
next layer loss target loss 18.28083 other loss 17440.615
result 1 [11.87  9.52  2.37] neuron -135.0445 0.54572666
e 920 loss -24.066002 target loss -544.84753 other loss -90670.36 tv loss 3695.107
next layer loss target loss 18.270208 other loss 17440.537
result 1 [11.87  9.51  2.37] neuron -135.0793 0.5452562
e 930 loss -24.066061 target loss -545.1494 other loss -90677.95 tv loss 3695.928
next layer loss target loss 18.255997 other loss 17439.39
result 1 [11.88  9.51  2.37] neuron -135.13611 0.5444358
e 940 loss -24.066023 target loss -545.3039 other loss -90670.34 tv loss 3696.1018
next layer loss target loss 18.238531 other loss 17437.812
result 1 [11.88  9.51  2.37] neuron -135.17418 0.5438492
e 950 loss -24.066082 target loss -545.30554 other loss -90660.75 tv loss 3695.6182
next layer loss target loss 18.235783 other loss 17436.135
result 1 [11.88  9.51  2.37] neuron -135.18248 0.5433381
e 960 loss -24.066223 target loss -545.11865 other loss -90668.3 tv loss 3695.5781
next layer loss target loss 18.256214 other loss 17439.035
result 1 [11.88  9.51  2.37] neuron -135.14958 0.54413724
e 970 loss -24.066267 target loss -544.9453 other loss -90662.31 tv loss 3695.246
next layer loss target loss 18.273064 other loss 17438.098
result 1 [11.88  9.51  2.38] neuron -135.07599 0.54454285
e 980 loss -24.066303 target loss -545.0154 other loss -90654.96 tv loss 3695.1282
next layer loss target loss 18.260399 other loss 17436.557
result 1 [11.88  9.51  2.38] neuron -135.11371 0.54394716
e 990 loss -24.066319 target loss -545.1663 other loss -90653.45 tv loss 3695.0369
next layer loss target loss 18.24009 other loss 17436.84
result 1 [11.88  9.51  2.37] neuron -135.20862 0.5434481
RE filter conv2d_4 110 RE acc 0.3333333333333333
e 0 loss -33.48564 target loss 25.449032 other loss 11251.533 tv loss 3976.1335
next layer loss target loss 324.71063 other loss 148313.38
result 1 [12.2   8.22  1.93] neuron 5.839527 1.2175596
e 10 loss -34.5146 target loss 163.19675 other loss 12690.16 tv loss 3947.1836
next layer loss target loss 404.69833 other loss 153837.39
result 1 [11.9   8.19  2.21] neuron 64.79076 1.234175
e 20 loss -35.221645 target loss 217.26636 other loss 13525.77 tv loss 3957.9546
next layer loss target loss 461.51562 other loss 158848.03
result 1 [11.67  8.16  2.44] neuron 101.46748 1.2294408
e 30 loss -35.6163 target loss 300.34985 other loss 14921.368 tv loss 3953.308
next layer loss target loss 541.3652 other loss 166243.48
result 1 [11.46  7.88  2.61] neuron 143.06813 1.2386202
e 40 loss -35.826523 target loss 344.57825 other loss 15814.418 tv loss 3973.1145
next layer loss target loss 593.5662 other loss 172126.92
result 1 [11.33  7.63  2.73] neuron 168.55267 1.2594371
e 50 loss -35.99339 target loss 377.16248 other loss 16670.479 tv loss 4002.714
next layer loss target loss 632.50574 other loss 177376.8
result 1 [11.36  7.51  2.76] neuron 185.23163 1.2944857
e 60 loss -36.143612 target loss 392.25873 other loss 17298.326 tv loss 4037.2627
next layer loss target loss 655.2202 other loss 181360.75
result 1 [11.43  7.52  2.77] neuron 193.65634 1.3371756
e 70 loss -36.261612 target loss 403.10052 other loss 17677.945 tv loss 4067.526
next layer loss target loss 671.59814 other loss 184291.89
result 1 [11.46  7.51  2.77] neuron 199.53183 1.3742586
e 80 loss -36.351353 target loss 413.8184 other loss 18045.67 tv loss 4092.4624
next layer loss target loss 686.3293 other loss 186717.16
result 1 [11.49  7.47  2.79] neuron 205.0551 1.4059225
e 90 loss -36.420547 target loss 425.32953 other loss 18312.467 tv loss 4112.117
next layer loss target loss 700.1406 other loss 188600.88
result 1 [11.5   7.38  2.81] neuron 210.71527 1.431233
e 100 loss -36.477577 target loss 436.064 other loss 18545.572 tv loss 4128.747
next layer loss target loss 712.56885 other loss 190186.45
result 1 [11.51  7.3   2.83] neuron 215.79025 1.4529885
e 110 loss -36.526554 target loss 445.7356 other loss 18783.107 tv loss 4142.9165
next layer loss target loss 723.7644 other loss 191643.86
result 1 [11.52  7.23  2.85] neuron 220.20349 1.4725604
e 120 loss -36.56943 target loss 453.74515 other loss 18991.695 tv loss 4155.0205
next layer loss target loss 733.2722 other loss 192931.9
result 1 [11.54  7.17  2.86] neuron 223.8749 1.4903122
e 130 loss -36.60909 target loss 462.16263 other loss 19253.904 tv loss 4163.4434
next layer loss target loss 742.8655 other loss 194237.88
result 1 [11.58  7.12  2.86] neuron 227.5231 1.5088513
e 140 loss -36.650898 target loss 472.72263 other loss 19619.854 tv loss 4165.396
next layer loss target loss 753.9843 other loss 195673.06
result 1 [11.63  7.07  2.86] neuron 231.85724 1.524501
e 150 loss -36.696957 target loss 483.98273 other loss 19995.596 tv loss 4161.4414
next layer loss target loss 765.32733 other loss 196983.97
result 1 [11.69  6.99  2.86] neuron 236.55615 1.5437136
e 160 loss -36.748848 target loss 497.5406 other loss 20471.58 tv loss 4149.6084
next layer loss target loss 778.661 other loss 198479.1
result 1 [11.76  6.89  2.85] neuron 242.22485 1.5693996
e 170 loss -36.814217 target loss 515.13904 other loss 21169.691 tv loss 4122.3486
next layer loss target loss 796.5518 other loss 200599.14
result 1 [11.91  6.77  2.84] neuron 249.633 1.6040406
e 180 loss -36.937298 target loss 540.213 other loss 22265.38 tv loss 4066.9602
next layer loss target loss 823.1908 other loss 203673.56
result 1 [12.17  6.56  2.82] neuron 259.36142 1.6394657
e 190 loss -37.136837 target loss 572.42035 other loss 23719.18 tv loss 3972.9692
next layer loss target loss 859.8055 other loss 207465.14
result 1 [12.54  6.47  2.77] neuron 270.32376 1.6891063
e 200 loss -37.36223 target loss 596.29724 other loss 24641.092 tv loss 3898.6152
next layer loss target loss 890.5944 other loss 209636.78
result 1 [12.84  6.46  2.73] neuron 278.39886 1.7377102
e 210 loss -37.56612 target loss 616.39 other loss 25304.146 tv loss 3839.7744
next layer loss target loss 916.95996 other loss 211015.73
result 1 [13.12  6.49  2.72] neuron 284.8576 1.7839966
e 220 loss -37.72385 target loss 635.5067 other loss 25944.768 tv loss 3788.3782
next layer loss target loss 941.86694 other loss 212286.44
result 1 [13.33  6.52  2.71] neuron 289.96228 1.8300414
e 230 loss -37.83996 target loss 649.31793 other loss 26348.854 tv loss 3757.226
next layer loss target loss 961.79755 other loss 213101.11
result 1 [13.53  6.68  2.7 ] neuron 293.3744 1.8760871
e 240 loss -37.92632 target loss 662.9681 other loss 26748.018 tv loss 3732.92
next layer loss target loss 981.7082 other loss 214060.06
result 1 [13.67  6.84  2.69] neuron 296.73044 1.934469
e 250 loss -37.986435 target loss 673.8638 other loss 27025.863 tv loss 3718.6775
next layer loss target loss 998.79517 other loss 214908.44
result 1 [13.76  6.98  2.68] neuron 299.773 1.9816972
e 260 loss -38.025787 target loss 682.68445 other loss 27205.92 tv loss 3713.9854
next layer loss target loss 1012.53613 other loss 215581.45
result 1 [13.82  7.1   2.67] neuron 302.36377 2.0185935
e 270 loss -38.05548 target loss 689.8812 other loss 27313.992 tv loss 3717.706
next layer loss target loss 1023.2862 other loss 216048.88
result 1 [13.86  7.18  2.66] neuron 304.43433 2.0581186
e 280 loss -38.082726 target loss 695.32684 other loss 27351.396 tv loss 3728.3823
next layer loss target loss 1031.3604 other loss 216305.06
result 1 [13.87  7.22  2.65] neuron 305.89774 2.088704
e 290 loss -38.1092 target loss 700.0477 other loss 27349.002 tv loss 3742.5615
next layer loss target loss 1037.8545 other loss 216406.22
result 1 [13.86  7.25  2.62] neuron 307.0513 2.111093
e 300 loss -38.135834 target loss 705.4722 other loss 27322.35 tv loss 3755.6816
next layer loss target loss 1043.7817 other loss 216411.64
result 1 [13.82  7.26  2.6 ] neuron 308.59265 2.1233833
e 310 loss -38.163063 target loss 709.7093 other loss 27259.63 tv loss 3771.2656
next layer loss target loss 1048.1615 other loss 216264.0
result 1 [13.76  7.27  2.58] neuron 309.5212 2.13331
e 320 loss -38.199223 target loss 711.5929 other loss 27077.998 tv loss 3793.097
next layer loss target loss 1048.9199 other loss 215595.66
result 1 [13.65  7.27  2.57] neuron 309.29187 2.1390986
e 330 loss -38.229294 target loss 716.08093 other loss 27012.031 tv loss 3807.897
next layer loss target loss 1052.1759 other loss 215163.81
result 1 [13.52  7.32  2.55] neuron 309.22046 2.150571
e 340 loss -38.255405 target loss 719.83484 other loss 26936.127 tv loss 3822.0896
next layer loss target loss 1055.7096 other loss 214917.9
result 1 [13.43  7.36  2.53] neuron 309.41412 2.1595705
e 350 loss -38.27967 target loss 723.2673 other loss 26898.27 tv loss 3834.0374
next layer loss target loss 1060.119 other loss 214981.58
result 1 [13.38  7.39  2.52] neuron 310.07294 2.167821
e 360 loss -38.30429 target loss 728.5498 other loss 26983.03 tv loss 3838.5376
next layer loss target loss 1067.4019 other loss 215563.03
result 1 [13.41  7.41  2.5 ] neuron 311.74237 2.1785793
e 370 loss -38.32865 target loss 732.8395 other loss 26999.252 tv loss 3847.6787
next layer loss target loss 1073.3008 other loss 215958.22
result 1 [13.4   7.42  2.48] neuron 313.21576 2.1856081
e 380 loss -38.353195 target loss 738.02795 other loss 27050.791 tv loss 3856.0776
next layer loss target loss 1080.0282 other loss 216394.02
result 1 [13.39  7.45  2.46] neuron 314.76416 2.194811
e 390 loss -38.377483 target loss 742.15784 other loss 27063.666 tv loss 3866.7156
next layer loss target loss 1085.6443 other loss 216717.27
result 1 [13.37  7.47  2.44] neuron 315.99988 2.202296
e 400 loss -38.40211 target loss 746.91254 other loss 27109.352 tv loss 3875.9492
next layer loss target loss 1092.0726 other loss 217147.0
result 1 [13.36  7.5   2.43] neuron 317.3814 2.211328
e 410 loss -35.14357 target loss 540.74274 other loss 30455.436 tv loss 4037.7842
next layer loss target loss 929.30164 other loss 209769.45
result 1 [12.9   7.13  2.5 ] neuron 247.54324 2.095894
e 420 loss -33.968674 target loss 382.1647 other loss 26331.912 tv loss 4225.794
next layer loss target loss 793.8296 other loss 200268.52
result 1 [12.21  7.03  2.73] neuron 191.27478 2.0125756
e 430 loss -34.580784 target loss 321.13043 other loss 19117.94 tv loss 4332.808
next layer loss target loss 731.11926 other loss 191637.17
result 1 [11.77  7.48  2.63] neuron 167.69617 2.0125952
e 440 loss -33.70245 target loss 301.1619 other loss 16696.025 tv loss 4361.8394
next layer loss target loss 710.25696 other loss 188961.22
result 1 [11.5   7.51  2.58] neuron 159.85619 2.0098794
e 450 loss -33.409073 target loss 296.44348 other loss 15990.976 tv loss 4371.0527
next layer loss target loss 704.836 other loss 188333.2
result 1 [11.41  7.52  2.56] neuron 157.92712 2.0068166
e 460 loss -33.377567 target loss 297.31708 other loss 15880.362 tv loss 4374.7637
next layer loss target loss 705.0393 other loss 188429.45
result 1 [11.39  7.51  2.56] neuron 158.19595 2.004065
e 470 loss -33.439056 target loss 300.22556 other loss 15980.16 tv loss 4376.3984
next layer loss target loss 707.2723 other loss 188779.1
result 1 [11.4   7.5   2.56] neuron 159.26622 2.0013661
e 480 loss -33.53381 target loss 303.8724 other loss 16154.17 tv loss 4377.1924
next layer loss target loss 710.2441 other loss 189214.75
result 1 [11.42  7.49  2.55] neuron 160.61595 1.9986398
e 490 loss -33.64016 target loss 307.7736 other loss 16354.612 tv loss 4377.571
next layer loss target loss 713.4956 other loss 189679.77
result 1 [11.45  7.48  2.55] neuron 162.05801 1.9959234
e 500 loss -33.75095 target loss 311.7706 other loss 16565.398 tv loss 4377.834
next layer loss target loss 716.8792 other loss 190157.9
result 1 [11.49  7.47  2.55] neuron 163.5308 1.9932075
e 510 loss -33.862835 target loss 315.78622 other loss 16780.002 tv loss 4377.8457
next layer loss target loss 720.299 other loss 190638.7
result 1 [11.53  7.46  2.55] neuron 165.0069 1.990508
e 520 loss -33.975048 target loss 319.79688 other loss 16996.055 tv loss 4377.737
next layer loss target loss 723.7255 other loss 191118.39
result 1 [11.57  7.45  2.55] neuron 166.4768 1.9878368
e 530 loss -34.08736 target loss 323.80487 other loss 17212.95 tv loss 4377.4644
next layer loss target loss 727.1645 other loss 191596.84
result 1 [11.61  7.44  2.55] neuron 167.9401 1.9851953
e 540 loss -34.199886 target loss 327.81396 other loss 17430.629 tv loss 4377.092
next layer loss target loss 730.62573 other loss 192075.03
result 1 [11.65  7.42  2.55] neuron 169.39532 1.982563
e 550 loss -34.312572 target loss 331.83585 other loss 17649.275 tv loss 4376.6104
next layer loss target loss 734.12805 other loss 192554.45
result 1 [11.69  7.41  2.54] neuron 170.84814 1.979926
e 560 loss -34.42456 target loss 335.83722 other loss 17867.51 tv loss 4375.783
next layer loss target loss 737.6149 other loss 193029.22
result 1 [11.73  7.4   2.54] neuron 172.28848 1.977307
e 570 loss -34.53502 target loss 339.79962 other loss 18083.582 tv loss 4374.6973
next layer loss target loss 741.0641 other loss 193493.19
result 1 [11.78  7.39  2.54] neuron 173.70743 1.974759
e 580 loss -34.643322 target loss 343.71884 other loss 18296.416 tv loss 4373.2124
next layer loss target loss 744.45654 other loss 193942.25
result 1 [11.82  7.38  2.53] neuron 175.0917 1.9723091
e 590 loss -34.749416 target loss 347.58923 other loss 18505.41 tv loss 4371.3647
next layer loss target loss 747.7824 other loss 194374.92
result 1 [11.86  7.38  2.53] neuron 176.43243 1.9700419
e 600 loss -34.853775 target loss 351.43835 other loss 18711.205 tv loss 4369.2217
next layer loss target loss 751.0892 other loss 194795.34
result 1 [11.9   7.37  2.52] neuron 177.749 1.9684957
e 610 loss -34.955627 target loss 355.27307 other loss 18913.639 tv loss 4366.9463
next layer loss target loss 754.3649 other loss 195206.14
result 1 [11.94  7.37  2.52] neuron 179.05328 1.96702
e 620 loss -35.05434 target loss 359.06152 other loss 19111.19 tv loss 4364.577
next layer loss target loss 757.5833 other loss 195604.22
result 1 [11.98  7.37  2.52] neuron 180.33485 1.9656414
e 630 loss -35.149464 target loss 362.81326 other loss 19303.074 tv loss 4362.136
next layer loss target loss 760.74023 other loss 195988.05
result 1 [12.02  7.36  2.51] neuron 181.59589 1.9643435
e 640 loss -35.241085 target loss 366.5512 other loss 19488.799 tv loss 4359.585
next layer loss target loss 763.8436 other loss 196357.48
result 1 [12.05  7.36  2.51] neuron 182.83804 1.9631419
e 650 loss -35.329296 target loss 370.28802 other loss 19668.658 tv loss 4356.9644
next layer loss target loss 766.9163 other loss 196715.55
result 1 [12.09  7.36  2.5 ] neuron 184.0654 1.9620199
e 660 loss -35.414215 target loss 374.02698 other loss 19842.178 tv loss 4354.284
next layer loss target loss 769.9825 other loss 197061.69
result 1 [12.13  7.35  2.5 ] neuron 185.2833 1.960977
e 670 loss -35.496063 target loss 377.78445 other loss 20009.625 tv loss 4351.4844
next layer loss target loss 773.0462 other loss 197398.78
result 1 [12.16  7.35  2.49] neuron 186.50395 1.9599962
e 680 loss -35.57483 target loss 381.55426 other loss 20170.594 tv loss 4348.63
next layer loss target loss 776.0852 other loss 197726.2
result 1 [12.19  7.35  2.49] neuron 187.71959 1.9590849
e 690 loss -35.650547 target loss 385.34183 other loss 20325.209 tv loss 4345.6836
next layer loss target loss 779.11914 other loss 198045.69
result 1 [12.22  7.34  2.48] neuron 188.9336 1.9582379
e 700 loss -35.72356 target loss 389.14346 other loss 20472.846 tv loss 4342.6616
next layer loss target loss 782.1397 other loss 198355.19
result 1 [12.25  7.34  2.48] neuron 190.1441 1.9578373
e 710 loss -35.794086 target loss 392.97394 other loss 20614.693 tv loss 4339.593
next layer loss target loss 785.1785 other loss 198660.33
result 1 [12.27  7.34  2.47] neuron 191.35971 1.9579334
e 720 loss -35.862064 target loss 396.81845 other loss 20749.828 tv loss 4336.554
next layer loss target loss 788.21497 other loss 198956.73
result 1 [12.3   7.34  2.47] neuron 192.57866 1.9589376
e 730 loss -35.927834 target loss 400.68225 other loss 20878.42 tv loss 4333.5293
next layer loss target loss 791.24713 other loss 199244.23
result 1 [12.32  7.34  2.47] neuron 193.79642 1.960103
e 740 loss -35.991688 target loss 404.56512 other loss 21001.12 tv loss 4330.444
next layer loss target loss 794.27045 other loss 199524.78
result 1 [12.34  7.34  2.46] neuron 195.01907 1.9612864
e 750 loss -36.05388 target loss 408.46857 other loss 21118.057 tv loss 4327.3135
next layer loss target loss 797.3035 other loss 199798.45
result 1 [12.36  7.34  2.46] neuron 196.24118 1.9624864
e 760 loss -36.114662 target loss 412.3947 other loss 21229.33 tv loss 4324.1304
next layer loss target loss 800.345 other loss 200064.02
result 1 [12.38  7.34  2.45] neuron 197.46268 1.9636949
e 770 loss -36.174606 target loss 416.35162 other loss 21335.576 tv loss 4320.879
next layer loss target loss 803.4116 other loss 200323.08
result 1 [12.4   7.33  2.45] neuron 198.6885 1.9648302
e 780 loss -36.233604 target loss 420.32623 other loss 21436.916 tv loss 4317.5234
next layer loss target loss 806.48334 other loss 200575.2
result 1 [12.41  7.33  2.44] neuron 199.913 1.9658854
e 790 loss -36.29178 target loss 424.3169 other loss 21533.553 tv loss 4314.106
next layer loss target loss 809.5481 other loss 200819.7
result 1 [12.43  7.33  2.43] neuron 201.13452 1.9669449
e 800 loss -36.349384 target loss 428.32986 other loss 21626.29 tv loss 4310.6836
next layer loss target loss 812.6198 other loss 201058.9
result 1 [12.45  7.33  2.42] neuron 202.35751 1.9680097
e 810 loss -36.40649 target loss 432.36166 other loss 21715.586 tv loss 4307.262
next layer loss target loss 815.69525 other loss 201293.89
result 1 [12.47  7.32  2.42] neuron 203.58054 1.9690098
e 820 loss -36.463284 target loss 436.4088 other loss 21801.857 tv loss 4303.7754
next layer loss target loss 818.7663 other loss 201524.89
result 1 [12.48  7.32  2.41] neuron 204.80304 1.9700217
e 830 loss -36.519497 target loss 440.46927 other loss 21885.47 tv loss 4300.2124
next layer loss target loss 821.8311 other loss 201752.19
result 1 [12.5   7.32  2.4 ] neuron 206.02509 1.9710456
e 840 loss -36.575275 target loss 444.5375 other loss 21966.75 tv loss 4296.5967
next layer loss target loss 824.88586 other loss 201976.48
result 1 [12.52  7.31  2.39] neuron 207.24802 1.9725589
e 850 loss -36.630444 target loss 448.60666 other loss 22045.863 tv loss 4292.9805
next layer loss target loss 827.9305 other loss 202197.72
result 1 [12.54  7.31  2.38] neuron 208.46826 1.9751283
e 860 loss -36.684814 target loss 452.6662 other loss 22122.436 tv loss 4289.375
next layer loss target loss 830.9575 other loss 202413.44
result 1 [12.55  7.3   2.38] neuron 209.67842 1.9776852
e 870 loss -36.73831 target loss 456.71243 other loss 22196.424 tv loss 4285.764
next layer loss target loss 833.9583 other loss 202622.75
result 1 [12.57  7.29  2.37] neuron 210.8776 1.9802231
e 880 loss -36.79102 target loss 460.74976 other loss 22268.49 tv loss 4282.164
next layer loss target loss 836.9468 other loss 202828.06
result 1 [12.58  7.29  2.37] neuron 212.07059 1.9816458
e 890 loss -36.843086 target loss 464.78552 other loss 22339.209 tv loss 4278.5728
next layer loss target loss 839.9303 other loss 203031.27
result 1 [12.6   7.28  2.36] neuron 213.25966 1.9829615
e 900 loss -36.894566 target loss 468.82233 other loss 22408.787 tv loss 4274.9463
next layer loss target loss 842.9069 other loss 203232.28
result 1 [12.61  7.27  2.36] neuron 214.44705 1.9842666
e 910 loss -36.945423 target loss 472.86478 other loss 22477.684 tv loss 4271.24
next layer loss target loss 845.87445 other loss 203432.89
result 1 [12.62  7.27  2.35] neuron 215.63528 1.9855665
e 920 loss -36.99534 target loss 476.8946 other loss 22545.395 tv loss 4267.479
next layer loss target loss 848.8289 other loss 203630.72
result 1 [12.63  7.26  2.35] neuron 216.81686 1.9868515
e 930 loss -37.04425 target loss 480.90015 other loss 22611.553 tv loss 4263.6953
next layer loss target loss 851.76556 other loss 203823.72
result 1 [12.64  7.25  2.34] neuron 217.98743 1.9881101
e 940 loss -37.092224 target loss 484.89102 other loss 22676.168 tv loss 4259.87
next layer loss target loss 854.6826 other loss 204011.14
result 1 [12.65  7.24  2.34] neuron 219.14865 1.9893394
e 950 loss -37.139153 target loss 488.86154 other loss 22739.314 tv loss 4256.029
next layer loss target loss 857.5769 other loss 204193.5
result 1 [12.66  7.24  2.34] neuron 220.29959 1.9905387
e 960 loss -37.184917 target loss 492.80563 other loss 22801.035 tv loss 4252.1807
next layer loss target loss 860.4367 other loss 204370.31
result 1 [12.67  7.23  2.33] neuron 221.43652 1.9917085
e 970 loss -37.22937 target loss 496.7147 other loss 22861.531 tv loss 4248.33
next layer loss target loss 863.26556 other loss 204542.67
result 1 [12.68  7.22  2.33] neuron 222.55968 1.9928509
e 980 loss -37.272514 target loss 500.5972 other loss 22921.348 tv loss 4244.424
next layer loss target loss 866.0607 other loss 204712.58
result 1 [12.69  7.21  2.32] neuron 223.6756 1.9937168
e 990 loss -37.314125 target loss 504.4372 other loss 22980.588 tv loss 4240.5127
next layer loss target loss 868.8242 other loss 204881.16
result 1 [12.69  7.21  2.32] neuron 224.77914 1.9945464
RE filter conv2d_1 51 RE acc 0.3333333333333333
e 0 loss -21.085888 target loss -932.11255 other loss -97580.125 tv loss 3976.1335
next layer loss target loss 39.903946 other loss 17843.95
result 1 [12.2   8.22  1.93] neuron -279.30414 1.8060168
e 10 loss -21.515625 target loss -874.9728 other loss -93461.11 tv loss 3839.017
next layer loss target loss 39.925694 other loss 17542.201
result 1 [12.02  8.59  2.09] neuron -259.50574 1.7485633
e 20 loss -21.76168 target loss -837.6807 other loss -89812.31 tv loss 3704.8018
next layer loss target loss 38.80635 other loss 17116.86
result 1 [11.89  8.72  2.13] neuron -247.03906 1.6868317
e 30 loss -21.89988 target loss -808.3523 other loss -86634.53 tv loss 3576.5874
next layer loss target loss 37.843758 other loss 16709.777
result 1 [11.78  8.61  2.11] neuron -237.83061 1.6379839
e 40 loss -21.962505 target loss -786.9405 other loss -84387.99 tv loss 3478.6077
next layer loss target loss 37.319485 other loss 16418.564
result 1 [11.74  8.55  2.1 ] neuron -231.0326 1.610188
e 50 loss -21.98517 target loss -773.70123 other loss -83156.19 tv loss 3421.8472
next layer loss target loss 37.123505 other loss 16254.289
result 1 [11.74  8.51  2.09] neuron -226.87254 1.5971102
e 60 loss -21.99699 target loss -766.96405 other loss -82588.16 tv loss 3399.9224
next layer loss target loss 37.080544 other loss 16174.101
result 1 [11.74  8.47  2.1 ] neuron -224.60043 1.5893568
e 70 loss -22.007095 target loss -764.74426 other loss -82375.484 tv loss 3394.712
next layer loss target loss 37.042297 other loss 16148.53
result 1 [11.72  8.45  2.11] neuron -223.85837 1.5834959
e 80 loss -22.015617 target loss -764.6438 other loss -82390.266 tv loss 3396.7598
next layer loss target loss 37.131535 other loss 16154.146
result 1 [11.72  8.45  2.11] neuron -223.79344 1.5827098
e 90 loss -22.022396 target loss -764.8197 other loss -82448.66 tv loss 3399.6125
next layer loss target loss 37.25276 other loss 16161.981
result 1 [11.73  8.45  2.12] neuron -223.91719 1.5854146
e 100 loss -22.027897 target loss -763.8414 other loss -82384.17 tv loss 3398.771
next layer loss target loss 37.301464 other loss 16160.426
result 1 [11.72  8.45  2.13] neuron -223.61821 1.5845237
e 110 loss -22.032541 target loss -762.5593 other loss -82262.24 tv loss 3395.0605
next layer loss target loss 37.31877 other loss 16149.808
result 1 [11.72  8.45  2.13] neuron -223.26886 1.5830182
e 120 loss -22.036627 target loss -761.16504 other loss -82167.336 tv loss 3391.5718
next layer loss target loss 37.364285 other loss 16138.679
result 1 [11.72  8.45  2.14] neuron -222.82849 1.5825918
e 130 loss -22.040287 target loss -759.98376 other loss -82092.66 tv loss 3389.5107
next layer loss target loss 37.40947 other loss 16129.862
result 1 [11.72  8.45  2.14] neuron -222.44601 1.5825496
e 140 loss -22.04341 target loss -759.0028 other loss -82044.02 tv loss 3387.488
next layer loss target loss 37.479458 other loss 16117.705
result 1 [11.72  8.44  2.15] neuron -222.13605 1.5836297
e 150 loss -22.045933 target loss -758.08545 other loss -81965.59 tv loss 3385.1633
next layer loss target loss 37.505375 other loss 16109.786
result 1 [11.72  8.44  2.15] neuron -221.87085 1.5829482
e 160 loss -22.048092 target loss -757.2605 other loss -81909.81 tv loss 3383.4863
next layer loss target loss 37.540855 other loss 16105.367
result 1 [11.72  8.45  2.16] neuron -221.60486 1.582671
e 170 loss -22.049976 target loss -756.56067 other loss -81889.0 tv loss 3382.917
next layer loss target loss 37.588097 other loss 16103.221
result 1 [11.72  8.45  2.16] neuron -221.35263 1.5832171
e 180 loss -22.051638 target loss -755.93665 other loss -81857.445 tv loss 3382.2783
next layer loss target loss 37.61588 other loss 16100.949
result 1 [11.72  8.46  2.16] neuron -221.14673 1.5833315
e 190 loss -22.053104 target loss -755.3319 other loss -81817.88 tv loss 3380.6653
next layer loss target loss 37.63929 other loss 16097.254
result 1 [11.72  8.46  2.16] neuron -220.97318 1.5834765
e 200 loss -22.054382 target loss -754.7136 other loss -81774.11 tv loss 3378.8228
next layer loss target loss 37.664078 other loss 16092.602
result 1 [11.72  8.46  2.17] neuron -220.80295 1.5836805
e 210 loss -22.055563 target loss -754.1318 other loss -81749.15 tv loss 3377.418
next layer loss target loss 37.705666 other loss 16090.4
result 1 [11.72  8.47  2.17] neuron -220.63716 1.5843269
e 220 loss -22.056675 target loss -753.7615 other loss -81747.89 tv loss 3377.412
next layer loss target loss 37.760014 other loss 16091.756
result 1 [11.72  8.48  2.17] neuron -220.52408 1.5854788
e 230 loss -22.057655 target loss -753.5616 other loss -81747.44 tv loss 3377.32
next layer loss target loss 37.79386 other loss 16093.48
result 1 [11.72  8.48  2.17] neuron -220.47362 1.5859587
e 240 loss -22.0585 target loss -753.4844 other loss -81749.5 tv loss 3377.5073
next layer loss target loss 37.81156 other loss 16094.465
result 1 [11.72  8.49  2.17] neuron -220.46788 1.586554
e 250 loss -22.059237 target loss -753.2355 other loss -81743.47 tv loss 3377.311
next layer loss target loss 37.833206 other loss 16094.671
result 1 [11.72  8.49  2.18] neuron -220.38673 1.5868438
e 260 loss -22.059916 target loss -753.0025 other loss -81728.42 tv loss 3376.7178
next layer loss target loss 37.845894 other loss 16091.805
result 1 [11.72  8.49  2.18] neuron -220.31656 1.5870112
e 270 loss -22.06052 target loss -752.7889 other loss -81717.64 tv loss 3376.3535
next layer loss target loss 37.86 other loss 16091.075
result 1 [11.72  8.49  2.18] neuron -220.24182 1.586966
e 280 loss -22.061085 target loss -752.58167 other loss -81711.99 tv loss 3376.049
next layer loss target loss 37.881012 other loss 16091.264
result 1 [11.72  8.49  2.18] neuron -220.17676 1.5871029
e 290 loss -22.06161 target loss -752.5409 other loss -81703.91 tv loss 3375.7327
next layer loss target loss 37.891216 other loss 16091.339
result 1 [11.72  8.49  2.18] neuron -220.18217 1.5871704
e 300 loss -22.062103 target loss -752.3816 other loss -81718.234 tv loss 3375.9863
next layer loss target loss 37.92184 other loss 16092.06
result 1 [11.72  8.5   2.18] neuron -220.10715 1.5877147
e 310 loss -22.062603 target loss -752.2146 other loss -81726.16 tv loss 3375.9673
next layer loss target loss 37.95569 other loss 16091.8125
result 1 [11.73  8.5   2.19] neuron -220.03247 1.5883827
e 320 loss -22.063072 target loss -752.13525 other loss -81725.6 tv loss 3376.2002
next layer loss target loss 37.97113 other loss 16092.0
result 1 [11.73  8.5   2.19] neuron -219.98494 1.5885484
e 330 loss -22.063538 target loss -752.041 other loss -81723.914 tv loss 3376.0842
next layer loss target loss 37.98674 other loss 16091.574
result 1 [11.73  8.5   2.19] neuron -219.94666 1.5887799
e 340 loss -22.063957 target loss -751.96075 other loss -81720.336 tv loss 3375.8052
next layer loss target loss 38.00186 other loss 16090.869
result 1 [11.73  8.5   2.19] neuron -219.9223 1.5890199
e 350 loss -22.064362 target loss -751.8969 other loss -81715.516 tv loss 3375.574
next layer loss target loss 38.00742 other loss 16089.479
result 1 [11.73  8.5   2.19] neuron -219.90665 1.5891721
e 360 loss -22.06475 target loss -751.82513 other loss -81715.09 tv loss 3375.4653
next layer loss target loss 38.02004 other loss 16089.791
result 1 [11.73  8.5   2.19] neuron -219.89354 1.5892911
e 370 loss -22.065128 target loss -751.84625 other loss -81721.875 tv loss 3375.6746
next layer loss target loss 38.032963 other loss 16090.477
result 1 [11.73  8.51  2.19] neuron -219.90222 1.5896976
e 380 loss -22.065495 target loss -751.8077 other loss -81732.3 tv loss 3375.9785
next layer loss target loss 38.055275 other loss 16091.131
result 1 [11.73  8.51  2.2 ] neuron -219.88425 1.5902942
e 390 loss -22.065853 target loss -751.66907 other loss -81725.75 tv loss 3375.6873
next layer loss target loss 38.06829 other loss 16090.416
result 1 [11.73  8.51  2.2 ] neuron -219.84506 1.5904204
e 400 loss -22.066208 target loss -751.4536 other loss -81719.19 tv loss 3375.1372
next layer loss target loss 38.085785 other loss 16089.45
result 1 [11.73  8.51  2.2 ] neuron -219.78262 1.5906339
e 410 loss -22.066534 target loss -751.319 other loss -81706.55 tv loss 3374.6602
next layer loss target loss 38.08851 other loss 16088.046
result 1 [11.73  8.51  2.2 ] neuron -219.75009 1.5906676
e 420 loss -22.066858 target loss -751.1797 other loss -81701.33 tv loss 3374.3926
next layer loss target loss 38.097122 other loss 16087.106
result 1 [11.73  8.51  2.2 ] neuron -219.70041 1.5907891
e 430 loss -22.067165 target loss -751.0237 other loss -81695.09 tv loss 3374.102
next layer loss target loss 38.105667 other loss 16086.78
result 1 [11.73  8.51  2.2 ] neuron -219.64276 1.5908167
e 440 loss -22.067444 target loss -750.9822 other loss -81690.945 tv loss 3373.995
next layer loss target loss 38.109524 other loss 16086.451
result 1 [11.73  8.52  2.2 ] neuron -219.63222 1.5908895
e 450 loss -22.067728 target loss -750.938 other loss -81693.8 tv loss 3373.981
next layer loss target loss 38.11621 other loss 16086.965
result 1 [11.73  8.52  2.2 ] neuron -219.61893 1.591012
e 460 loss -22.067972 target loss -750.91394 other loss -81694.86 tv loss 3374.0364
next layer loss target loss 38.12124 other loss 16087.178
result 1 [11.73  8.52  2.2 ] neuron -219.60638 1.5911909
e 470 loss -22.068214 target loss -750.86395 other loss -81693.5 tv loss 3373.933
next layer loss target loss 38.125744 other loss 16087.425
result 1 [11.73  8.52  2.21] neuron -219.5918 1.5912676
e 480 loss -22.06845 target loss -750.81384 other loss -81691.53 tv loss 3373.814
next layer loss target loss 38.130283 other loss 16087.003
result 1 [11.73  8.52  2.21] neuron -219.57545 1.5912724
e 490 loss -22.068686 target loss -750.8495 other loss -81688.766 tv loss 3373.845
next layer loss target loss 38.128883 other loss 16085.937
result 1 [11.73  8.52  2.21] neuron -219.59566 1.5914632
e 500 loss -22.068901 target loss -750.71826 other loss -81691.91 tv loss 3373.75
next layer loss target loss 38.143303 other loss 16086.278
result 1 [11.73  8.52  2.21] neuron -219.54562 1.5915267
e 510 loss -22.069122 target loss -750.73303 other loss -81688.375 tv loss 3373.7773
next layer loss target loss 38.146664 other loss 16086.226
result 1 [11.73  8.52  2.21] neuron -219.54736 1.5915887
e 520 loss -22.06931 target loss -750.64215 other loss -81695.86 tv loss 3373.8362
next layer loss target loss 38.158653 other loss 16087.295
result 1 [11.73  8.52  2.21] neuron -219.51218 1.5916817
e 530 loss -22.069544 target loss -750.6826 other loss -81699.46 tv loss 3374.0942
next layer loss target loss 38.16433 other loss 16087.927
result 1 [11.73  8.52  2.21] neuron -219.52557 1.5918016
e 540 loss -22.06973 target loss -750.70044 other loss -81697.87 tv loss 3374.0593
next layer loss target loss 38.1672 other loss 16086.967
result 1 [11.73  8.53  2.21] neuron -219.53839 1.5918778
e 550 loss -22.069946 target loss -750.6801 other loss -81701.17 tv loss 3374.133
next layer loss target loss 38.173935 other loss 16087.621
result 1 [11.73  8.52  2.21] neuron -219.53253 1.5919327
e 560 loss -22.070143 target loss -750.6593 other loss -81704.016 tv loss 3374.2122
next layer loss target loss 38.182434 other loss 16088.131
result 1 [11.73  8.53  2.21] neuron -219.51718 1.5920918
e 570 loss -22.070318 target loss -750.62866 other loss -81695.44 tv loss 3373.9395
next layer loss target loss 38.18075 other loss 16087.277
result 1 [11.73  8.53  2.21] neuron -219.5067 1.5919856
e 580 loss -22.070477 target loss -750.65247 other loss -81692.83 tv loss 3373.9116
next layer loss target loss 38.17799 other loss 16086.337
result 1 [11.73  8.53  2.21] neuron -219.51582 1.592094
e 590 loss -22.070646 target loss -750.5632 other loss -81690.75 tv loss 3373.71
next layer loss target loss 38.18209 other loss 16085.521
result 1 [11.74  8.53  2.22] neuron -219.48509 1.5920312
e 600 loss -22.07084 target loss -750.58203 other loss -81695.67 tv loss 3373.726
next layer loss target loss 38.185627 other loss 16086.299
result 1 [11.74  8.53  2.22] neuron -219.50385 1.5922296
e 610 loss -22.070993 target loss -750.5355 other loss -81703.94 tv loss 3373.7998
next layer loss target loss 38.193592 other loss 16086.736
result 1 [11.74  8.53  2.22] neuron -219.48877 1.5923852
e 620 loss -22.071167 target loss -750.5097 other loss -81700.16 tv loss 3373.6992
next layer loss target loss 38.19711 other loss 16086.719
result 1 [11.74  8.53  2.22] neuron -219.48044 1.592359
e 630 loss -22.071312 target loss -750.51013 other loss -81706.41 tv loss 3373.8484
next layer loss target loss 38.202747 other loss 16087.315
result 1 [11.74  8.53  2.22] neuron -219.48572 1.5925256
e 640 loss -22.071482 target loss -750.535 other loss -81696.72 tv loss 3373.6555
next layer loss target loss 38.197662 other loss 16087.247
result 1 [11.74  8.53  2.22] neuron -219.49438 1.5923597
e 650 loss -22.07163 target loss -750.4945 other loss -81701.35 tv loss 3373.7256
next layer loss target loss 38.20533 other loss 16088.092
result 1 [11.74  8.53  2.22] neuron -219.4805 1.59246
e 660 loss -22.071783 target loss -750.50256 other loss -81705.86 tv loss 3373.6929
next layer loss target loss 38.207417 other loss 16087.323
result 1 [11.74  8.53  2.22] neuron -219.49384 1.5926194
e 670 loss -22.07193 target loss -750.58984 other loss -81705.46 tv loss 3373.976
next layer loss target loss 38.207924 other loss 16088.08
result 1 [11.74  8.53  2.22] neuron -219.52179 1.592859
e 680 loss -22.072084 target loss -750.59045 other loss -81710.484 tv loss 3374.0457
next layer loss target loss 38.21241 other loss 16088.258
result 1 [11.74  8.53  2.22] neuron -219.51755 1.592945
e 690 loss -22.072216 target loss -750.5785 other loss -81721.95 tv loss 3374.2493
next layer loss target loss 38.222916 other loss 16088.92
result 1 [11.74  8.53  2.22] neuron -219.51921 1.5931826
e 700 loss -22.072365 target loss -750.60516 other loss -81712.39 tv loss 3374.219
next layer loss target loss 38.216785 other loss 16087.717
result 1 [11.74  8.53  2.22] neuron -219.52196 1.5930319
e 710 loss -22.072504 target loss -750.6062 other loss -81716.06 tv loss 3374.3506
next layer loss target loss 38.22228 other loss 16088.728
result 1 [11.74  8.53  2.22] neuron -219.52621 1.593199
e 720 loss -22.072634 target loss -750.64716 other loss -81719.12 tv loss 3374.436
next layer loss target loss 38.22509 other loss 16088.764
result 1 [11.74  8.53  2.22] neuron -219.54538 1.5933832
e 730 loss -22.07277 target loss -750.5248 other loss -81722.39 tv loss 3374.2046
next layer loss target loss 38.23467 other loss 16089.278
result 1 [11.74  8.53  2.22] neuron -219.51324 1.5933576
e 740 loss -22.07291 target loss -750.5366 other loss -81711.09 tv loss 3374.0732
next layer loss target loss 38.227165 other loss 16088.947
result 1 [11.74  8.53  2.22] neuron -219.51323 1.5931242
e 750 loss -22.073038 target loss -750.45465 other loss -81710.45 tv loss 3374.099
next layer loss target loss 38.231415 other loss 16090.174
result 1 [11.74  8.53  2.22] neuron -219.475 1.5931442
e 760 loss -22.073174 target loss -750.42395 other loss -81711.91 tv loss 3373.8481
next layer loss target loss 38.236267 other loss 16089.917
result 1 [11.74  8.54  2.22] neuron -219.47617 1.5934383
e 770 loss -22.073301 target loss -750.3905 other loss -81708.66 tv loss 3373.733
next layer loss target loss 38.233967 other loss 16089.789
result 1 [11.74  8.54  2.22] neuron -219.4666 1.5934564
e 780 loss -22.073404 target loss -750.3754 other loss -81714.59 tv loss 3374.0808
next layer loss target loss 38.24207 other loss 16092.088
result 1 [11.74  8.54  2.22] neuron -219.44652 1.5933048
e 790 loss -22.07354 target loss -750.4851 other loss -81715.19 tv loss 3374.178
next layer loss target loss 38.23745 other loss 16091.015
result 1 [11.74  8.54  2.22] neuron -219.49063 1.5934101
e 800 loss -22.073654 target loss -750.35516 other loss -81703.26 tv loss 3373.6726
next layer loss target loss 38.23587 other loss 16089.436
result 1 [11.74  8.54  2.22] neuron -219.44681 1.5932071
e 810 loss -22.073786 target loss -750.328 other loss -81732.81 tv loss 3374.724
next layer loss target loss 38.265972 other loss 16095.299
result 1 [11.74  8.55  2.23] neuron -219.41388 1.5938125
e 820 loss -22.073904 target loss -750.4667 other loss -81738.305 tv loss 3374.9924
next layer loss target loss 38.26449 other loss 16095.865
result 1 [11.74  8.55  2.23] neuron -219.45947 1.5938436
e 830 loss -22.074009 target loss -750.382 other loss -81726.44 tv loss 3374.5796
next layer loss target loss 38.262085 other loss 16094.756
result 1 [11.74  8.55  2.23] neuron -219.43515 1.5937037
e 840 loss -22.07412 target loss -750.4009 other loss -81730.61 tv loss 3374.6382
next layer loss target loss 38.26335 other loss 16094.469
result 1 [11.75  8.55  2.23] neuron -219.4379 1.5938088
e 850 loss -22.07422 target loss -750.39325 other loss -81737.805 tv loss 3374.7405
next layer loss target loss 38.268856 other loss 16095.221
result 1 [11.75  8.55  2.23] neuron -219.43948 1.5939046
e 860 loss -22.074314 target loss -750.45886 other loss -81737.11 tv loss 3374.837
next layer loss target loss 38.266006 other loss 16094.736
result 1 [11.75  8.55  2.23] neuron -219.46217 1.5939528
e 870 loss -22.074398 target loss -750.5294 other loss -81740.44 tv loss 3375.0254
next layer loss target loss 38.264557 other loss 16094.998
result 1 [11.75  8.55  2.23] neuron -219.48444 1.5940387
e 880 loss -22.074482 target loss -750.4855 other loss -81744.4 tv loss 3375.132
next layer loss target loss 38.272446 other loss 16096.633
result 1 [11.75  8.55  2.23] neuron -219.46101 1.59405
e 890 loss -22.074558 target loss -750.5194 other loss -81743.22 tv loss 3375.2183
next layer loss target loss 38.271275 other loss 16096.596
result 1 [11.75  8.55  2.23] neuron -219.4631 1.5940521
e 900 loss -22.074654 target loss -750.5321 other loss -81749.24 tv loss 3375.2083
next layer loss target loss 38.273758 other loss 16095.682
result 1 [11.75  8.55  2.23] neuron -219.48206 1.5942203
e 910 loss -22.074718 target loss -750.5036 other loss -81751.016 tv loss 3375.1636
next layer loss target loss 38.277138 other loss 16095.226
result 1 [11.75  8.54  2.23] neuron -219.47205 1.5942273
e 920 loss -22.074795 target loss -750.6075 other loss -81750.69 tv loss 3375.4458
next layer loss target loss 38.27638 other loss 16095.933
result 1 [11.75  8.54  2.23] neuron -219.50189 1.5942619
e 930 loss -22.074858 target loss -750.6065 other loss -81754.04 tv loss 3375.496
next layer loss target loss 38.279377 other loss 16095.3
result 1 [11.75  8.54  2.23] neuron -219.50122 1.5943055
e 940 loss -22.074936 target loss -750.5745 other loss -81755.266 tv loss 3375.4185
next layer loss target loss 38.28397 other loss 16095.323
result 1 [11.75  8.54  2.23] neuron -219.49313 1.5943482
e 950 loss -22.074972 target loss -750.56854 other loss -81743.484 tv loss 3375.3525
next layer loss target loss 38.27984 other loss 16096.322
result 1 [11.75  8.54  2.23] neuron -219.47873 1.5939893
e 960 loss -22.07507 target loss -750.57153 other loss -81747.47 tv loss 3375.2874
next layer loss target loss 38.28019 other loss 16094.698
result 1 [11.75  8.54  2.23] neuron -219.49063 1.5941412
e 970 loss -22.075066 target loss -750.4847 other loss -81754.914 tv loss 3375.1123
next layer loss target loss 38.28752 other loss 16093.004
result 1 [11.76  8.54  2.23] neuron -219.47855 1.5943742
e 980 loss -22.0752 target loss -750.49585 other loss -81739.98 tv loss 3375.209
next layer loss target loss 38.283325 other loss 16094.767
result 1 [11.75  8.54  2.23] neuron -219.45905 1.5938922
e 990 loss -22.075258 target loss -750.5 other loss -81745.72 tv loss 3375.2827
next layer loss target loss 38.287834 other loss 16094.767
result 1 [11.75  8.54  2.23] neuron -219.45976 1.5939729
RE filter conv2d_4 37 RE acc 0.3333333333333333
e 0 loss -23.276026 target loss -721.4981 other loss -97790.74 tv loss 3976.1335
next layer loss target loss 48.30115 other loss 17835.553
result 0 [6.08 0.16 7.83] neuron -283.93628 3.016661
e 10 loss -23.609184 target loss -675.39966 other loss -92626.75 tv loss 3806.7397
next layer loss target loss 51.16983 other loss 17442.576
result 0 [5.96 0.14 7.73] neuron -266.4355 3.0117035
e 20 loss -23.7649 target loss -649.5887 other loss -88776.27 tv loss 3664.2852
next layer loss target loss 50.775166 other loss 16983.889
result 0 [6.07 0.15 7.65] neuron -255.69652 2.9208703
e 30 loss -23.82753 target loss -633.54346 other loss -86596.09 tv loss 3571.2808
next layer loss target loss 50.353176 other loss 16705.047
result 0 [6.24 0.15 7.67] neuron -249.16 2.8665717
e 40 loss -23.849787 target loss -625.2219 other loss -85615.74 tv loss 3522.1873
next layer loss target loss 50.451805 other loss 16594.703
result 0 [6.25 0.15 7.69] neuron -245.96121 2.8521209
e 50 loss -23.863415 target loss -621.7573 other loss -85256.11 tv loss 3508.498
next layer loss target loss 50.86825 other loss 16569.629
result 0 [6.18 0.15 7.65] neuron -244.7183 2.8535066
e 60 loss -23.87776 target loss -620.7701 other loss -85188.68 tv loss 3512.3315
next layer loss target loss 51.163322 other loss 16578.035
result 0 [6.18 0.15 7.59] neuron -244.57144 2.8583608
e 70 loss -23.889692 target loss -620.1431 other loss -85219.625 tv loss 3516.96
next layer loss target loss 51.45024 other loss 16596.982
result 0 [6.18 0.15 7.56] neuron -244.67963 2.8658693
e 80 loss -23.899609 target loss -619.49536 other loss -85221.125 tv loss 3519.2087
next layer loss target loss 51.554474 other loss 16596.285
result 0 [6.16 0.15 7.52] neuron -244.60846 2.8661556
e 90 loss -23.907639 target loss -618.23785 other loss -85142.39 tv loss 3517.8333
next layer loss target loss 51.72935 other loss 16591.248
result 0 [6.15 0.16 7.49] neuron -244.31519 2.8671966
e 100 loss -23.9144 target loss -616.6283 other loss -84989.25 tv loss 3514.0073
next layer loss target loss 51.84657 other loss 16578.416
result 0 [6.14 0.16 7.46] neuron -243.86494 2.8659358
e 110 loss -23.91984 target loss -615.27783 other loss -84877.66 tv loss 3511.0037
next layer loss target loss 51.990784 other loss 16570.268
result 0 [6.13 0.16 7.43] neuron -243.48357 2.8670657
e 120 loss -23.924171 target loss -614.2606 other loss -84794.266 tv loss 3509.2083
next layer loss target loss 52.118504 other loss 16566.621
result 0 [6.12 0.16 7.4 ] neuron -243.25462 2.8682334
e 130 loss -23.927734 target loss -613.4807 other loss -84735.69 tv loss 3508.2444
next layer loss target loss 52.2081 other loss 16563.082
result 0 [6.11 0.16 7.38] neuron -243.08975 2.8686612
e 140 loss -23.930656 target loss -612.86255 other loss -84700.055 tv loss 3508.017
next layer loss target loss 52.289886 other loss 16561.771
result 0 [6.1  0.16 7.35] neuron -242.96112 2.869167
e 150 loss -23.932962 target loss -612.2716 other loss -84659.72 tv loss 3507.5205
next layer loss target loss 52.369873 other loss 16560.467
result 0 [6.09 0.16 7.33] neuron -242.84106 2.8700042
e 160 loss -23.934834 target loss -611.632 other loss -84608.28 tv loss 3506.6406
next layer loss target loss 52.45686 other loss 16558.82
result 0 [6.08 0.16 7.32] neuron -242.68062 2.870573
e 170 loss -23.936314 target loss -611.10284 other loss -84572.55 tv loss 3506.1423
next layer loss target loss 52.522816 other loss 16557.084
result 0 [6.08 0.16 7.3 ] neuron -242.54741 2.8710334
e 180 loss -23.937508 target loss -610.66785 other loss -84540.25 tv loss 3505.3071
next layer loss target loss 52.55112 other loss 16553.846
result 0 [6.07 0.16 7.29] neuron -242.44664 2.869986
e 190 loss -23.938488 target loss -610.29724 other loss -84513.125 tv loss 3504.6548
next layer loss target loss 52.577927 other loss 16551.543
result 0 [6.06 0.16 7.28] neuron -242.35544 2.8695273
e 200 loss -23.939327 target loss -609.8407 other loss -84468.57 tv loss 3503.5876
next layer loss target loss 52.607277 other loss 16548.041
result 0 [6.06 0.16 7.27] neuron -242.23305 2.8690128
e 210 loss -23.940002 target loss -609.46014 other loss -84435.86 tv loss 3503.0535
next layer loss target loss 52.657204 other loss 16546.934
result 0 [6.06 0.16 7.26] neuron -242.13222 2.8692782
e 220 loss -23.940601 target loss -609.3467 other loss -84426.58 tv loss 3503.5693
next layer loss target loss 52.678566 other loss 16546.312
result 0 [6.05 0.16 7.25] neuron -242.1041 2.8685842
e 230 loss -23.941135 target loss -609.2075 other loss -84424.66 tv loss 3503.6973
next layer loss target loss 52.713715 other loss 16547.895
result 0 [6.04 0.16 7.24] neuron -242.0812 2.8690538
e 240 loss -23.941624 target loss -608.9884 other loss -84412.5 tv loss 3503.7627
next layer loss target loss 52.752052 other loss 16547.611
result 0 [6.04 0.16 7.24] neuron -242.00424 2.8691032
e 250 loss -23.942093 target loss -608.83167 other loss -84404.586 tv loss 3503.6938
next layer loss target loss 52.784187 other loss 16548.625
result 0 [6.04 0.16 7.23] neuron -241.97229 2.8696856
e 260 loss -23.942543 target loss -608.8063 other loss -84423.71 tv loss 3504.7764
next layer loss target loss 52.838852 other loss 16553.531
result 0 [6.04 0.16 7.22] neuron -241.98882 2.8712096
e 270 loss -23.942936 target loss -608.6178 other loss -84416.66 tv loss 3505.1958
next layer loss target loss 52.903297 other loss 16555.928
result 0 [6.03 0.16 7.22] neuron -241.93893 2.8724232
e 280 loss -23.943304 target loss -608.64886 other loss -84439.84 tv loss 3506.4944
next layer loss target loss 52.959335 other loss 16560.932
result 0 [6.02 0.16 7.21] neuron -241.96875 2.8739576
e 290 loss -23.94365 target loss -608.4945 other loss -84426.71 tv loss 3506.3213
next layer loss target loss 52.9739 other loss 16560.168
result 0 [6.02 0.16 7.21] neuron -241.90613 2.873633
e 300 loss -23.943953 target loss -608.371 other loss -84410.734 tv loss 3505.8027
next layer loss target loss 52.965088 other loss 16557.625
result 0 [6.02 0.16 7.2 ] neuron -241.84648 2.8726506
e 310 loss -23.944239 target loss -608.2018 other loss -84394.7 tv loss 3505.3467
next layer loss target loss 52.983665 other loss 16556.701
result 0 [6.02 0.16 7.2 ] neuron -241.78317 2.8724618
e 320 loss -23.944519 target loss -608.14417 other loss -84398.87 tv loss 3505.7722
next layer loss target loss 53.004925 other loss 16557.672
result 0 [6.02 0.16 7.2 ] neuron -241.75255 2.8727229
e 330 loss -23.944773 target loss -607.98804 other loss -84384.914 tv loss 3505.3767
next layer loss target loss 53.01413 other loss 16556.207
result 0 [6.02 0.16 7.2 ] neuron -241.7034 2.87232
e 340 loss -23.945005 target loss -607.916 other loss -84375.06 tv loss 3505.2388
next layer loss target loss 53.017773 other loss 16555.242
result 0 [6.02 0.16 7.19] neuron -241.67596 2.8719742
e 350 loss -23.945227 target loss -607.77246 other loss -84365.36 tv loss 3505.1172
next layer loss target loss 53.04036 other loss 16555.344
result 0 [6.01 0.16 7.19] neuron -241.62732 2.8721278
e 360 loss -23.945429 target loss -607.7379 other loss -84351.06 tv loss 3504.829
next layer loss target loss 53.022568 other loss 16553.129
result 0 [6.01 0.16 7.19] neuron -241.60321 2.871233
e 370 loss -23.945633 target loss -607.6537 other loss -84346.805 tv loss 3504.8525
next layer loss target loss 53.04724 other loss 16554.188
result 0 [6.01 0.16 7.18] neuron -241.57483 2.871583
e 380 loss -23.945816 target loss -607.662 other loss -84351.31 tv loss 3505.1904
next layer loss target loss 53.056732 other loss 16555.504
result 0 [6.01 0.16 7.18] neuron -241.58292 2.8717716
e 390 loss -23.946 target loss -607.6358 other loss -84346.45 tv loss 3505.3418
next layer loss target loss 53.0574 other loss 16555.037
result 0 [6.01 0.16 7.18] neuron -241.57347 2.8714366
e 400 loss -23.946186 target loss -607.63605 other loss -84355.08 tv loss 3505.5637
next layer loss target loss 53.058914 other loss 16555.625
result 0 [6.01 0.16 7.18] neuron -241.57912 2.8714986
e 410 loss -23.946358 target loss -607.70056 other loss -84370.34 tv loss 3506.2607
next layer loss target loss 53.06632 other loss 16558.137
result 0 [6.02 0.16 7.18] neuron -241.62106 2.8721395
e 420 loss -23.946543 target loss -607.7662 other loss -84387.44 tv loss 3507.086
next layer loss target loss 53.08761 other loss 16561.0
result 0 [6.01 0.16 7.17] neuron -241.65399 2.8730464
e 430 loss -23.946705 target loss -607.63684 other loss -84377.55 tv loss 3506.753
next layer loss target loss 53.09773 other loss 16559.602
result 0 [6.01 0.16 7.17] neuron -241.60246 2.8729937
e 440 loss -23.946856 target loss -607.5842 other loss -84380.984 tv loss 3506.8516
next layer loss target loss 53.11698 other loss 16560.55
result 0 [6.01 0.16 7.17] neuron -241.58693 2.8735433
e 450 loss -23.946995 target loss -607.5352 other loss -84376.61 tv loss 3506.928
next layer loss target loss 53.128307 other loss 16560.814
result 0 [6.01 0.16 7.17] neuron -241.57329 2.8736267
e 460 loss -23.947123 target loss -607.4889 other loss -84368.8 tv loss 3506.6472
next layer loss target loss 53.1199 other loss 16559.955
result 0 [6.01 0.16 7.17] neuron -241.5598 2.8731368
e 470 loss -23.947247 target loss -607.51294 other loss -84375.7 tv loss 3507.0757
next layer loss target loss 53.12935 other loss 16561.129
result 0 [6.01 0.16 7.17] neuron -241.5668 2.873466
e 480 loss -23.947353 target loss -607.5194 other loss -84382.625 tv loss 3507.4
next layer loss target loss 53.13874 other loss 16562.492
result 0 [6.01 0.16 7.16] neuron -241.57114 2.8737912
e 490 loss -23.947468 target loss -607.5515 other loss -84382.78 tv loss 3507.3652
next layer loss target loss 53.124405 other loss 16561.566
result 0 [6.02 0.16 7.16] neuron -241.57965 2.8732758
e 500 loss -23.947565 target loss -607.5227 other loss -84387.99 tv loss 3507.591
next layer loss target loss 53.144196 other loss 16562.38
result 0 [6.01 0.16 7.16] neuron -241.56659 2.8737533
e 510 loss -23.94767 target loss -607.4871 other loss -84386.89 tv loss 3507.7095
next layer loss target loss 53.153603 other loss 16563.27
result 0 [6.01 0.16 7.16] neuron -241.56403 2.8739028
e 520 loss -23.947744 target loss -607.4248 other loss -84368.68 tv loss 3507.2856
next layer loss target loss 53.12937 other loss 16560.996
result 0 [6.02 0.16 7.16] neuron -241.53784 2.872889
e 530 loss -23.947836 target loss -607.32367 other loss -84375.88 tv loss 3507.347
next layer loss target loss 53.17323 other loss 16562.977
result 0 [6.01 0.16 7.16] neuron -241.50113 2.8743227
e 540 loss -23.94793 target loss -607.2976 other loss -84369.95 tv loss 3507.0535
next layer loss target loss 53.162292 other loss 16561.766
result 0 [6.02 0.16 7.16] neuron -241.49072 2.8739433
e 550 loss -23.94799 target loss -607.35315 other loss -84365.44 tv loss 3507.1558
next layer loss target loss 53.138474 other loss 16560.928
result 0 [6.02 0.16 7.16] neuron -241.50659 2.8730605
e 560 loss -23.94803 target loss -607.1824 other loss -84367.82 tv loss 3507.002
next layer loss target loss 53.19206 other loss 16562.914
result 0 [6.01 0.16 7.16] neuron -241.45682 2.8747103
e 570 loss -23.94811 target loss -607.1969 other loss -84364.94 tv loss 3506.9106
next layer loss target loss 53.181168 other loss 16561.857
result 0 [6.02 0.16 7.16] neuron -241.45393 2.8743117
e 580 loss -23.948181 target loss -607.2844 other loss -84358.56 tv loss 3506.9192
next layer loss target loss 53.13932 other loss 16560.547
result 0 [6.02 0.16 7.16] neuron -241.48024 2.8728411
e 590 loss -23.948246 target loss -607.2422 other loss -84361.87 tv loss 3507.0024
next layer loss target loss 53.159477 other loss 16561.6
result 0 [6.02 0.16 7.15] neuron -241.46556 2.8735645
e 600 loss -23.948296 target loss -607.1239 other loss -84355.83 tv loss 3506.8228
next layer loss target loss 53.179356 other loss 16561.623
result 0 [6.02 0.16 7.15] neuron -241.41734 2.8739765
e 610 loss -23.948353 target loss -606.9701 other loss -84331.984 tv loss 3505.8833
next layer loss target loss 53.164394 other loss 16558.324
result 0 [6.02 0.16 7.15] neuron -241.35912 2.8730817
e 620 loss -23.948414 target loss -606.9999 other loss -84335.44 tv loss 3506.0574
next layer loss target loss 53.165375 other loss 16559.12
result 0 [6.02 0.16 7.15] neuron -241.37195 2.8731775
e 630 loss -23.948448 target loss -606.91797 other loss -84326.72 tv loss 3505.783
next layer loss target loss 53.167442 other loss 16558.367
result 0 [6.02 0.16 7.15] neuron -241.34187 2.8730774
e 640 loss -23.948494 target loss -606.88354 other loss -84318.85 tv loss 3505.6038
next layer loss target loss 53.160778 other loss 16557.414
result 0 [6.02 0.16 7.15] neuron -241.33328 2.872674
e 650 loss -23.948532 target loss -606.85376 other loss -84316.21 tv loss 3505.6216
next layer loss target loss 53.166798 other loss 16558.21
result 0 [6.02 0.16 7.15] neuron -241.33734 2.8728178
e 660 loss -23.948572 target loss -606.8163 other loss -84316.016 tv loss 3505.4768
next layer loss target loss 53.16756 other loss 16557.223
result 0 [6.02 0.16 7.15] neuron -241.31656 2.8728485
e 670 loss -23.948616 target loss -606.7257 other loss -84310.836 tv loss 3505.3477
next layer loss target loss 53.184364 other loss 16557.66
result 0 [6.02 0.16 7.15] neuron -241.29073 2.8732731
e 680 loss -23.948643 target loss -606.697 other loss -84302.87 tv loss 3505.142
next layer loss target loss 53.172226 other loss 16556.484
result 0 [6.02 0.16 7.15] neuron -241.27905 2.872782
e 690 loss -23.948675 target loss -606.70544 other loss -84305.016 tv loss 3505.147
next layer loss target loss 53.174797 other loss 16556.379
result 0 [6.02 0.16 7.15] neuron -241.27802 2.8728883
e 700 loss -23.948706 target loss -606.65875 other loss -84295.62 tv loss 3504.9324
next layer loss target loss 53.170555 other loss 16556.09
result 0 [6.02 0.16 7.15] neuron -241.2675 2.872579
e 710 loss -23.948738 target loss -606.6844 other loss -84298.92 tv loss 3505.0215
next layer loss target loss 53.17073 other loss 16556.402
result 0 [6.02 0.16 7.15] neuron -241.276 2.872638
e 720 loss -23.948746 target loss -606.60364 other loss -84288.984 tv loss 3504.9321
next layer loss target loss 53.180412 other loss 16556.484
result 0 [6.02 0.16 7.15] neuron -241.24571 2.8726559
e 730 loss -23.948778 target loss -606.654 other loss -84292.46 tv loss 3504.9893
next layer loss target loss 53.170082 other loss 16556.326
result 0 [6.02 0.16 7.15] neuron -241.2598 2.872427
e 740 loss -23.948803 target loss -606.63464 other loss -84299.3 tv loss 3504.8257
next layer loss target loss 53.17986 other loss 16556.227
result 0 [6.02 0.16 7.15] neuron -241.25632 2.872922
e 750 loss -23.948833 target loss -606.66296 other loss -84297.08 tv loss 3504.8723
next layer loss target loss 53.16629 other loss 16555.934
result 0 [6.02 0.16 7.15] neuron -241.26947 2.8723884
e 760 loss -23.94886 target loss -606.58765 other loss -84295.06 tv loss 3505.0422
next layer loss target loss 53.19505 other loss 16557.496
result 0 [6.02 0.16 7.15] neuron -241.24738 2.8731246
e 770 loss -23.948889 target loss -606.6172 other loss -84291.38 tv loss 3504.904
next layer loss target loss 53.17209 other loss 16556.059
result 0 [6.02 0.16 7.15] neuron -241.24886 2.8723316
e 780 loss -23.948904 target loss -606.65497 other loss -84295.17 tv loss 3505.0667
next layer loss target loss 53.170216 other loss 16556.348
result 0 [6.02 0.16 7.15] neuron -241.26093 2.872244
e 790 loss -23.94892 target loss -606.65466 other loss -84292.91 tv loss 3504.9175
next layer loss target loss 53.159344 other loss 16555.564
result 0 [6.02 0.16 7.15] neuron -241.26167 2.8718543
e 800 loss -23.948956 target loss -606.58734 other loss -84293.25 tv loss 3505.001
next layer loss target loss 53.186634 other loss 16556.701
result 0 [6.02 0.16 7.15] neuron -241.23906 2.872586
e 810 loss -23.94896 target loss -606.5956 other loss -84288.86 tv loss 3504.9265
next layer loss target loss 53.174347 other loss 16556.262
result 0 [6.02 0.16 7.15] neuron -241.24292 2.872081
e 820 loss -23.948982 target loss -606.61285 other loss -84294.25 tv loss 3504.8105
next layer loss target loss 53.170105 other loss 16555.465
result 0 [6.02 0.16 7.15] neuron -241.2435 2.8721297
e 830 loss -23.949013 target loss -606.5641 other loss -84293.22 tv loss 3504.9585
next layer loss target loss 53.187088 other loss 16556.66
result 0 [6.02 0.16 7.15] neuron -241.23277 2.8725116
e 840 loss -23.94903 target loss -606.5408 other loss -84286.266 tv loss 3504.9185
next layer loss target loss 53.18609 other loss 16556.271
result 0 [6.02 0.16 7.14] neuron -241.22131 2.8723118
e 850 loss -23.94906 target loss -606.4806 other loss -84286.19 tv loss 3504.7817
next layer loss target loss 53.204964 other loss 16556.8
result 0 [6.02 0.16 7.14] neuron -241.20607 2.8729537
e 860 loss -23.949066 target loss -606.53296 other loss -84286.62 tv loss 3504.7817
next layer loss target loss 53.188507 other loss 16555.625
result 0 [6.02 0.16 7.14] neuron -241.21146 2.872427
e 870 loss -23.949074 target loss -606.46765 other loss -84278.86 tv loss 3504.5745
next layer loss target loss 53.18499 other loss 16554.941
result 0 [6.02 0.16 7.14] neuron -241.189 2.8722875
e 880 loss -23.949112 target loss -606.4365 other loss -84276.1 tv loss 3504.6367
next layer loss target loss 53.19879 other loss 16556.045
result 0 [6.02 0.16 7.14] neuron -241.19528 2.8725173
e 890 loss -23.94912 target loss -606.4279 other loss -84272.67 tv loss 3504.5005
next layer loss target loss 53.19229 other loss 16555.082
result 0 [6.02 0.16 7.14] neuron -241.18341 2.8722308
e 900 loss -23.949139 target loss -606.383 other loss -84276.03 tv loss 3504.5698
next layer loss target loss 53.20937 other loss 16556.023
result 0 [6.02 0.16 7.14] neuron -241.16779 2.872832
e 910 loss -23.949156 target loss -606.3923 other loss -84280.74 tv loss 3504.7393
next layer loss target loss 53.221832 other loss 16556.68
result 0 [6.02 0.16 7.14] neuron -241.17242 2.873259
e 920 loss -23.949177 target loss -606.33606 other loss -84271.01 tv loss 3504.29
next layer loss target loss 53.210976 other loss 16555.469
result 0 [6.02 0.16 7.14] neuron -241.15308 2.872657
e 930 loss -23.949167 target loss -606.3627 other loss -84275.836 tv loss 3504.2998
next layer loss target loss 53.214287 other loss 16555.074
result 0 [6.02 0.16 7.14] neuron -241.15196 2.8728905
e 940 loss -23.949165 target loss -606.2054 other loss -84266.03 tv loss 3504.4338
next layer loss target loss 53.25015 other loss 16556.941
result 0 [6.02 0.16 7.14] neuron -241.10165 2.8735802
e 950 loss -23.949078 target loss -606.56616 other loss -84279.39 tv loss 3504.496
next layer loss target loss 53.154263 other loss 16552.486
result 0 [6.02 0.16 7.14] neuron -241.19257 2.8709662
e 960 loss -23.949194 target loss -606.3282 other loss -84260.53 tv loss 3504.0078
next layer loss target loss 53.201523 other loss 16553.945
result 0 [6.02 0.16 7.14] neuron -241.1338 2.8720677
e 970 loss -23.949194 target loss -606.114 other loss -84251.87 tv loss 3504.0676
next layer loss target loss 53.250656 other loss 16556.314
result 0 [6.02 0.16 7.14] neuron -241.0708 2.873215
e 980 loss -23.949219 target loss -606.29987 other loss -84278.08 tv loss 3504.4087
next layer loss target loss 53.232002 other loss 16555.133
result 0 [6.02 0.16 7.14] neuron -241.10452 2.8731098
e 990 loss -23.94928 target loss -606.30524 other loss -84269.64 tv loss 3504.3887
next layer loss target loss 53.227524 other loss 16555.602
result 0 [6.02 0.16 7.14] neuron -241.12982 2.8728826
RE filter conv2d_4 167 RE acc 0.0
e 0 loss -37.940533 target loss 79.786316 other loss 11197.195 tv loss 3976.1335
next layer loss target loss 715.8581 other loss 147922.22
result 1 [12.2   8.22  1.93] neuron 268.31873 2.1100914
e 10 loss -40.887367 target loss 367.3814 other loss 14135.584 tv loss 3952.5176
next layer loss target loss 931.6226 other loss 157127.98
result 1 [12.39  8.86  1.96] neuron 385.21567 2.2591372
e 20 loss -43.30053 target loss 570.88696 other loss 15521.204 tv loss 3929.7634
next layer loss target loss 1102.6266 other loss 165797.02
result 1 [12.11  9.    1.92] neuron 478.18958 2.3345616
e 30 loss -45.580704 target loss 771.6226 other loss 16602.605 tv loss 3912.3882
next layer loss target loss 1273.5834 other loss 175182.98
result 1 [11.98  8.9   1.91] neuron 568.05084 2.3766649
e 40 loss -47.789703 target loss 982.7544 other loss 17604.188 tv loss 3870.3242
next layer loss target loss 1450.1075 other loss 185052.12
result 1 [11.85  8.89  1.97] neuron 656.57776 2.3828688
e 50 loss -49.970078 target loss 1195.9869 other loss 18664.98 tv loss 3778.9465
next layer loss target loss 1623.5533 other loss 194728.81
result 1 [11.4   8.24  2.08] neuron 739.1303 2.3809571
e 60 loss -51.975143 target loss 1392.9598 other loss 19832.074 tv loss 3642.1953
next layer loss target loss 1779.5482 other loss 203131.5
result 1 [10.64  7.67  2.28] neuron 811.0985 2.3659937
e 70 loss -50.129917 target loss 1295.1074 other loss 15589.832 tv loss 3730.5679
next layer loss target loss 1707.5559 other loss 195618.34
result 1 [10.96  7.92  2.1 ] neuron 782.5267 2.3723795
e 80 loss -48.92838 target loss 1227.0883 other loss 13343.367 tv loss 3789.4045
next layer loss target loss 1658.0349 other loss 191541.38
result 1 [11.17  8.16  2.  ] neuron 762.33704 2.3792834
e 90 loss -48.652466 target loss 1207.525 other loss 12654.606 tv loss 3808.298
next layer loss target loss 1645.4523 other loss 190574.98
result 1 [11.2   8.21  1.95] neuron 757.85095 2.3820822
e 100 loss -48.714268 target loss 1206.5072 other loss 12537.29 tv loss 3816.3147
next layer loss target loss 1647.088 other loss 190771.92
result 1 [11.19  8.2   1.93] neuron 759.4884 2.3848891
e 110 loss -48.905903 target loss 1212.5327 other loss 12638.957 tv loss 3820.4265
next layer loss target loss 1654.1411 other loss 191415.08
result 1 [11.16  8.16  1.91] neuron 763.47986 2.3874915
e 120 loss -49.134853 target loss 1220.5325 other loss 12834.131 tv loss 3821.4868
next layer loss target loss 1662.3217 other loss 192153.3
result 1 [11.13  8.11  1.89] neuron 767.9416 2.3901343
e 130 loss -49.388054 target loss 1229.5823 other loss 13072.684 tv loss 3821.814
next layer loss target loss 1671.291 other loss 192968.25
result 1 [11.1   8.05  1.88] neuron 772.7747 2.393203
e 140 loss -49.65686 target loss 1239.1826 other loss 13337.809 tv loss 3821.751
next layer loss target loss 1680.7043 other loss 193833.56
result 1 [11.06  8.    1.87] neuron 777.8168 2.3960402
e 150 loss -49.93605 target loss 1249.1001 other loss 13624.82 tv loss 3820.9092
next layer loss target loss 1690.3792 other loss 194732.88
result 1 [11.02  7.96  1.86] neuron 782.9718 2.398578
e 160 loss -50.22266 target loss 1259.2207 other loss 13929.832 tv loss 3819.4648
next layer loss target loss 1700.2225 other loss 195661.05
result 1 [10.98  7.91  1.85] neuron 788.20215 2.401096
e 170 loss -50.514076 target loss 1269.4836 other loss 14249.821 tv loss 3817.5125
next layer loss target loss 1710.188 other loss 196616.12
result 1 [10.93  7.86  1.84] neuron 793.496 2.4037092
e 180 loss -50.8071 target loss 1279.7957 other loss 14582.139 tv loss 3815.313
next layer loss target loss 1720.194 other loss 197592.31
result 1 [10.89  7.81  1.83] neuron 798.82336 2.406407
e 190 loss -51.09195 target loss 1289.6958 other loss 14913.454 tv loss 3812.1985
next layer loss target loss 1729.5605 other loss 198528.95
result 1 [10.84  7.77  1.82] neuron 803.90625 2.4085615
e 200 loss -51.373245 target loss 1299.5099 other loss 15249.755 tv loss 3808.8755
next layer loss target loss 1738.7883 other loss 199469.08
result 1 [10.8   7.73  1.8 ] neuron 808.96173 2.4105656
e 210 loss -51.65163 target loss 1309.31 other loss 15590.232 tv loss 3805.5317
next layer loss target loss 1748.0107 other loss 200422.27
result 1 [10.76  7.68  1.78] neuron 813.9874 2.4125278
e 220 loss -51.92222 target loss 1319.0941 other loss 15930.471 tv loss 3801.9512
next layer loss target loss 1757.2476 other loss 201384.11
result 1 [10.72  7.65  1.77] neuron 819.0066 2.4144351
e 230 loss -52.178284 target loss 1328.8282 other loss 16265.259 tv loss 3798.2544
next layer loss target loss 1766.4619 other loss 202347.88
result 1 [10.68  7.61  1.75] neuron 824.02203 2.4162517
e 240 loss -52.412663 target loss 1338.4255 other loss 16586.4 tv loss 3794.3262
next layer loss target loss 1775.5712 other loss 203299.7
result 1 [10.65  7.58  1.73] neuron 828.9885 2.4179337
e 250 loss -52.619244 target loss 1347.7668 other loss 16881.453 tv loss 3790.4702
next layer loss target loss 1784.4928 other loss 204220.42
result 1 [10.62  7.56  1.71] neuron 833.86194 2.4194288
e 260 loss -52.79641 target loss 1356.7457 other loss 17137.8 tv loss 3786.6885
next layer loss target loss 1793.1414 other loss 205089.73
result 1 [10.59  7.53  1.7 ] neuron 838.6035 2.4206865
e 270 loss -52.9495 target loss 1365.2814 other loss 17348.72 tv loss 3782.9326
next layer loss target loss 1801.444 other loss 205893.12
result 1 [10.57  7.51  1.68] neuron 843.176 2.421691
e 280 loss -53.08533 target loss 1373.3914 other loss 17515.22 tv loss 3779.2407
next layer loss target loss 1809.4088 other loss 206630.1
result 1 [10.54  7.49  1.67] neuron 847.5781 2.4224544
e 290 loss -53.21012 target loss 1381.0739 other loss 17643.477 tv loss 3775.6584
next layer loss target loss 1817.0176 other loss 207304.19
result 1 [10.52  7.48  1.65] neuron 851.7896 2.423025
e 300 loss -53.328156 target loss 1388.4232 other loss 17741.178 tv loss 3772.2495
next layer loss target loss 1824.3602 other loss 207927.02
result 1 [10.5   7.46  1.64] neuron 855.85364 2.4234579
e 310 loss -53.441666 target loss 1395.5215 other loss 17816.164 tv loss 3768.9226
next layer loss target loss 1831.4976 other loss 208510.02
result 1 [10.47  7.44  1.62] neuron 859.80225 2.4238043
e 320 loss -53.55175 target loss 1402.3936 other loss 17875.553 tv loss 3765.6326
next layer loss target loss 1838.4443 other loss 209060.61
result 1 [10.45  7.42  1.61] neuron 863.6368 2.424102
e 330 loss -53.658947 target loss 1409.0768 other loss 17924.848 tv loss 3762.3865
next layer loss target loss 1845.2297 other loss 209585.34
result 1 [10.44  7.4   1.6 ] neuron 867.34186 2.4243743
e 340 loss -53.761417 target loss 1415.5613 other loss 17967.992 tv loss 3759.1965
next layer loss target loss 1851.8215 other loss 210085.44
result 1 [10.43  7.38  1.59] neuron 870.8994 2.4246309
e 350 loss -53.859344 target loss 1421.8683 other loss 18007.562 tv loss 3755.9802
next layer loss target loss 1858.2256 other loss 210564.48
result 1 [10.42  7.36  1.58] neuron 874.321 2.4248796
e 360 loss -53.95304 target loss 1428.0209 other loss 18045.14 tv loss 3752.8774
next layer loss target loss 1864.4652 other loss 211027.14
result 1 [10.42  7.34  1.57] neuron 877.62775 2.425127
e 370 loss -54.042778 target loss 1434.0615 other loss 18081.188 tv loss 3749.8135
next layer loss target loss 1870.5817 other loss 211477.27
result 1 [10.41  7.32  1.56] neuron 880.84143 2.425382
e 380 loss -54.129234 target loss 1440.0167 other loss 18116.615 tv loss 3746.7756
next layer loss target loss 1876.5979 other loss 211917.39
result 1 [10.41  7.29  1.55] neuron 883.9813 2.4256432
e 390 loss -54.213425 target loss 1445.8811 other loss 18151.715 tv loss 3743.6848
next layer loss target loss 1882.5098 other loss 212347.77
result 1 [10.4   7.27  1.54] neuron 887.03705 2.4259133
e 400 loss -54.296326 target loss 1451.6699 other loss 18186.527 tv loss 3740.5962
next layer loss target loss 1888.3464 other loss 212770.17
result 1 [10.39  7.25  1.54] neuron 890.02325 2.4261963
e 410 loss -54.37803 target loss 1457.41 other loss 18221.082 tv loss 3737.425
next layer loss target loss 1894.1278 other loss 213186.78
result 1 [10.39  7.23  1.53] neuron 892.96936 2.4264953
e 420 loss -54.45792 target loss 1463.0625 other loss 18255.697 tv loss 3734.274
next layer loss target loss 1899.8234 other loss 213595.45
result 1 [10.38  7.22  1.53] neuron 895.8504 2.4268024
e 430 loss -54.536163 target loss 1468.6361 other loss 18290.334 tv loss 3731.2546
next layer loss target loss 1905.4393 other loss 213997.75
result 1 [10.37  7.21  1.52] neuron 898.67847 2.427115
e 440 loss -54.612133 target loss 1474.1332 other loss 18325.098 tv loss 3728.0889
next layer loss target loss 1910.9606 other loss 214391.73
result 1 [10.36  7.2   1.51] neuron 901.4376 2.4274225
e 450 loss -54.686478 target loss 1479.5746 other loss 18360.375 tv loss 3724.8926
next layer loss target loss 1916.4124 other loss 214779.12
result 1 [10.35  7.19  1.51] neuron 904.1427 2.4277124
e 460 loss -54.75914 target loss 1484.948 other loss 18396.322 tv loss 3721.5845
next layer loss target loss 1921.7894 other loss 215159.77
result 1 [10.35  7.19  1.5 ] neuron 906.8076 2.4279916
e 470 loss -54.830696 target loss 1490.2732 other loss 18432.684 tv loss 3718.315
next layer loss target loss 1927.1075 other loss 215535.72
result 1 [10.34  7.18  1.49] neuron 909.4293 2.4282649
e 480 loss -54.900383 target loss 1495.5388 other loss 18469.512 tv loss 3715.025
next layer loss target loss 1932.355 other loss 215905.66
result 1 [10.34  7.17  1.49] neuron 911.9979 2.4285295
e 490 loss -54.96833 target loss 1500.7689 other loss 18506.488 tv loss 3711.6777
next layer loss target loss 1937.5537 other loss 216271.16
result 1 [10.34  7.16  1.48] neuron 914.5356 2.4287844
e 500 loss -55.03412 target loss 1505.924 other loss 18543.447 tv loss 3708.2493
next layer loss target loss 1942.667 other loss 216629.12
result 1 [10.33  7.15  1.47] neuron 917.03033 2.4290316
e 510 loss -55.098183 target loss 1510.9999 other loss 18580.422 tv loss 3704.7715
next layer loss target loss 1947.6908 other loss 216979.73
result 1 [10.33  7.15  1.47] neuron 919.46826 2.429272
e 520 loss -55.161217 target loss 1516.0006 other loss 18617.23 tv loss 3701.3103
next layer loss target loss 1952.6299 other loss 217324.27
result 1 [10.32  7.14  1.46] neuron 921.85425 2.4295127
e 530 loss -55.222427 target loss 1520.9165 other loss 18653.938 tv loss 3697.6782
next layer loss target loss 1957.4801 other loss 217661.44
result 1 [10.32  7.13  1.45] neuron 924.17664 2.4297526
e 540 loss -55.28238 target loss 1525.7318 other loss 18690.41 tv loss 3694.0469
next layer loss target loss 1962.2227 other loss 217990.89
result 1 [10.31  7.13  1.45] neuron 926.42474 2.4299943
e 550 loss -55.340454 target loss 1530.4517 other loss 18726.957 tv loss 3690.3306
next layer loss target loss 1966.863 other loss 218312.3
result 1 [10.3   7.12  1.44] neuron 928.5861 2.4302366
e 560 loss -55.39653 target loss 1535.0842 other loss 18763.324 tv loss 3686.3677
next layer loss target loss 1971.4031 other loss 218625.06
result 1 [10.3   7.12  1.44] neuron 930.6804 2.4304664
e 570 loss -55.451344 target loss 1539.647 other loss 18799.533 tv loss 3682.3323
next layer loss target loss 1975.8624 other loss 218931.36
result 1 [10.29  7.12  1.43] neuron 932.7189 2.4306884
e 580 loss -55.50518 target loss 1544.1516 other loss 18835.545 tv loss 3678.285
next layer loss target loss 1980.2556 other loss 219232.73
result 1 [10.28  7.11  1.43] neuron 934.7206 2.4309044
e 590 loss -55.557724 target loss 1548.589 other loss 18871.715 tv loss 3674.231
next layer loss target loss 1984.5809 other loss 219528.48
result 1 [10.27  7.12  1.42] neuron 936.6825 2.4311078
e 600 loss -55.609257 target loss 1552.9679 other loss 18907.846 tv loss 3670.21
next layer loss target loss 1988.8408 other loss 219818.84
result 1 [10.27  7.11  1.42] neuron 938.6134 2.4313006
e 610 loss -55.659718 target loss 1557.2845 other loss 18943.756 tv loss 3666.169
next layer loss target loss 1993.0383 other loss 220104.47
result 1 [10.26  7.11  1.41] neuron 940.5062 2.4314926
e 620 loss -55.709198 target loss 1561.5518 other loss 18979.348 tv loss 3662.1377
next layer loss target loss 1997.1816 other loss 220385.95
result 1 [10.26  7.11  1.41] neuron 942.3646 2.4316835
e 630 loss -55.757362 target loss 1565.7588 other loss 19014.824 tv loss 3658.096
next layer loss target loss 2001.2528 other loss 220662.3
result 1 [10.25  7.11  1.41] neuron 944.17816 2.4318717
e 640 loss -55.804024 target loss 1569.8949 other loss 19049.86 tv loss 3654.0652
next layer loss target loss 2005.2429 other loss 220932.69
result 1 [10.25  7.11  1.4 ] neuron 945.942 2.4320602
e 650 loss -55.84919 target loss 1573.951 other loss 19084.58 tv loss 3650.118
next layer loss target loss 2009.1384 other loss 221195.98
result 1 [10.24  7.1   1.4 ] neuron 947.65576 2.4322453
e 660 loss -55.893425 target loss 1577.9524 other loss 19119.037 tv loss 3646.2302
next layer loss target loss 2012.973 other loss 221454.2
result 1 [10.24  7.1   1.39] neuron 949.3248 2.4324234
e 670 loss -53.539185 target loss 1315.212 other loss 14136.976 tv loss 3896.397
next layer loss target loss 1815.3198 other loss 210234.27
result 1 [10.58  6.61  1.36] neuron 874.1057 2.5097408
e 680 loss -49.5726 target loss 1106.6382 other loss 13661.241 tv loss 4040.416
next layer loss target loss 1657.8843 other loss 205836.56
result 1 [10.76  6.12  1.31] neuron 808.54346 2.555641
e 690 loss -47.51573 target loss 1031.0066 other loss 13473.131 tv loss 4085.7026
next layer loss target loss 1600.9214 other loss 204229.7
result 1 [10.7   5.85  1.28] neuron 783.076 2.5446026
e 700 loss -46.946827 target loss 1010.52405 other loss 13464.349 tv loss 4100.883
next layer loss target loss 1586.1482 other loss 203914.89
result 1 [10.69  5.77  1.27] neuron 776.504 2.5391688
e 710 loss -46.922913 target loss 1010.5852 other loss 13527.556 tv loss 4105.845
next layer loss target loss 1587.276 other loss 204110.14
result 1 [10.71  5.78  1.26] neuron 777.12463 2.5420008
e 720 loss -47.09271 target loss 1017.9672 other loss 13616.242 tv loss 4107.258
next layer loss target loss 1594.076 other loss 204488.97
result 1 [10.73  5.82  1.26] neuron 780.30664 2.5472913
e 730 loss -47.32911 target loss 1027.8689 other loss 13713.82 tv loss 4107.341
next layer loss target loss 1602.8065 other loss 204929.22
result 1 [10.76  5.88  1.27] neuron 784.36346 2.5534418
e 740 loss -47.58681 target loss 1038.6002 other loss 13814.538 tv loss 4106.8203
next layer loss target loss 1612.1484 other loss 205389.53
result 1 [10.78  5.93  1.27] neuron 788.68445 2.5598762
e 750 loss -47.849068 target loss 1049.5242 other loss 13916.105 tv loss 4105.887
next layer loss target loss 1621.5916 other loss 205850.8
result 1 [10.81  5.98  1.27] neuron 793.0431 2.5659816
e 760 loss -48.110847 target loss 1060.404 other loss 14016.56 tv loss 4104.8477
next layer loss target loss 1630.9469 other loss 206304.7
result 1 [10.83  6.03  1.28] neuron 797.3533 2.5688133
e 770 loss -48.37211 target loss 1071.2532 other loss 14117.331 tv loss 4103.864
next layer loss target loss 1640.245 other loss 206756.16
result 1 [10.85  6.08  1.28] neuron 801.63574 2.5715594
e 780 loss -48.633316 target loss 1082.0306 other loss 14219.843 tv loss 4102.608
next layer loss target loss 1649.4497 other loss 207200.97
result 1 [10.88  6.13  1.28] neuron 805.8787 2.574007
e 790 loss -48.894974 target loss 1092.7552 other loss 14324.239 tv loss 4101.0815
next layer loss target loss 1658.5819 other loss 207642.05
result 1 [10.9   6.18  1.28] neuron 810.06995 2.576351
e 800 loss -49.15497 target loss 1103.4193 other loss 14429.875 tv loss 4099.353
next layer loss target loss 1667.6409 other loss 208080.34
result 1 [10.91  6.23  1.29] neuron 814.20984 2.5781322
e 810 loss -49.40934 target loss 1113.9382 other loss 14534.801 tv loss 4097.5596
next layer loss target loss 1676.5698 other loss 208511.08
result 1 [10.93  6.28  1.29] neuron 818.2815 2.579386
e 820 loss -49.65233 target loss 1124.2546 other loss 14636.762 tv loss 4095.669
next layer loss target loss 1685.3169 other loss 208934.72
result 1 [10.94  6.33  1.29] neuron 822.24994 2.5806406
e 830 loss -49.87951 target loss 1134.2308 other loss 14732.34 tv loss 4093.6929
next layer loss target loss 1693.7676 other loss 209345.03
result 1 [10.94  6.38  1.29] neuron 826.0539 2.5819285
e 840 loss -50.09073 target loss 1143.8107 other loss 14819.93 tv loss 4091.7725
next layer loss target loss 1701.8927 other loss 209741.03
result 1 [10.94  6.42  1.29] neuron 829.68567 2.58329
e 850 loss -50.286667 target loss 1153.0297 other loss 14899.508 tv loss 4089.794
next layer loss target loss 1709.7301 other loss 210125.1
result 1 [10.94  6.46  1.29] neuron 833.15796 2.5843086
e 860 loss -50.46837 target loss 1161.8923 other loss 14970.895 tv loss 4087.8696
next layer loss target loss 1717.2859 other loss 210497.02
result 1 [10.93  6.49  1.3 ] neuron 836.49243 2.5845838
e 870 loss -50.639076 target loss 1170.4452 other loss 15035.404 tv loss 4085.9858
next layer loss target loss 1724.6016 other loss 210858.67
result 1 [10.94  6.52  1.3 ] neuron 839.7063 2.584676
e 880 loss -50.8011 target loss 1178.7024 other loss 15094.361 tv loss 4084.1113
next layer loss target loss 1731.6846 other loss 211209.56
result 1 [10.94  6.55  1.3 ] neuron 842.7981 2.584483
e 890 loss -50.95694 target loss 1186.7214 other loss 15149.037 tv loss 4082.2646
next layer loss target loss 1738.5703 other loss 211551.86
result 1 [10.94  6.57  1.3 ] neuron 845.7743 2.5841491
e 900 loss -51.107765 target loss 1194.5654 other loss 15200.1045 tv loss 4080.3447
next layer loss target loss 1745.3025 other loss 211887.62
result 1 [10.95  6.6   1.3 ] neuron 848.67737 2.5838926
e 910 loss -51.253746 target loss 1202.2446 other loss 15248.155 tv loss 4078.3586
next layer loss target loss 1751.8904 other loss 212216.31
result 1 [10.95  6.61  1.3 ] neuron 851.50635 2.5836751
e 920 loss -51.395996 target loss 1209.7585 other loss 15293.683 tv loss 4076.2446
next layer loss target loss 1758.3298 other loss 212537.06
result 1 [10.96  6.63  1.3 ] neuron 854.2557 2.5834906
e 930 loss -51.534584 target loss 1217.1221 other loss 15337.079 tv loss 4074.0222
next layer loss target loss 1764.6359 other loss 212850.84
result 1 [10.96  6.64  1.3 ] neuron 856.95105 2.5833344
e 940 loss -51.66972 target loss 1224.3356 other loss 15378.332 tv loss 4071.8462
next layer loss target loss 1770.8113 other loss 213157.45
result 1 [10.96  6.65  1.3 ] neuron 859.5742 2.5832074
e 950 loss -51.80208 target loss 1231.4124 other loss 15417.636 tv loss 4069.663
next layer loss target loss 1776.8701 other loss 213456.94
result 1 [10.96  6.67  1.3 ] neuron 862.13245 2.583114
e 960 loss -51.93116 target loss 1238.3655 other loss 15454.76 tv loss 4067.4724
next layer loss target loss 1782.8204 other loss 213751.14
result 1 [10.95  6.67  1.3 ] neuron 864.63995 2.5830586
e 970 loss -52.056686 target loss 1245.1925 other loss 15489.148 tv loss 4065.2212
next layer loss target loss 1788.6656 other loss 214040.69
result 1 [10.95  6.68  1.3 ] neuron 867.1005 2.5830553
e 980 loss -52.17829 target loss 1251.8734 other loss 15520.353 tv loss 4062.8308
next layer loss target loss 1794.3887 other loss 214324.12
result 1 [10.95  6.69  1.3 ] neuron 869.50073 2.5827575
e 990 loss -52.295837 target loss 1258.3835 other loss 15548.453 tv loss 4060.3994
next layer loss target loss 1799.9792 other loss 214600.66
result 1 [10.95  6.7   1.3 ] neuron 871.8341 2.5820625
RE filter conv2d_1 44 RE acc 0.3333333333333333
e 0 loss -0.154562 target loss -2986.4927 other loss -203994.02 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -1013.65967 -0.6395594
e 10 loss -0.20236588 target loss -2977.2805 other loss -203528.25 tv loss 3977.0356
next layer loss target loss 0.0 other loss 9237.363
result 1 [12.18  8.04  1.84] neuron -1007.86255 -0.6363415
e 20 loss -0.22312355 target loss -2973.5693 other loss -202678.62 tv loss 3957.617
next layer loss target loss 0.0 other loss 9233.446
result 1 [12.15  7.95  1.79] neuron -1005.34076 -0.63517356
e 30 loss -0.2345829 target loss -2970.9534 other loss -202276.36 tv loss 3953.71
next layer loss target loss 0.0 other loss 9224.211
result 1 [12.12  7.92  1.77] neuron -1003.7272 -0.6323091
e 40 loss -0.24460411 target loss -2970.3013 other loss -202389.92 tv loss 3958.0742
next layer loss target loss 0.0 other loss 9225.875
result 1 [12.13  7.92  1.77] neuron -1003.83826 -0.6316572
e 50 loss -0.25385475 target loss -2969.7617 other loss -202404.38 tv loss 3959.3271
next layer loss target loss 0.0 other loss 9213.166
result 1 [12.15  7.93  1.78] neuron -1003.8346 -0.6315188
e 60 loss -0.261034 target loss -2968.956 other loss -202450.11 tv loss 3961.148
next layer loss target loss 0.0 other loss 9205.597
result 1 [12.16  7.9   1.78] neuron -1003.834 -0.63183236
e 70 loss -0.26706505 target loss -2967.8093 other loss -202371.0 tv loss 3959.3499
next layer loss target loss 0.0 other loss 9195.701
result 1 [12.16  7.89  1.78] neuron -1003.48254 -0.63158107
e 80 loss -0.27195358 target loss -2966.6963 other loss -202294.19 tv loss 3958.1274
next layer loss target loss 0.0 other loss 9187.665
result 1 [12.17  7.88  1.78] neuron -1003.113 -0.6311995
e 90 loss -0.27593803 target loss -2965.8647 other loss -202267.64 tv loss 3957.7612
next layer loss target loss 0.0 other loss 9181.682
result 1 [12.17  7.87  1.79] neuron -1002.92114 -0.6308738
e 100 loss -0.27915382 target loss -2965.1975 other loss -202260.2 tv loss 3957.712
next layer loss target loss 0.0 other loss 9176.305
result 1 [12.18  7.86  1.79] neuron -1002.7977 -0.63068664
e 110 loss -0.28175735 target loss -2964.459 other loss -202235.14 tv loss 3957.5022
next layer loss target loss 0.0 other loss 9173.0
result 1 [12.18  7.85  1.79] neuron -1002.5584 -0.6303414
e 120 loss -0.283926 target loss -2963.7131 other loss -202192.97 tv loss 3957.2998
next layer loss target loss 0.0 other loss 9171.003
result 1 [12.18  7.85  1.79] neuron -1002.24054 -0.6297639
e 130 loss -0.2857895 target loss -2962.971 other loss -202173.64 tv loss 3957.5825
next layer loss target loss 0.0 other loss 9172.646
result 1 [12.18  7.85  1.78] neuron -1001.90063 -0.62917626
e 140 loss -0.2873726 target loss -2962.3767 other loss -202139.03 tv loss 3957.5234
next layer loss target loss 0.0 other loss 9171.02
result 1 [12.18  7.85  1.78] neuron -1001.6347 -0.6287271
e 150 loss -0.28877258 target loss -2961.842 other loss -202125.72 tv loss 3957.7134
next layer loss target loss 0.0 other loss 9171.919
result 1 [12.18  7.84  1.78] neuron -1001.3938 -0.62826836
e 160 loss -0.29001045 target loss -2961.3474 other loss -202104.62 tv loss 3957.545
next layer loss target loss 0.0 other loss 9172.148
result 1 [12.18  7.84  1.78] neuron -1001.1647 -0.628041
e 170 loss -0.29113197 target loss -2960.9448 other loss -202018.69 tv loss 3956.0732
next layer loss target loss 0.0 other loss 9165.356
result 1 [12.18  7.84  1.78] neuron -1000.9712 -0.6276654
e 180 loss -0.29211807 target loss -2960.65 other loss -202027.94 tv loss 3956.3403
next layer loss target loss 0.0 other loss 9165.65
result 1 [12.19  7.84  1.78] neuron -1000.8773 -0.627577
e 190 loss -0.29302597 target loss -2960.3262 other loss -202022.6 tv loss 3956.738
next layer loss target loss 0.0 other loss 9165.961
result 1 [12.19  7.83  1.78] neuron -1000.72473 -0.62742203
e 200 loss -0.29383087 target loss -2959.994 other loss -202013.3 tv loss 3956.5728
next layer loss target loss 0.0 other loss 9166.557
result 1 [12.19  7.83  1.78] neuron -1000.5828 -0.62716174
e 210 loss -0.29454803 target loss -2959.7324 other loss -202004.7 tv loss 3956.6162
next layer loss target loss 0.0 other loss 9166.006
result 1 [12.19  7.83  1.78] neuron -1000.4769 -0.6270123
e 220 loss -0.29520988 target loss -2959.4421 other loss -202012.81 tv loss 3957.595
next layer loss target loss 0.0 other loss 9168.129
result 1 [12.19  7.83  1.78] neuron -1000.3187 -0.6264994
e 230 loss -0.2958088 target loss -2959.2737 other loss -202004.7 tv loss 3957.3086
next layer loss target loss 0.0 other loss 9167.403
result 1 [12.19  7.83  1.79] neuron -1000.2672 -0.62622976
e 240 loss -0.29634857 target loss -2959.1418 other loss -201993.39 tv loss 3956.874
next layer loss target loss 0.0 other loss 9165.651
result 1 [12.19  7.83  1.79] neuron -1000.2316 -0.62601566
e 250 loss -0.2968502 target loss -2958.9297 other loss -201997.52 tv loss 3957.5005
next layer loss target loss 0.0 other loss 9167.135
result 1 [12.19  7.83  1.79] neuron -1000.11536 -0.6255679
e 260 loss -0.29730415 target loss -2958.7163 other loss -201981.05 tv loss 3957.3228
next layer loss target loss 0.0 other loss 9167.496
result 1 [12.19  7.83  1.79] neuron -999.98804 -0.6251612
e 270 loss -0.29774284 target loss -2958.5566 other loss -201968.3 tv loss 3957.2102
next layer loss target loss 0.0 other loss 9167.559
result 1 [12.19  7.83  1.79] neuron -999.89355 -0.62483484
e 280 loss -0.2981434 target loss -2958.3457 other loss -201958.97 tv loss 3957.5496
next layer loss target loss 0.0 other loss 9168.58
result 1 [12.18  7.83  1.79] neuron -999.7558 -0.6244273
e 290 loss -0.2985363 target loss -2958.1306 other loss -201929.56 tv loss 3957.4282
next layer loss target loss 0.0 other loss 9167.67
result 1 [12.18  7.83  1.79] neuron -999.60876 -0.62406784
e 300 loss -0.29889488 target loss -2957.9314 other loss -201915.8 tv loss 3957.4548
next layer loss target loss 0.0 other loss 9168.291
result 1 [12.18  7.83  1.79] neuron -999.48425 -0.623725
e 310 loss -0.29923058 target loss -2957.8232 other loss -201921.42 tv loss 3957.75
next layer loss target loss 0.0 other loss 9168.628
result 1 [12.18  7.83  1.79] neuron -999.44995 -0.6234858
e 320 loss -0.29953384 target loss -2957.7698 other loss -201915.81 tv loss 3957.5095
next layer loss target loss 0.0 other loss 9167.137
result 1 [12.18  7.83  1.79] neuron -999.4475 -0.6234013
e 330 loss -0.29980278 target loss -2957.5715 other loss -201909.45 tv loss 3957.6614
next layer loss target loss 0.0 other loss 9168.674
result 1 [12.17  7.83  1.79] neuron -999.3199 -0.6229603
e 340 loss -0.30007935 target loss -2957.235 other loss -201884.47 tv loss 3957.9136
next layer loss target loss 0.0 other loss 9171.471
result 1 [12.17  7.83  1.79] neuron -999.06464 -0.6221746
e 350 loss -0.30033112 target loss -2957.0762 other loss -201862.22 tv loss 3957.599
next layer loss target loss 0.0 other loss 9170.413
result 1 [12.17  7.83  1.79] neuron -998.9704 -0.6218935
e 360 loss -0.30056 target loss -2957.012 other loss -201882.58 tv loss 3958.2556
next layer loss target loss 0.0 other loss 9171.391
result 1 [12.17  7.83  1.79] neuron -998.9617 -0.6217504
e 370 loss -0.30076408 target loss -2956.9087 other loss -201882.42 tv loss 3958.4321
next layer loss target loss 0.0 other loss 9171.539
result 1 [12.17  7.83  1.79] neuron -998.9138 -0.62154305
e 380 loss -0.30095673 target loss -2956.7935 other loss -201879.88 tv loss 3958.5225
next layer loss target loss 0.0 other loss 9172.047
result 1 [12.17  7.83  1.79] neuron -998.8558 -0.6213136
e 390 loss -0.30112457 target loss -2956.7043 other loss -201879.55 tv loss 3958.7505
next layer loss target loss 0.0 other loss 9171.976
result 1 [12.16  7.83  1.79] neuron -998.8089 -0.6210889
e 400 loss -0.30128098 target loss -2956.6484 other loss -201880.4 tv loss 3958.831
next layer loss target loss 0.0 other loss 9171.629
result 1 [12.16  7.83  1.79] neuron -998.792 -0.6209997
e 410 loss -0.3014202 target loss -2956.5662 other loss -201884.33 tv loss 3959.121
next layer loss target loss 0.0 other loss 9172.066
result 1 [12.16  7.83  1.79] neuron -998.7521 -0.62082267
e 420 loss -0.301548 target loss -2956.4426 other loss -201872.14 tv loss 3959.1
next layer loss target loss 0.0 other loss 9171.902
result 1 [12.16  7.83  1.79] neuron -998.6686 -0.6205707
e 430 loss -0.3016796 target loss -2956.2888 other loss -201866.98 tv loss 3959.0815
next layer loss target loss 0.0 other loss 9173.29
result 1 [12.16  7.83  1.79] neuron -998.57245 -0.6202359
e 440 loss -0.30178833 target loss -2956.2432 other loss -201873.75 tv loss 3959.2466
next layer loss target loss 0.0 other loss 9173.488
result 1 [12.16  7.83  1.79] neuron -998.5622 -0.62013936
e 450 loss -0.3018837 target loss -2956.1765 other loss -201873.94 tv loss 3959.462
next layer loss target loss 0.0 other loss 9173.491
result 1 [12.16  7.83  1.79] neuron -998.52985 -0.62004787
e 460 loss -0.30197525 target loss -2956.131 other loss -201874.22 tv loss 3959.5012
next layer loss target loss 0.0 other loss 9173.212
result 1 [12.16  7.82  1.79] neuron -998.5139 -0.6199496
e 470 loss -0.302063 target loss -2956.052 other loss -201873.73 tv loss 3959.596
next layer loss target loss 0.0 other loss 9173.695
result 1 [12.15  7.82  1.79] neuron -998.4702 -0.61976606
e 480 loss -0.30213737 target loss -2955.9988 other loss -201864.62 tv loss 3959.399
next layer loss target loss 0.0 other loss 9172.938
result 1 [12.15  7.82  1.79] neuron -998.44354 -0.6196989
e 490 loss -0.30221558 target loss -2955.905 other loss -201860.77 tv loss 3959.4873
next layer loss target loss 0.0 other loss 9173.436
result 1 [12.15  7.82  1.79] neuron -998.37476 -0.61944425
e 500 loss -0.30227852 target loss -2955.8518 other loss -201855.11 tv loss 3959.5127
next layer loss target loss 0.0 other loss 9173.213
result 1 [12.15  7.82  1.79] neuron -998.342 -0.61937946
e 510 loss -0.30233383 target loss -2955.815 other loss -201861.72 tv loss 3959.7385
next layer loss target loss 0.0 other loss 9173.845
result 1 [12.15  7.82  1.79] neuron -998.32275 -0.61929715
e 520 loss -0.30239487 target loss -2955.7515 other loss -201861.27 tv loss 3959.8228
next layer loss target loss 0.0 other loss 9174.242
result 1 [12.15  7.82  1.79] neuron -998.284 -0.6191604
e 530 loss -0.302454 target loss -2955.7168 other loss -201862.27 tv loss 3959.9272
next layer loss target loss 0.0 other loss 9174.204
result 1 [12.15  7.82  1.79] neuron -998.2671 -0.6190882
e 540 loss -0.30249023 target loss -2955.6802 other loss -201863.72 tv loss 3960.0327
next layer loss target loss 0.0 other loss 9174.219
result 1 [12.15  7.82  1.79] neuron -998.25287 -0.6190058
e 550 loss -0.30253983 target loss -2955.6536 other loss -201864.02 tv loss 3960.0554
next layer loss target loss 0.0 other loss 9173.941
result 1 [12.15  7.82  1.79] neuron -998.2457 -0.6189628
e 560 loss -0.3025837 target loss -2955.6206 other loss -201867.23 tv loss 3960.1719
next layer loss target loss 0.0 other loss 9174.049
result 1 [12.15  7.82  1.79] neuron -998.236 -0.6188985
e 570 loss -0.30262756 target loss -2955.5796 other loss -201871.17 tv loss 3960.3535
next layer loss target loss 0.0 other loss 9174.468
result 1 [12.14  7.82  1.79] neuron -998.21265 -0.6187779
e 580 loss -0.30268097 target loss -2955.386 other loss -201861.77 tv loss 3960.8184
next layer loss target loss 0.0 other loss 9176.421
result 1 [12.14  7.82  1.79] neuron -998.05664 -0.61837405
e 590 loss -0.30273438 target loss -2955.0574 other loss -201840.14 tv loss 3961.377
next layer loss target loss 0.0 other loss 9179.781
result 1 [12.13  7.82  1.78] neuron -997.79175 -0.61772215
e 600 loss -0.30277252 target loss -2955.092 other loss -201837.0 tv loss 3961.0222
next layer loss target loss 0.0 other loss 9177.675
result 1 [12.13  7.82  1.79] neuron -997.84015 -0.61784357
e 610 loss -0.3028164 target loss -2954.9897 other loss -201834.1 tv loss 3961.3867
next layer loss target loss 0.0 other loss 9178.276
result 1 [12.13  7.82  1.78] neuron -997.76514 -0.6176058
e 620 loss -0.30286598 target loss -2954.9438 other loss -201840.1 tv loss 3961.5776
next layer loss target loss 0.0 other loss 9178.867
result 1 [12.13  7.82  1.79] neuron -997.74133 -0.61750054
e 630 loss -0.30290413 target loss -2954.862 other loss -201834.86 tv loss 3961.56
next layer loss target loss 0.0 other loss 9179.0625
result 1 [12.12  7.82  1.78] neuron -997.69403 -0.61734474
e 640 loss -0.30294037 target loss -2954.7642 other loss -201829.39 tv loss 3961.5842
next layer loss target loss 0.0 other loss 9179.74
result 1 [12.12  7.82  1.78] neuron -997.6342 -0.6171582
e 650 loss -0.30298615 target loss -2954.7432 other loss -201827.53 tv loss 3961.52
next layer loss target loss 0.0 other loss 9179.209
result 1 [12.12  7.82  1.78] neuron -997.63135 -0.617124
e 660 loss -0.30300713 target loss -2954.7214 other loss -201831.58 tv loss 3961.5698
next layer loss target loss 0.0 other loss 9179.292
result 1 [12.12  7.82  1.79] neuron -997.62854 -0.617061
e 670 loss -0.30304527 target loss -2954.6946 other loss -201829.66 tv loss 3961.5894
next layer loss target loss 0.0 other loss 9179.02
result 1 [12.12  7.82  1.79] neuron -997.61707 -0.61702347
e 680 loss -0.30307198 target loss -2954.6626 other loss -201838.53 tv loss 3961.8618
next layer loss target loss 0.0 other loss 9179.979
result 1 [12.12  7.82  1.79] neuron -997.6018 -0.6169308
e 690 loss -0.3031025 target loss -2954.6501 other loss -201835.44 tv loss 3961.7598
next layer loss target loss 0.0 other loss 9179.528
result 1 [12.12  7.82  1.79] neuron -997.6003 -0.6169176
e 700 loss -0.30311775 target loss -2954.6265 other loss -201839.31 tv loss 3961.9185
next layer loss target loss 0.0 other loss 9179.754
result 1 [12.12  7.82  1.79] neuron -997.5901 -0.61685735
e 710 loss -0.30314445 target loss -2954.52 other loss -201841.28 tv loss 3962.2612
next layer loss target loss 0.0 other loss 9181.219
result 1 [12.11  7.82  1.79] neuron -997.51385 -0.61665344
e 720 loss -0.30317116 target loss -2954.5015 other loss -201839.14 tv loss 3962.1948
next layer loss target loss 0.0 other loss 9180.932
result 1 [12.11  7.82  1.79] neuron -997.50916 -0.6166483
e 730 loss -0.30319405 target loss -2954.4966 other loss -201847.84 tv loss 3962.3672
next layer loss target loss 0.0 other loss 9181.31
result 1 [12.11  7.82  1.79] neuron -997.51154 -0.6165708
e 740 loss -0.30321312 target loss -2954.4756 other loss -201843.9 tv loss 3962.2886
next layer loss target loss 0.0 other loss 9180.985
result 1 [12.11  7.82  1.79] neuron -997.5028 -0.616542
e 750 loss -0.30323792 target loss -2954.453 other loss -201850.86 tv loss 3962.4648
next layer loss target loss 0.0 other loss 9181.852
result 1 [12.11  7.82  1.79] neuron -997.4941 -0.6164763
e 760 loss -0.30325317 target loss -2954.4268 other loss -201839.02 tv loss 3962.2175
next layer loss target loss 0.0 other loss 9180.885
result 1 [12.11  7.82  1.79] neuron -997.47705 -0.61644757
e 770 loss -0.30327034 target loss -2954.4102 other loss -201842.05 tv loss 3962.4531
next layer loss target loss 0.0 other loss 9181.199
result 1 [12.11  7.81  1.79] neuron -997.4689 -0.61641943
e 780 loss -0.30329323 target loss -2954.4001 other loss -201848.8 tv loss 3962.5115
next layer loss target loss 0.0 other loss 9181.82
result 1 [12.11  7.82  1.79] neuron -997.461 -0.61635315
e 790 loss -0.30327225 target loss -2954.3982 other loss -201858.92 tv loss 3962.5403
next layer loss target loss 0.0 other loss 9182.525
result 1 [12.11  7.82  1.79] neuron -997.4542 -0.6162627
e 800 loss -0.30333328 target loss -2954.3787 other loss -201855.34 tv loss 3962.7402
next layer loss target loss 0.0 other loss 9182.488
result 1 [12.11  7.81  1.79] neuron -997.44635 -0.6162845
e 810 loss -0.30330658 target loss -2954.371 other loss -201834.2 tv loss 3962.4917
next layer loss target loss 0.0 other loss 9180.422
result 1 [12.11  7.81  1.78] neuron -997.44446 -0.6163535
e 820 loss -0.30312157 target loss -2954.3677 other loss -201814.64 tv loss 3962.5164
next layer loss target loss 0.0 other loss 9178.622
result 1 [12.1   7.81  1.78] neuron -997.4409 -0.6164619
e 830 loss -0.30324745 target loss -2954.3672 other loss -201868.25 tv loss 3962.6226
next layer loss target loss 0.0 other loss 9183.464
result 1 [12.11  7.82  1.79] neuron -997.42804 -0.61610633
e 840 loss -0.30332565 target loss -2954.339 other loss -201842.34 tv loss 3962.888
next layer loss target loss 0.0 other loss 9181.266
result 1 [12.1   7.81  1.78] neuron -997.4265 -0.6162731
e 850 loss -0.30333328 target loss -2954.3406 other loss -201873.56 tv loss 3962.957
next layer loss target loss 0.0 other loss 9184.182
result 1 [12.11  7.82  1.79] neuron -997.4148 -0.61605495
e 860 loss -0.30338478 target loss -2954.3044 other loss -201838.27 tv loss 3962.7188
next layer loss target loss 0.0 other loss 9181.248
result 1 [12.1   7.81  1.78] neuron -997.399 -0.6161782
e 870 loss -0.30339432 target loss -2954.3115 other loss -201836.97 tv loss 3962.7212
next layer loss target loss 0.0 other loss 9181.007
result 1 [12.1   7.81  1.78] neuron -997.40125 -0.61619866
e 880 loss -0.3034191 target loss -2954.3088 other loss -201843.72 tv loss 3962.8508
next layer loss target loss 0.0 other loss 9181.438
result 1 [12.1   7.81  1.78] neuron -997.3976 -0.6161506
e 890 loss -0.3033676 target loss -2954.3015 other loss -201832.48 tv loss 3962.8154
next layer loss target loss 0.0 other loss 9180.537
result 1 [12.1   7.81  1.78] neuron -997.39624 -0.6162021
e 900 loss -0.30345726 target loss -2954.27 other loss -201852.95 tv loss 3962.8467
next layer loss target loss 0.0 other loss 9182.619
result 1 [12.11  7.81  1.78] neuron -997.3583 -0.6159681
e 910 loss -0.30345535 target loss -2954.3071 other loss -201857.3 tv loss 3962.8752
next layer loss target loss 0.0 other loss 9182.376
result 1 [12.11  7.81  1.79] neuron -997.38837 -0.61603004
e 920 loss -0.30344582 target loss -2954.2346 other loss -201833.69 tv loss 3962.9116
next layer loss target loss 0.0 other loss 9181.201
result 1 [12.1   7.81  1.78] neuron -997.3465 -0.6160345
e 930 loss -0.30351448 target loss -2954.2842 other loss -201833.34 tv loss 3962.4805
next layer loss target loss 0.0 other loss 9180.264
result 1 [12.1   7.81  1.78] neuron -997.3724 -0.61607474
e 940 loss -0.3034649 target loss -2954.248 other loss -201869.06 tv loss 3963.2188
next layer loss target loss 0.0 other loss 9184.128
result 1 [12.11  7.81  1.79] neuron -997.3444 -0.6158417
e 950 loss -0.30348206 target loss -2954.2666 other loss -201863.86 tv loss 3963.042
next layer loss target loss 0.0 other loss 9183.288
result 1 [12.11  7.81  1.79] neuron -997.3599 -0.61589915
e 960 loss -0.30351067 target loss -2954.2605 other loss -201858.52 tv loss 3962.9802
next layer loss target loss 0.0 other loss 9182.813
result 1 [12.11  7.81  1.78] neuron -997.3549 -0.6159011
e 970 loss -0.3034649 target loss -2954.2485 other loss -201870.81 tv loss 3963.1758
next layer loss target loss 0.0 other loss 9184.119
result 1 [12.11  7.81  1.79] neuron -997.3436 -0.61581326
e 980 loss -0.30351257 target loss -2954.2507 other loss -201862.52 tv loss 3963.1077
next layer loss target loss 0.0 other loss 9183.148
result 1 [12.11  7.81  1.78] neuron -997.3439 -0.6158474
e 990 loss -0.3035164 target loss -2954.2305 other loss -201860.97 tv loss 3963.0317
next layer loss target loss 0.0 other loss 9183.322
result 1 [12.11  7.81  1.78] neuron -997.3318 -0.6157978
RE filter conv2d_3 63 RE acc 0.3333333333333333
e 0 loss -2.6870193 target loss -2733.2495 other loss -204247.25 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -814.08844 -0.35486686
e 10 loss -3.2787304 target loss -2637.2954 other loss -202745.52 tv loss 3955.1616
next layer loss target loss 0.0 other loss 9315.958
result 1 [12.25  8.21  1.77] neuron -758.0229 -0.30844712
e 20 loss -3.750637 target loss -2545.8455 other loss -200866.6 tv loss 3904.0593
next layer loss target loss 0.0 other loss 9357.289
result 1 [11.75  8.01  1.59] neuron -704.50073 -0.28789568
e 30 loss -4.236021 target loss -2425.8345 other loss -200779.05 tv loss 3866.885
next layer loss target loss 0.0 other loss 9504.551
result 1 [11.06  7.61  1.44] neuron -641.43286 -0.23946321
e 40 loss -4.770649 target loss -2290.0054 other loss -203560.5 tv loss 3872.2034
next layer loss target loss 0.090121806 other loss 9959.077
result 1 [10.7   7.12  1.39] neuron -571.99634 -0.18577284
e 50 loss -5.4587097 target loss -2114.0479 other loss -207145.8 tv loss 3853.6743
next layer loss target loss 0.89441085 other loss 10480.685
result 1 [10.33  6.4   1.39] neuron -486.85327 -0.06957236
e 60 loss -6.2837257 target loss -1926.081 other loss -210913.56 tv loss 3794.7832
next layer loss target loss 3.7207904 other loss 10995.39
result 1 [9.72 5.42 1.42] neuron -398.73947 0.07551652
e 70 loss -7.276291 target loss -1738.8616 other loss -214699.31 tv loss 3705.55
next layer loss target loss 17.448582 other loss 11514.127
result 1 [9.61 5.03 1.47] neuron -312.49292 0.19580191
e 80 loss -8.4057865 target loss -1564.8113 other loss -217694.08 tv loss 3592.685
next layer loss target loss 45.430042 other loss 11979.816
result 1 [9.43 4.86 1.57] neuron -232.39378 0.32860988
e 90 loss -9.631182 target loss -1402.1191 other loss -220029.33 tv loss 3471.8535
next layer loss target loss 90.75776 other loss 12430.745
result 1 [9.25 4.35 1.72] neuron -162.25647 0.5158302
e 100 loss -10.653541 target loss -1268.6675 other loss -221837.83 tv loss 3362.4946
next layer loss target loss 137.13611 other loss 12815.382
result 1 [9.07 4.13 1.88] neuron -109.32759 0.6498055
e 110 loss -11.472671 target loss -1166.159 other loss -223337.03 tv loss 3280.0288
next layer loss target loss 176.90454 other loss 13123.0625
result 1 [9.01 3.95 2.02] neuron -74.077896 0.78020066
e 120 loss -12.214898 target loss -1077.1467 other loss -224785.05 tv loss 3220.5352
next layer loss target loss 214.16888 other loss 13403.756
result 1 [9.13 4.06 2.18] neuron -48.82257 0.9093823
e 130 loss -12.931973 target loss -990.54517 other loss -226316.02 tv loss 3172.528
next layer loss target loss 251.01279 other loss 13704.51
result 1 [9.35 4.57 2.31] neuron -29.197006 1.0266716
e 140 loss -12.405237 target loss -1041.0566 other loss -223972.58 tv loss 3154.4854
next layer loss target loss 234.46371 other loss 13467.464
result 1 [9.22 4.58 2.24] neuron -56.68754 1.0583684
e 150 loss -11.38326 target loss -1160.3329 other loss -221674.0 tv loss 3204.627
next layer loss target loss 194.09875 other loss 13049.933
result 1 [8.58 3.36 1.88] neuron -99.86725 0.94867367
e 160 loss -10.8521805 target loss -1182.8114 other loss -221681.69 tv loss 3211.2056
next layer loss target loss 184.87445 other loss 12983.767
result 1 [8.29 2.98 1.73] neuron -107.448616 0.9234422
e 170 loss -10.650314 target loss -1187.7087 other loss -221788.52 tv loss 3210.75
next layer loss target loss 182.9909 other loss 12977.482
result 1 [8.22 2.91 1.67] neuron -108.61428 0.9204959
e 180 loss -10.633892 target loss -1186.581 other loss -221889.9 tv loss 3208.698
next layer loss target loss 183.8925 other loss 12985.987
result 1 [8.22 2.91 1.65] neuron -107.64734 0.92476004
e 190 loss -10.687675 target loss -1183.3345 other loss -221984.34 tv loss 3206.0322
next layer loss target loss 185.82565 other loss 12998.922
result 1 [8.24 2.93 1.64] neuron -105.932655 0.931765
e 200 loss -10.768102 target loss -1179.279 other loss -222077.02 tv loss 3203.1104
next layer loss target loss 188.16951 other loss 13013.697
result 1 [8.28 2.96 1.63] neuron -103.92283 0.93988925
e 210 loss -10.859438 target loss -1174.8596 other loss -222170.36 tv loss 3200.022
next layer loss target loss 190.7119 other loss 13029.512
result 1 [8.32 2.99 1.63] neuron -101.76973 0.9485492
e 220 loss -10.956112 target loss -1170.2366 other loss -222265.08 tv loss 3196.7834
next layer loss target loss 193.38986 other loss 13046.054
result 1 [8.36 3.02 1.62] neuron -99.52771 0.95755416
e 230 loss -11.055335 target loss -1165.5032 other loss -222361.23 tv loss 3193.4363
next layer loss target loss 196.13867 other loss 13063.107
result 1 [8.4  3.06 1.62] neuron -97.24086 0.96679646
e 240 loss -11.155568 target loss -1160.7218 other loss -222458.8 tv loss 3190.061
next layer loss target loss 198.90543 other loss 13080.423
result 1 [8.44 3.11 1.61] neuron -94.918846 0.9762843
e 250 loss -11.256619 target loss -1155.9093 other loss -222558.03 tv loss 3186.6953
next layer loss target loss 201.70047 other loss 13097.947
result 1 [8.48 3.16 1.6 ] neuron -92.579346 0.9859883
e 260 loss -11.358766 target loss -1151.0353 other loss -222659.56 tv loss 3183.2908
next layer loss target loss 204.53912 other loss 13115.941
result 1 [8.52 3.21 1.59] neuron -90.209595 0.99580747
e 270 loss -11.461787 target loss -1146.1066 other loss -222762.6 tv loss 3179.8237
next layer loss target loss 207.41403 other loss 13134.332
result 1 [8.57 3.26 1.58] neuron -87.81334 1.0057423
e 280 loss -11.565789 target loss -1141.1066 other loss -222867.55 tv loss 3176.2864
next layer loss target loss 210.31934 other loss 13153.179
result 1 [8.61 3.32 1.58] neuron -85.38194 1.0157909
e 290 loss -11.671154 target loss -1136.0536 other loss -222974.33 tv loss 3172.7217
next layer loss target loss 213.24536 other loss 13172.472
result 1 [8.65 3.38 1.57] neuron -82.90756 1.025981
e 300 loss -11.777633 target loss -1130.939 other loss -223083.17 tv loss 3169.0713
next layer loss target loss 216.19586 other loss 13192.189
result 1 [8.7  3.45 1.56] neuron -80.40676 1.036277
e 310 loss -11.885255 target loss -1125.7473 other loss -223193.75 tv loss 3165.3174
next layer loss target loss 219.18253 other loss 13212.289
result 1 [8.74 3.51 1.55] neuron -77.867966 1.0467124
e 320 loss -11.993948 target loss -1120.4846 other loss -223306.7 tv loss 3161.5022
next layer loss target loss 222.22198 other loss 13232.824
result 1 [8.79 3.58 1.54] neuron -75.29624 1.0572855
e 330 loss -12.103569 target loss -1115.1576 other loss -223421.5 tv loss 3157.622
next layer loss target loss 225.31418 other loss 13253.616
result 1 [8.84 3.66 1.53] neuron -72.69707 1.0679817
e 340 loss -12.2137575 target loss -1109.7919 other loss -223537.06 tv loss 3153.7273
next layer loss target loss 228.44498 other loss 13274.616
result 1 [8.88 3.74 1.52] neuron -70.08787 1.078383
e 350 loss -12.324277 target loss -1104.4004 other loss -223653.88 tv loss 3149.8184
next layer loss target loss 231.58615 other loss 13295.849
result 1 [8.93 3.82 1.52] neuron -67.467606 1.0883482
e 360 loss -12.434698 target loss -1098.985 other loss -223772.56 tv loss 3145.854
next layer loss target loss 234.7356 other loss 13317.383
result 1 [8.98 3.91 1.51] neuron -64.83534 1.0972593
e 370 loss -12.544912 target loss -1093.5402 other loss -223891.39 tv loss 3141.7786
next layer loss target loss 237.90468 other loss 13339.146
result 1 [9.03 4.   1.5 ] neuron -62.194897 1.1056163
e 380 loss -12.654626 target loss -1088.0596 other loss -224009.95 tv loss 3137.5776
next layer loss target loss 241.08043 other loss 13361.191
result 1 [9.07 4.09 1.49] neuron -59.539913 1.1138489
e 390 loss -12.7640705 target loss -1082.53 other loss -224129.0 tv loss 3133.2954
next layer loss target loss 244.29485 other loss 13383.497
result 1 [9.12 4.19 1.48] neuron -56.86521 1.1220994
e 400 loss -12.872244 target loss -1077.0038 other loss -224247.48 tv loss 3128.8445
next layer loss target loss 247.51024 other loss 13405.802
result 1 [9.17 4.28 1.47] neuron -54.19351 1.1302814
e 410 loss -12.977859 target loss -1071.5243 other loss -224364.03 tv loss 3124.1846
next layer loss target loss 250.69037 other loss 13427.605
result 1 [9.22 4.38 1.47] neuron -51.548912 1.1443167
e 420 loss -13.080818 target loss -1066.0781 other loss -224477.72 tv loss 3119.312
next layer loss target loss 253.84052 other loss 13448.926
result 1 [9.27 4.48 1.46] neuron -48.931976 1.1604426
e 430 loss -13.180844 target loss -1060.6805 other loss -224589.6 tv loss 3114.3154
next layer loss target loss 256.95044 other loss 13469.957
result 1 [9.32 4.59 1.45] neuron -46.343346 1.175612
e 440 loss -13.278421 target loss -1055.3148 other loss -224699.66 tv loss 3109.2288
next layer loss target loss 260.05322 other loss 13490.865
result 1 [9.36 4.69 1.45] neuron -43.78202 1.1903062
e 450 loss -13.373139 target loss -1049.9863 other loss -224807.62 tv loss 3104.0244
next layer loss target loss 263.14825 other loss 13511.395
result 1 [9.41 4.8  1.44] neuron -41.254543 1.2048061
e 460 loss -13.465286 target loss -1044.7144 other loss -224913.6 tv loss 3098.6514
next layer loss target loss 266.23138 other loss 13531.571
result 1 [9.45 4.91 1.44] neuron -38.7738 1.2194924
e 470 loss -13.55431 target loss -1039.493 other loss -225017.39 tv loss 3093.1467
next layer loss target loss 269.30582 other loss 13551.305
result 1 [9.49 5.02 1.43] neuron -36.333775 1.2343469
e 480 loss -13.639469 target loss -1034.3604 other loss -225120.02 tv loss 3087.5679
next layer loss target loss 272.34558 other loss 13570.589
result 1 [9.53 5.13 1.43] neuron -33.933693 1.2477775
e 490 loss -13.721121 target loss -1029.3174 other loss -225219.9 tv loss 3081.9656
next layer loss target loss 275.35913 other loss 13589.704
result 1 [9.56 5.24 1.43] neuron -31.590622 1.2612278
e 500 loss -13.799174 target loss -1024.3785 other loss -225317.73 tv loss 3076.3745
next layer loss target loss 278.32617 other loss 13608.562
result 1 [9.6  5.36 1.42] neuron -29.309767 1.274818
e 510 loss -13.873656 target loss -1019.58093 other loss -225412.06 tv loss 3070.8237
next layer loss target loss 281.22656 other loss 13626.929
result 1 [9.63 5.48 1.42] neuron -27.101624 1.2876103
e 520 loss -13.944562 target loss -1014.903 other loss -225503.03 tv loss 3065.3013
next layer loss target loss 284.0867 other loss 13644.949
result 1 [9.67 5.6  1.42] neuron -24.970373 1.3004768
e 530 loss -14.012224 target loss -1010.3602 other loss -225590.64 tv loss 3059.8296
next layer loss target loss 286.89337 other loss 13662.563
result 1 [9.7  5.73 1.42] neuron -22.922739 1.3136504
e 540 loss -14.077212 target loss -1005.94836 other loss -225675.12 tv loss 3054.4219
next layer loss target loss 289.6598 other loss 13679.863
result 1 [9.73 5.85 1.41] neuron -20.947924 1.3273318
e 550 loss -14.139433 target loss -1001.68304 other loss -225756.28 tv loss 3049.032
next layer loss target loss 292.38928 other loss 13696.982
result 1 [9.76 5.99 1.41] neuron -19.049091 1.3412094
e 560 loss -14.199045 target loss -997.57324 other loss -225834.16 tv loss 3043.632
next layer loss target loss 295.07117 other loss 13713.807
result 1 [9.8  6.12 1.41] neuron -17.235548 1.3558292
e 570 loss -14.256271 target loss -993.6394 other loss -225908.45 tv loss 3038.2393
next layer loss target loss 297.67896 other loss 13730.014
result 1 [9.83 6.25 1.41] neuron -15.517651 1.370848
e 580 loss -14.310846 target loss -989.89343 other loss -225979.81 tv loss 3032.8843
next layer loss target loss 300.19885 other loss 13745.543
result 1 [9.86 6.38 1.4 ] neuron -13.898218 1.3858812
e 590 loss -14.363489 target loss -986.2876 other loss -226048.03 tv loss 3027.5215
next layer loss target loss 302.6603 other loss 13760.642
result 1 [9.89 6.51 1.4 ] neuron -12.354895 1.4011502
e 600 loss -14.414051 target loss -982.8423 other loss -226111.78 tv loss 3022.2495
next layer loss target loss 305.04523 other loss 13775.13
result 1 [9.92 6.65 1.4 ] neuron -10.902422 1.4164169
e 610 loss -14.46257 target loss -979.54785 other loss -226171.6 tv loss 3017.0903
next layer loss target loss 307.34576 other loss 13789.011
result 1 [9.94 6.79 1.4 ] neuron -9.549356 1.4323232
e 620 loss -14.50861 target loss -976.41046 other loss -226229.31 tv loss 3012.0754
next layer loss target loss 309.56464 other loss 13802.552
result 1 [9.97 6.94 1.4 ] neuron -8.279598 1.4480495
e 630 loss -14.552753 target loss -973.37823 other loss -226285.67 tv loss 3007.2234
next layer loss target loss 311.7233 other loss 13815.781
result 1 [9.99 7.08 1.4 ] neuron -7.0837555 1.4636075
e 640 loss -14.594597 target loss -970.4546 other loss -226340.0 tv loss 3002.4705
next layer loss target loss 313.80115 other loss 13828.688
result 1 [10.02  7.24  1.4 ] neuron -5.9598446 1.4786255
e 650 loss -14.634031 target loss -967.6468 other loss -226393.23 tv loss 2997.9583
next layer loss target loss 315.78217 other loss 13841.262
result 1 [10.04  7.39  1.41] neuron -4.9173183 1.4936638
e 660 loss -14.67101 target loss -964.9512 other loss -226444.97 tv loss 2993.6313
next layer loss target loss 317.66638 other loss 13853.569
result 1 [10.06  7.55  1.41] neuron -3.937706 1.5083163
e 670 loss -14.705769 target loss -962.3515 other loss -226496.08 tv loss 2989.5815
next layer loss target loss 319.456 other loss 13865.581
result 2 [10.09  7.71  1.41] neuron -3.0057945 1.5225937
e 680 loss -14.739407 target loss -959.8037 other loss -226547.36 tv loss 2985.7053
next layer loss target loss 321.18756 other loss 13877.569
result 2 [10.11  7.86  1.41] neuron -2.1150818 1.5365353
e 690 loss -14.7723465 target loss -957.2789 other loss -226599.11 tv loss 2981.9253
next layer loss target loss 322.89243 other loss 13889.482
result 2 [10.13  8.02  1.41] neuron -1.2626648 1.5502787
e 700 loss -14.803442 target loss -954.832 other loss -226650.4 tv loss 2978.3147
next layer loss target loss 324.50757 other loss 13901.106
result 2 [10.15  8.17  1.41] neuron -0.4618225 1.5636365
e 710 loss -14.8332615 target loss -952.4318 other loss -226701.48 tv loss 2974.8403
next layer loss target loss 326.05902 other loss 13912.552
result 2 [10.17  8.33  1.41] neuron 0.29797173 1.5766277
e 720 loss -14.860386 target loss -950.1432 other loss -226750.53 tv loss 2971.5173
next layer loss target loss 327.48193 other loss 13923.387
result 2 [10.2   8.49  1.42] neuron 1.0201893 1.5890577
e 730 loss -14.884857 target loss -947.9762 other loss -226799.38 tv loss 2968.544
next layer loss target loss 328.77087 other loss 13933.754
result 2 [10.22  8.62  1.42] neuron 1.699688 1.6007464
e 740 loss -14.907297 target loss -945.91016 other loss -226848.73 tv loss 2965.9482
next layer loss target loss 329.94232 other loss 13943.705
result 2 [10.23  8.74  1.42] neuron 2.321785 1.6116779
e 750 loss -14.928791 target loss -943.8856 other loss -226899.0 tv loss 2963.539
next layer loss target loss 331.054 other loss 13953.568
result 2 [10.25  8.86  1.42] neuron 2.9120579 1.6221695
e 760 loss -14.94972 target loss -941.8779 other loss -226949.81 tv loss 2961.2344
next layer loss target loss 332.12915 other loss 13963.395
result 2 [10.27  8.97  1.42] neuron 3.4804325 1.6324043
e 770 loss -14.969542 target loss -939.9184 other loss -227000.19 tv loss 2959.0112
next layer loss target loss 333.13394 other loss 13972.933
result 2 [10.29  9.08  1.42] neuron 4.0084705 1.6413586
e 780 loss -14.988073 target loss -938.02637 other loss -227050.69 tv loss 2956.9944
next layer loss target loss 334.05576 other loss 13982.141
result 2 [10.3   9.19  1.42] neuron 4.49518 1.6491559
e 790 loss -15.005933 target loss -936.1577 other loss -227101.84 tv loss 2955.0977
next layer loss target loss 334.93387 other loss 13991.229
result 2 [10.32  9.29  1.43] neuron 4.9641876 1.6567464
e 800 loss -15.023445 target loss -934.29895 other loss -227153.5 tv loss 2953.3008
next layer loss target loss 335.78406 other loss 14000.256
result 2 [10.34  9.38  1.43] neuron 5.416025 1.6643071
e 810 loss -15.040348 target loss -932.47925 other loss -227205.14 tv loss 2951.6228
next layer loss target loss 336.5921 other loss 14009.113
result 2 [10.35  9.47  1.43] neuron 5.8465157 1.671385
e 820 loss -15.056616 target loss -930.6906 other loss -227257.03 tv loss 2950.0764
next layer loss target loss 337.35492 other loss 14017.818
result 2 [10.37  9.55  1.43] neuron 6.2554626 1.6778944
e 830 loss -15.07233 target loss -928.92926 other loss -227309.31 tv loss 2948.6636
next layer loss target loss 338.0768 other loss 14026.432
result 2 [10.39  9.64  1.43] neuron 6.648945 1.6841743
e 840 loss -15.087837 target loss -927.1814 other loss -227361.8 tv loss 2947.3367
next layer loss target loss 338.7745 other loss 14035.003
result 2 [10.4   9.73  1.43] neuron 7.027628 1.690212
e 850 loss -15.103064 target loss -925.4508 other loss -227414.38 tv loss 2946.0857
next layer loss target loss 339.44656 other loss 14043.46
result 2 [10.42  9.81  1.43] neuron 7.3872833 1.6961045
e 860 loss -15.117645 target loss -923.7506 other loss -227467.27 tv loss 2944.9727
next layer loss target loss 340.0708 other loss 14051.772
result 2 [10.43  9.88  1.43] neuron 7.7278786 1.7017567
e 870 loss -15.132185 target loss -922.05164 other loss -227520.66 tv loss 2943.9246
next layer loss target loss 340.6768 other loss 14060.056
result 2 [10.45  9.94  1.43] neuron 8.056692 1.7072506
e 880 loss -15.146707 target loss -920.35315 other loss -227574.27 tv loss 2942.9
next layer loss target loss 341.2677 other loss 14068.334
result 2 [10.46 10.    1.43] neuron 8.3710785 1.7123406
e 890 loss -15.160574 target loss -918.6918 other loss -227628.16 tv loss 2942.0015
next layer loss target loss 341.80682 other loss 14076.523
result 2 [10.47 10.05  1.43] neuron 8.658203 1.7165046
e 900 loss -15.17357 target loss -917.0746 other loss -227682.03 tv loss 2941.3052
next layer loss target loss 342.2824 other loss 14084.477
result 2 [10.48 10.09  1.43] neuron 8.923912 1.7199781
e 910 loss -15.186447 target loss -915.46185 other loss -227736.77 tv loss 2940.7078
next layer loss target loss 342.73245 other loss 14092.406
result 2 [10.49 10.13  1.43] neuron 9.177431 1.7232618
e 920 loss -15.199282 target loss -913.85254 other loss -227792.1 tv loss 2940.1697
next layer loss target loss 343.17038 other loss 14100.305
result 2 [10.5  10.16  1.43] neuron 9.422815 1.7264445
e 930 loss -15.211524 target loss -912.2701 other loss -227848.88 tv loss 2939.8506
next layer loss target loss 343.55484 other loss 14108.201
result 2 [10.51 10.18  1.43] neuron 9.655357 1.7293053
e 940 loss -15.223692 target loss -910.69543 other loss -227907.14 tv loss 2939.6995
next layer loss target loss 343.9073 other loss 14116.112
result 2 [10.52 10.2   1.43] neuron 9.870937 1.7313418
e 950 loss -15.235977 target loss -909.11084 other loss -227966.38 tv loss 2939.6108
next layer loss target loss 344.2466 other loss 14124.043
result 2 [10.53 10.22  1.43] neuron 10.077179 1.7330582
e 960 loss -15.248417 target loss -907.5165 other loss -228025.89 tv loss 2939.518
next layer loss target loss 344.58215 other loss 14131.933
result 2 [10.53 10.24  1.43] neuron 10.277325 1.7348182
e 970 loss -15.261051 target loss -905.9085 other loss -228085.89 tv loss 2939.421
next layer loss target loss 344.91724 other loss 14139.846
result 2 [10.54 10.25  1.43] neuron 10.472824 1.7365868
e 980 loss -15.273825 target loss -904.29364 other loss -228145.97 tv loss 2939.296
next layer loss target loss 345.25116 other loss 14147.668
result 2 [10.54 10.27  1.43] neuron 10.663473 1.7383547
e 990 loss -15.286723 target loss -902.67456 other loss -228206.1 tv loss 2939.126
next layer loss target loss 345.58856 other loss 14155.455
result 2 [10.55 10.29  1.43] neuron 10.851305 1.7400784
RE filter conv2d_3 40 RE acc 0.6666666666666666
e 0 loss -3.003355 target loss -2701.6162 other loss -204278.9 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -857.593 -0.5853615
e 10 loss -3.1974468 target loss -2667.7678 other loss -204398.94 tv loss 3965.6438
next layer loss target loss 0.0 other loss 9377.36
result 1 [12.27  8.27  1.84] neuron -842.603 -0.5796042
e 20 loss -3.2721024 target loss -2655.4678 other loss -203918.72 tv loss 3947.4468
next layer loss target loss 0.0 other loss 9491.956
result 1 [12.19  8.07  1.76] neuron -837.98944 -0.57327235
e 30 loss -3.3034115 target loss -2645.3179 other loss -202476.58 tv loss 3922.631
next layer loss target loss 0.0 other loss 9472.891
result 1 [12.08  7.84  1.69] neuron -834.9042 -0.56831825
e 40 loss -3.3144665 target loss -2636.974 other loss -202356.25 tv loss 3914.5698
next layer loss target loss 0.0 other loss 9525.407
result 1 [12.02  7.77  1.66] neuron -831.77893 -0.5611277
e 50 loss -3.3199005 target loss -2634.8906 other loss -202480.69 tv loss 3912.1802
next layer loss target loss 0.0 other loss 9548.976
result 1 [12.05  7.76  1.67] neuron -831.62476 -0.55976087
e 60 loss -3.3258 target loss -2636.1257 other loss -202265.42 tv loss 3909.0288
next layer loss target loss 0.0 other loss 9519.082
result 1 [12.05  7.75  1.67] neuron -832.256 -0.5618966
e 70 loss -3.3306847 target loss -2636.356 other loss -202239.9 tv loss 3908.8188
next layer loss target loss 0.0 other loss 9509.066
result 1 [12.06  7.76  1.68] neuron -832.2461 -0.56217813
e 80 loss -3.3348198 target loss -2636.1167 other loss -202309.89 tv loss 3909.678
next layer loss target loss 0.0 other loss 9512.373
result 1 [12.06  7.76  1.68] neuron -832.187 -0.5616726
e 90 loss -3.3384132 target loss -2635.3193 other loss -202237.03 tv loss 3907.6191
next layer loss target loss 0.0 other loss 9508.379
result 1 [12.05  7.75  1.68] neuron -831.8729 -0.5610453
e 100 loss -3.3415527 target loss -2634.78 other loss -202171.11 tv loss 3904.627
next layer loss target loss 0.0 other loss 9503.881
result 1 [12.05  7.74  1.68] neuron -831.833 -0.5609325
e 110 loss -3.3442898 target loss -2634.1475 other loss -202109.72 tv loss 3901.9268
next layer loss target loss 0.0 other loss 9499.86
result 1 [12.05  7.73  1.68] neuron -831.7006 -0.56080246
e 120 loss -3.3467026 target loss -2633.7217 other loss -202068.62 tv loss 3900.439
next layer loss target loss 0.0 other loss 9496.369
result 1 [12.05  7.73  1.68] neuron -831.6216 -0.56070614
e 130 loss -3.3488445 target loss -2633.2153 other loss -202052.06 tv loss 3899.4119
next layer loss target loss 0.0 other loss 9495.438
result 1 [12.04  7.72  1.68] neuron -831.47534 -0.5604238
e 140 loss -3.3507404 target loss -2632.8672 other loss -202035.5 tv loss 3898.3118
next layer loss target loss 0.0 other loss 9493.56
result 1 [12.04  7.72  1.68] neuron -831.4208 -0.56034
e 150 loss -3.3524303 target loss -2632.6218 other loss -202026.83 tv loss 3897.2224
next layer loss target loss 0.0 other loss 9491.676
result 1 [12.05  7.72  1.69] neuron -831.41296 -0.5603525
e 160 loss -3.3539352 target loss -2632.3264 other loss -202021.9 tv loss 3896.2563
next layer loss target loss 0.0 other loss 9490.6875
result 1 [12.05  7.72  1.69] neuron -831.3707 -0.5602848
e 170 loss -3.3552952 target loss -2632.0188 other loss -202023.27 tv loss 3895.5623
next layer loss target loss 0.0 other loss 9490.854
result 1 [12.05  7.72  1.69] neuron -831.3127 -0.5601436
e 180 loss -3.356533 target loss -2631.8555 other loss -202022.16 tv loss 3894.967
next layer loss target loss 0.0 other loss 9489.922
result 1 [12.05  7.72  1.69] neuron -831.3052 -0.5601302
e 190 loss -3.3576565 target loss -2631.6282 other loss -202041.36 tv loss 3894.6729
next layer loss target loss 0.0 other loss 9491.219
result 1 [12.05  7.72  1.69] neuron -831.26306 -0.55999494
e 200 loss -3.3587055 target loss -2631.2173 other loss -202044.78 tv loss 3894.4111
next layer loss target loss 0.0 other loss 9492.836
result 1 [12.05  7.72  1.69] neuron -831.11224 -0.5596498
e 210 loss -3.3596764 target loss -2630.9355 other loss -202046.88 tv loss 3893.684
next layer loss target loss 0.0 other loss 9493.656
result 1 [12.05  7.72  1.7 ] neuron -831.05774 -0.55952424
e 220 loss -3.360571 target loss -2630.7085 other loss -202045.78 tv loss 3892.9683
next layer loss target loss 0.0 other loss 9493.355
result 1 [12.05  7.72  1.7 ] neuron -831.0091 -0.5594256
e 230 loss -3.3614197 target loss -2630.43 other loss -202054.62 tv loss 3892.8037
next layer loss target loss 0.0 other loss 9494.572
result 1 [12.05  7.72  1.7 ] neuron -830.91345 -0.55918115
e 240 loss -3.3622265 target loss -2630.265 other loss -202063.17 tv loss 3892.573
next layer loss target loss 0.0 other loss 9495.283
result 1 [12.05  7.72  1.7 ] neuron -830.8644 -0.559044
e 250 loss -3.36298 target loss -2630.1633 other loss -202055.89 tv loss 3892.314
next layer loss target loss 0.0 other loss 9493.932
result 1 [12.05  7.72  1.7 ] neuron -830.8302 -0.55895036
e 260 loss -3.3637066 target loss -2629.9497 other loss -202058.08 tv loss 3892.0864
next layer loss target loss 0.0 other loss 9494.246
result 1 [12.05  7.72  1.7 ] neuron -830.74414 -0.55873686
e 270 loss -3.3644066 target loss -2629.7744 other loss -202056.19 tv loss 3891.8682
next layer loss target loss 0.0 other loss 9494.461
result 1 [12.04  7.72  1.7 ] neuron -830.6743 -0.5585723
e 280 loss -3.365078 target loss -2629.6018 other loss -202064.34 tv loss 3891.8071
next layer loss target loss 0.0 other loss 9495.323
result 1 [12.04  7.72  1.7 ] neuron -830.612 -0.55838317
e 290 loss -3.3657265 target loss -2629.4778 other loss -202077.78 tv loss 3891.8713
next layer loss target loss 0.0 other loss 9496.494
result 1 [12.04  7.72  1.7 ] neuron -830.5592 -0.55820686
e 300 loss -3.366356 target loss -2629.269 other loss -202086.97 tv loss 3891.8792
next layer loss target loss 0.0 other loss 9497.762
result 1 [12.04  7.72  1.7 ] neuron -830.46326 -0.5579465
e 310 loss -3.3669662 target loss -2629.108 other loss -202096.84 tv loss 3891.859
next layer loss target loss 0.0 other loss 9499.037
result 1 [12.04  7.72  1.7 ] neuron -830.40356 -0.55776435
e 320 loss -3.367548 target loss -2628.9236 other loss -202101.95 tv loss 3892.039
next layer loss target loss 0.0 other loss 9499.874
result 1 [12.04  7.71  1.7 ] neuron -830.3147 -0.5575235
e 330 loss -3.368122 target loss -2628.8022 other loss -202121.66 tv loss 3892.427
next layer loss target loss 0.0 other loss 9501.726
result 1 [12.04  7.72  1.71] neuron -830.2456 -0.55728525
e 340 loss -3.3686752 target loss -2628.6997 other loss -202130.12 tv loss 3892.499
next layer loss target loss 0.0 other loss 9502.043
result 1 [12.04  7.72  1.71] neuron -830.1953 -0.55712694
e 350 loss -3.3692207 target loss -2628.58 other loss -202138.25 tv loss 3892.629
next layer loss target loss 0.0 other loss 9502.864
result 1 [12.04  7.72  1.71] neuron -830.12634 -0.5569172
e 360 loss -3.3697472 target loss -2628.4893 other loss -202146.53 tv loss 3892.723
next layer loss target loss 0.0 other loss 9503.402
result 1 [12.04  7.72  1.71] neuron -830.09674 -0.5567978
e 370 loss -3.3702545 target loss -2628.3613 other loss -202144.31 tv loss 3892.5828
next layer loss target loss 0.0 other loss 9503.188
result 1 [12.04  7.72  1.71] neuron -830.03687 -0.5566415
e 380 loss -3.3707561 target loss -2628.2493 other loss -202144.66 tv loss 3892.5566
next layer loss target loss 0.0 other loss 9503.125
result 1 [12.04  7.72  1.71] neuron -829.97864 -0.55647665
e 390 loss -3.3712463 target loss -2628.138 other loss -202150.05 tv loss 3892.657
next layer loss target loss 0.0 other loss 9503.776
result 1 [12.03  7.72  1.71] neuron -829.92773 -0.55631554
e 400 loss -3.3717155 target loss -2628.0205 other loss -202150.61 tv loss 3892.7512
next layer loss target loss 0.0 other loss 9504.265
result 1 [12.03  7.72  1.71] neuron -829.8617 -0.556134
e 410 loss -3.3721714 target loss -2627.8972 other loss -202164.45 tv loss 3893.0024
next layer loss target loss 0.0 other loss 9505.819
result 1 [12.03  7.72  1.71] neuron -829.80206 -0.55592525
e 420 loss -3.3726273 target loss -2627.7795 other loss -202161.66 tv loss 3892.893
next layer loss target loss 0.0 other loss 9505.92
result 1 [12.03  7.72  1.71] neuron -829.7364 -0.55576
e 430 loss -3.3730545 target loss -2627.7083 other loss -202168.86 tv loss 3893.0388
next layer loss target loss 0.0 other loss 9506.568
result 1 [12.03  7.72  1.71] neuron -829.69934 -0.5556256
e 440 loss -3.3734818 target loss -2627.5781 other loss -202174.69 tv loss 3893.227
next layer loss target loss 0.0 other loss 9507.407
result 1 [12.03  7.72  1.71] neuron -829.6405 -0.55545247
e 450 loss -3.373886 target loss -2627.5208 other loss -202184.17 tv loss 3893.169
next layer loss target loss 0.0 other loss 9508.282
result 1 [12.03  7.72  1.71] neuron -829.6153 -0.5553527
e 460 loss -3.3743057 target loss -2627.348 other loss -202196.81 tv loss 3893.5562
next layer loss target loss 0.0 other loss 9510.215
result 1 [12.03  7.72  1.71] neuron -829.50494 -0.55506897
e 470 loss -3.3747158 target loss -2626.9644 other loss -202199.6 tv loss 3894.4075
next layer loss target loss 0.0 other loss 9512.972
result 1 [12.02  7.72  1.71] neuron -829.29285 -0.5545652
e 480 loss -3.3751144 target loss -2626.9595 other loss -202203.19 tv loss 3894.3362
next layer loss target loss 0.0 other loss 9513.025
result 1 [12.02  7.72  1.71] neuron -829.30804 -0.5545384
e 490 loss -3.3754864 target loss -2626.8887 other loss -202208.86 tv loss 3894.3071
next layer loss target loss 0.0 other loss 9513.385
result 1 [12.02  7.72  1.71] neuron -829.2745 -0.5544251
e 500 loss -3.375866 target loss -2626.7866 other loss -202211.14 tv loss 3894.1594
next layer loss target loss 0.0 other loss 9514.012
result 1 [12.02  7.72  1.71] neuron -829.22485 -0.55429935
e 510 loss -3.3762093 target loss -2626.7288 other loss -202217.77 tv loss 3894.1084
next layer loss target loss 0.0 other loss 9514.938
result 1 [12.02  7.72  1.71] neuron -829.1876 -0.55417866
e 520 loss -3.3764782 target loss -2626.7007 other loss -202234.2 tv loss 3894.27
next layer loss target loss 0.0 other loss 9516.418
result 1 [12.02  7.72  1.71] neuron -829.15857 -0.55405384
e 530 loss -3.3768826 target loss -2626.604 other loss -202218.83 tv loss 3894.6187
next layer loss target loss 0.0 other loss 9515.057
result 1 [12.02  7.71  1.71] neuron -829.1461 -0.5539609
e 540 loss -3.377243 target loss -2626.5962 other loss -202238.89 tv loss 3894.5483
next layer loss target loss 0.0 other loss 9516.785
result 1 [12.02  7.72  1.71] neuron -829.126 -0.5538671
e 550 loss -3.3775787 target loss -2626.5347 other loss -202239.53 tv loss 3894.6724
next layer loss target loss 0.0 other loss 9516.843
result 1 [12.02  7.72  1.71] neuron -829.1022 -0.55377364
e 560 loss -3.3778954 target loss -2626.457 other loss -202242.27 tv loss 3894.7722
next layer loss target loss 0.0 other loss 9517.336
result 1 [12.02  7.72  1.71] neuron -829.05994 -0.5536463
e 570 loss -3.378193 target loss -2626.3389 other loss -202241.67 tv loss 3894.772
next layer loss target loss 0.0 other loss 9517.873
result 1 [12.02  7.72  1.71] neuron -828.98474 -0.5534602
e 580 loss -3.3775196 target loss -2626.391 other loss -202294.39 tv loss 3894.5027
next layer loss target loss 0.0 other loss 9522.877
result 1 [12.03  7.73  1.71] neuron -828.9364 -0.55331075
e 590 loss -3.3786488 target loss -2626.279 other loss -202262.75 tv loss 3894.6245
next layer loss target loss 0.0 other loss 9520.203
result 1 [12.02  7.72  1.71] neuron -828.9348 -0.55328554
e 600 loss -3.378933 target loss -2626.1382 other loss -202273.83 tv loss 3894.8362
next layer loss target loss 0.0 other loss 9521.831
result 1 [12.02  7.72  1.71] neuron -828.8702 -0.5531068
e 610 loss -3.3793468 target loss -2626.085 other loss -202253.75 tv loss 3895.1423
next layer loss target loss 0.0 other loss 9520.107
result 1 [12.02  7.72  1.71] neuron -828.8583 -0.55302995
e 620 loss -3.379612 target loss -2625.9834 other loss -202252.86 tv loss 3895.2861
next layer loss target loss 0.0 other loss 9520.14
result 1 [12.01  7.72  1.71] neuron -828.8115 -0.55287594
e 630 loss -3.3798733 target loss -2625.925 other loss -202254.25 tv loss 3895.336
next layer loss target loss 0.0 other loss 9520.404
result 1 [12.01  7.72  1.71] neuron -828.7782 -0.5527688
e 640 loss -3.3801289 target loss -2625.876 other loss -202262.73 tv loss 3895.4434
next layer loss target loss 0.0 other loss 9521.264
result 1 [12.01  7.72  1.71] neuron -828.7517 -0.552662
e 650 loss -3.3803844 target loss -2625.8677 other loss -202269.19 tv loss 3895.4932
next layer loss target loss 0.0 other loss 9521.683
result 1 [12.01  7.72  1.71] neuron -828.7485 -0.55260754
e 660 loss -3.3806171 target loss -2625.8481 other loss -202274.66 tv loss 3895.4927
next layer loss target loss 0.0 other loss 9522.1045
result 1 [12.02  7.72  1.71] neuron -828.7363 -0.552538
e 670 loss -3.380844 target loss -2625.8076 other loss -202275.2 tv loss 3895.499
next layer loss target loss 0.0 other loss 9522.095
result 1 [12.02  7.72  1.71] neuron -828.71875 -0.5524639
e 680 loss -3.381075 target loss -2625.7668 other loss -202279.98 tv loss 3895.5654
next layer loss target loss 0.0 other loss 9522.555
result 1 [12.02  7.72  1.71] neuron -828.69604 -0.55236685
e 690 loss -3.3812904 target loss -2625.712 other loss -202286.92 tv loss 3895.755
next layer loss target loss 0.0 other loss 9523.398
result 1 [12.01  7.72  1.71] neuron -828.6664 -0.5522556
e 700 loss -3.3815079 target loss -2625.6394 other loss -202290.36 tv loss 3895.8037
next layer loss target loss 0.0 other loss 9524.122
result 1 [12.01  7.72  1.71] neuron -828.636 -0.5521544
e 710 loss -3.3817196 target loss -2625.5737 other loss -202294.25 tv loss 3895.8337
next layer loss target loss 0.0 other loss 9524.699
result 1 [12.01  7.72  1.71] neuron -828.6085 -0.55205894
e 720 loss -3.381916 target loss -2625.5015 other loss -202296.92 tv loss 3895.9392
next layer loss target loss 0.0 other loss 9525.264
result 1 [12.01  7.72  1.71] neuron -828.5725 -0.5519387
e 730 loss -3.3821144 target loss -2625.4702 other loss -202301.6 tv loss 3896.0017
next layer loss target loss 0.0 other loss 9525.842
result 1 [12.01  7.72  1.71] neuron -828.5581 -0.55187243
e 740 loss -3.382309 target loss -2625.4182 other loss -202308.34 tv loss 3896.0557
next layer loss target loss 0.0 other loss 9526.6875
result 1 [12.01  7.72  1.71] neuron -828.5378 -0.5517842
e 750 loss -3.382475 target loss -2625.3691 other loss -202319.55 tv loss 3896.1633
next layer loss target loss 0.0 other loss 9527.777
result 1 [12.01  7.72  1.71] neuron -828.5017 -0.5516802
e 760 loss -3.3826694 target loss -2625.2983 other loss -202305.03 tv loss 3896.277
next layer loss target loss 0.0 other loss 9526.639
result 1 [12.01  7.72  1.71] neuron -828.4936 -0.5516348
e 770 loss -3.3828392 target loss -2625.2634 other loss -202316.77 tv loss 3896.4395
next layer loss target loss 0.0 other loss 9527.703
result 1 [12.01  7.72  1.71] neuron -828.48254 -0.551554
e 780 loss -3.3830147 target loss -2625.2312 other loss -202328.03 tv loss 3896.3281
next layer loss target loss 0.0 other loss 9528.928
result 1 [12.01  7.72  1.71] neuron -828.4473 -0.55146617
e 790 loss -3.3831177 target loss -2625.1824 other loss -202340.53 tv loss 3896.332
next layer loss target loss 0.0 other loss 9530.165
result 1 [12.01  7.72  1.71] neuron -828.41394 -0.55136144
e 800 loss -3.3833656 target loss -2625.026 other loss -202332.75 tv loss 3896.588
next layer loss target loss 0.0 other loss 9530.113
result 1 [12.01  7.72  1.71] neuron -828.34924 -0.55118865
e 810 loss -3.3834476 target loss -2624.887 other loss -202323.61 tv loss 3896.9106
next layer loss target loss 0.0 other loss 9529.742
result 1 [12.    7.72  1.71] neuron -828.31683 -0.5510727
e 820 loss -3.3836575 target loss -2624.9292 other loss -202338.38 tv loss 3897.073
next layer loss target loss 0.0 other loss 9530.918
result 1 [12.01  7.72  1.71] neuron -828.3358 -0.55106384
e 830 loss -3.383831 target loss -2624.8618 other loss -202351.53 tv loss 3896.9775
next layer loss target loss 0.0 other loss 9532.107
result 1 [12.01  7.72  1.71] neuron -828.28 -0.55090964
e 840 loss -3.3839836 target loss -2624.8154 other loss -202331.2 tv loss 3896.9487
next layer loss target loss 0.0 other loss 9530.295
result 1 [12.    7.72  1.71] neuron -828.28503 -0.55091304
e 850 loss -3.3840828 target loss -2624.7478 other loss -202360.97 tv loss 3896.9915
next layer loss target loss 0.0 other loss 9533.431
result 1 [12.01  7.72  1.71] neuron -828.23975 -0.55078137
e 860 loss -3.384262 target loss -2624.6655 other loss -202358.19 tv loss 3897.1519
next layer loss target loss 0.0 other loss 9533.657
result 1 [12.01  7.72  1.71] neuron -828.2015 -0.55067027
e 870 loss -3.3843899 target loss -2624.6243 other loss -202359.05 tv loss 3897.106
next layer loss target loss 0.0 other loss 9533.74
result 1 [12.01  7.72  1.71] neuron -828.1902 -0.5506237
e 880 loss -3.3844833 target loss -2624.592 other loss -202379.03 tv loss 3897.373
next layer loss target loss 0.0 other loss 9535.822
result 1 [12.01  7.72  1.71] neuron -828.1638 -0.5505177
e 890 loss -3.3846474 target loss -2624.5432 other loss -202346.67 tv loss 3897.3047
next layer loss target loss 0.0 other loss 9532.829
result 1 [12.    7.72  1.71] neuron -828.1748 -0.5505188
e 900 loss -3.3847427 target loss -2624.458 other loss -202359.45 tv loss 3897.682
next layer loss target loss 0.0 other loss 9534.457
result 1 [12.    7.72  1.71] neuron -828.1448 -0.550402
e 910 loss -3.3848248 target loss -2624.4436 other loss -202384.34 tv loss 3897.3477
next layer loss target loss 0.0 other loss 9536.855
result 1 [12.01  7.73  1.71] neuron -828.0968 -0.5502834
e 920 loss -3.3850403 target loss -2624.3752 other loss -202360.08 tv loss 3897.4492
next layer loss target loss 0.0 other loss 9534.874
result 1 [12.    7.72  1.71] neuron -828.0917 -0.5502488
e 930 loss -3.3851223 target loss -2624.3354 other loss -202365.17 tv loss 3897.725
next layer loss target loss 0.0 other loss 9535.354
result 1 [12.    7.72  1.71] neuron -828.0854 -0.55018747
e 940 loss -3.3852673 target loss -2624.316 other loss -202367.1 tv loss 3897.6182
next layer loss target loss 0.0 other loss 9535.519
result 1 [12.    7.72  1.71] neuron -828.06464 -0.55012083
e 950 loss -3.3852997 target loss -2624.258 other loss -202365.7 tv loss 3897.92
next layer loss target loss 0.0 other loss 9535.739
result 1 [12.    7.72  1.71] neuron -828.0577 -0.5500524
e 960 loss -3.3854809 target loss -2624.2766 other loss -202370.4 tv loss 3897.7317
next layer loss target loss 0.0 other loss 9535.957
result 1 [12.    7.72  1.71] neuron -828.04834 -0.5500082
e 970 loss -3.3855286 target loss -2624.234 other loss -202370.61 tv loss 3898.123
next layer loss target loss 0.0 other loss 9536.128
result 1 [12.    7.72  1.71] neuron -828.0402 -0.5499345
e 980 loss -3.3856812 target loss -2624.2512 other loss -202382.6 tv loss 3897.7773
next layer loss target loss 0.0 other loss 9537.182
result 1 [12.    7.72  1.71] neuron -828.02637 -0.54990053
e 990 loss -3.3857498 target loss -2624.192 other loss -202396.97 tv loss 3898.0913
next layer loss target loss 0.0 other loss 9538.665
result 1 [12.    7.72  1.71] neuron -827.9938 -0.5497772
RE filter conv2d_3 62 RE acc 0.3333333333333333
e 0 loss -6.8533363 target loss -2316.622 other loss -204663.89 tv loss 3976.1335
next layer loss target loss 0.0 other loss 9117.753
result 1 [12.2   8.22  1.93] neuron -718.4221 -0.36941075
e 10 loss -7.1730995 target loss -2266.996 other loss -205056.9 tv loss 3975.087
next layer loss target loss 0.0 other loss 9436.559
result 1 [12.27  8.31  1.81] neuron -690.80774 -0.33931577
e 20 loss -7.337105 target loss -2230.0374 other loss -205364.52 tv loss 3970.3186
next layer loss target loss 0.0 other loss 9675.209
result 1 [12.11  8.19  1.7 ] neuron -671.0785 -0.29495728
e 30 loss -7.402527 target loss -2204.0173 other loss -205573.23 tv loss 3972.4453
next layer loss target loss 0.0 other loss 9816.994
result 1 [11.85  8.11  1.62] neuron -657.4788 -0.26328474
e 40 loss -7.425953 target loss -2191.4587 other loss -206143.31 tv loss 3980.0095
next layer loss target loss 0.0 other loss 9923.187
result 1 [11.75  8.13  1.58] neuron -651.1158 -0.24838078
e 50 loss -7.4425545 target loss -2186.5461 other loss -206549.8 tv loss 3991.0635
next layer loss target loss 0.0 other loss 9978.061
result 1 [11.72  8.15  1.57] neuron -648.7403 -0.24321751
e 60 loss -7.4568043 target loss -2185.9797 other loss -206805.03 tv loss 4003.605
next layer loss target loss 0.0 other loss 9998.985
result 1 [11.72  8.15  1.57] neuron -648.51074 -0.24288103
e 70 loss -7.4669514 target loss -2186.0962 other loss -207004.9 tv loss 4014.142
next layer loss target loss 0.0 other loss 10011.842
result 1 [11.73  8.15  1.57] neuron -648.62537 -0.24326819
e 80 loss -7.474413 target loss -2185.3086 other loss -207182.6 tv loss 4021.2932
next layer loss target loss 0.0 other loss 10026.433
result 1 [11.72  8.16  1.58] neuron -648.24756 -0.24246326
e 90 loss -7.480501 target loss -2183.423 other loss -207326.62 tv loss 4025.006
next layer loss target loss 0.0 other loss 10043.631
result 1 [11.71  8.15  1.57] neuron -647.2278 -0.24045786
e 100 loss -7.4855957 target loss -2181.302 other loss -207430.84 tv loss 4026.2964
next layer loss target loss 0.0 other loss 10059.345
result 1 [11.7   8.15  1.57] neuron -646.08954 -0.23821312
e 110 loss -7.489868 target loss -2179.6118 other loss -207506.98 tv loss 4026.7178
next layer loss target loss 0.0 other loss 10070.317
result 1 [11.69  8.15  1.58] neuron -645.2404 -0.23639205
e 120 loss -7.493532 target loss -2178.6558 other loss -207557.0 tv loss 4027.2764
next layer loss target loss 0.0 other loss 10075.757
result 1 [11.68  8.15  1.58] neuron -644.785 -0.23527524
e 130 loss -7.4967194 target loss -2177.8733 other loss -207606.12 tv loss 4027.7788
next layer loss target loss 0.0 other loss 10079.851
result 1 [11.68  8.16  1.58] neuron -644.4427 -0.23436481
e 140 loss -7.4994564 target loss -2177.2349 other loss -207642.38 tv loss 4027.8237
next layer loss target loss 0.0 other loss 10082.587
result 1 [11.68  8.16  1.59] neuron -644.18933 -0.23359454
e 150 loss -7.501831 target loss -2176.6206 other loss -207661.72 tv loss 4027.4912
next layer loss target loss 0.0 other loss 10084.186
result 1 [11.68  8.16  1.59] neuron -643.9462 -0.23286057
e 160 loss -7.5039425 target loss -2175.8608 other loss -207684.98 tv loss 4027.0764
next layer loss target loss 0.0 other loss 10086.482
result 1 [11.68  8.17  1.6 ] neuron -643.6089 -0.23194227
e 170 loss -7.505808 target loss -2175.0557 other loss -207714.64 tv loss 4026.6362
next layer loss target loss 0.0 other loss 10089.564
result 1 [11.68  8.17  1.6 ] neuron -643.2561 -0.23095062
e 180 loss -7.5074844 target loss -2174.3455 other loss -207727.86 tv loss 4026.058
next layer loss target loss 0.0 other loss 10091.092
result 1 [11.67  8.18  1.6 ] neuron -642.9432 -0.2300812
e 190 loss -7.5089855 target loss -2173.8293 other loss -207757.8 tv loss 4025.7139
next layer loss target loss 0.0 other loss 10093.773
result 1 [11.67  8.18  1.61] neuron -642.7678 -0.2293493
e 200 loss -7.510309 target loss -2173.4827 other loss -207769.31 tv loss 4025.3306
next layer loss target loss 0.0 other loss 10094.037
result 1 [11.67  8.18  1.61] neuron -642.66284 -0.22883882
e 210 loss -7.5115185 target loss -2172.967 other loss -207810.56 tv loss 4025.4062
next layer loss target loss 0.0 other loss 10097.337
result 1 [11.67  8.19  1.62] neuron -642.46936 -0.22807719
e 220 loss -7.5126057 target loss -2172.4253 other loss -207845.53 tv loss 4025.4678
next layer loss target loss 0.0 other loss 10100.657
result 1 [11.67  8.2   1.62] neuron -642.2366 -0.22729237
e 230 loss -7.513588 target loss -2172.0486 other loss -207851.94 tv loss 4025.0586
next layer loss target loss 0.0 other loss 10100.709
result 1 [11.66  8.2   1.62] neuron -642.08875 -0.22676277
e 240 loss -7.514496 target loss -2171.629 other loss -207883.25 tv loss 4024.9204
next layer loss target loss 0.0 other loss 10103.398
result 1 [11.66  8.21  1.62] neuron -641.9353 -0.22614726
e 250 loss -7.515318 target loss -2171.2532 other loss -207884.28 tv loss 4024.6257
next layer loss target loss 0.0 other loss 10103.626
result 1 [11.66  8.21  1.63] neuron -641.77124 -0.22562757
e 260 loss -7.5160885 target loss -2170.84 other loss -207913.22 tv loss 4024.7498
next layer loss target loss 0.0 other loss 10106.062
result 1 [11.65  8.21  1.63] neuron -641.60046 -0.22502795
e 270 loss -7.5167866 target loss -2170.5798 other loss -207933.52 tv loss 4024.8906
next layer loss target loss 0.0 other loss 10107.272
result 1 [11.65  8.22  1.63] neuron -641.5066 -0.22460124
e 280 loss -7.517439 target loss -2170.3706 other loss -207940.69 tv loss 4024.756
next layer loss target loss 0.0 other loss 10107.833
result 1 [11.65  8.22  1.63] neuron -641.4347 -0.22423397
e 290 loss -7.5180264 target loss -2170.1934 other loss -207949.42 tv loss 4024.5022
next layer loss target loss 0.0 other loss 10108.338
result 1 [11.65  8.22  1.63] neuron -641.39343 -0.22394648
e 300 loss -7.518593 target loss -2170.0222 other loss -207952.42 tv loss 4024.2861
next layer loss target loss 0.0 other loss 10108.46
result 1 [11.65  8.22  1.64] neuron -641.33057 -0.22365105
e 310 loss -7.5191174 target loss -2169.6833 other loss -207967.75 tv loss 4024.2524
next layer loss target loss 0.0 other loss 10110.368
result 1 [11.64  8.22  1.64] neuron -641.179 -0.22313313
e 320 loss -7.5196247 target loss -2169.1086 other loss -207992.31 tv loss 4024.3662
next layer loss target loss 0.0 other loss 10113.921
result 1 [11.64  8.22  1.64] neuron -640.87463 -0.22236624
e 330 loss -7.520117 target loss -2168.818 other loss -207990.33 tv loss 4024.3418
next layer loss target loss 0.0 other loss 10114.406
result 1 [11.63  8.22  1.64] neuron -640.7313 -0.22192295
e 340 loss -7.5205803 target loss -2168.5574 other loss -208012.83 tv loss 4024.7373
next layer loss target loss 0.0 other loss 10116.266
result 1 [11.63  8.22  1.64] neuron -640.6229 -0.22153015
e 350 loss -7.5210114 target loss -2168.3625 other loss -208024.4 tv loss 4025.1233
next layer loss target loss 0.0 other loss 10117.242
result 1 [11.63  8.22  1.64] neuron -640.52686 -0.22120997
e 360 loss -7.521433 target loss -2168.2148 other loss -208038.47 tv loss 4025.2393
next layer loss target loss 0.0 other loss 10118.463
result 1 [11.62  8.23  1.64] neuron -640.49133 -0.22092445
e 370 loss -7.521822 target loss -2168.084 other loss -208042.53 tv loss 4025.1597
next layer loss target loss 0.0 other loss 10118.975
result 1 [11.62  8.23  1.64] neuron -640.4419 -0.22069308
e 380 loss -7.5222015 target loss -2167.9312 other loss -208047.62 tv loss 4025.2058
next layer loss target loss 0.0 other loss 10119.32
result 1 [11.62  8.23  1.64] neuron -640.3699 -0.22042029
e 390 loss -7.522579 target loss -2167.7324 other loss -208059.36 tv loss 4025.167
next layer loss target loss 0.0 other loss 10120.363
result 1 [11.62  8.23  1.64] neuron -640.2772 -0.22010791
e 400 loss -7.522932 target loss -2167.5798 other loss -208066.22 tv loss 4025.2017
next layer loss target loss 0.0 other loss 10121.144
result 1 [11.61  8.23  1.64] neuron -640.20905 -0.21982372
e 410 loss -7.5232773 target loss -2167.3594 other loss -208074.48 tv loss 4025.1548
next layer loss target loss 0.0 other loss 10122.465
result 1 [11.61  8.23  1.64] neuron -640.10254 -0.21949576
e 420 loss -7.5236053 target loss -2167.31 other loss -208073.81 tv loss 4025.037
next layer loss target loss 0.0 other loss 10122.344
result 1 [11.61  8.23  1.64] neuron -640.0974 -0.21937756
e 430 loss -7.523924 target loss -2167.2402 other loss -208079.55 tv loss 4025.1436
next layer loss target loss 0.0 other loss 10122.74
result 1 [11.61  8.23  1.64] neuron -640.06586 -0.21923262
e 440 loss -7.524231 target loss -2167.1611 other loss -208085.56 tv loss 4025.2056
next layer loss target loss 0.0 other loss 10123.205
result 1 [11.61  8.23  1.64] neuron -640.02374 -0.21905293
e 450 loss -7.524534 target loss -2167.0637 other loss -208091.53 tv loss 4025.272
next layer loss target loss 0.0 other loss 10123.777
result 1 [11.61  8.23  1.64] neuron -639.97 -0.21886124
e 460 loss -7.5248203 target loss -2166.8716 other loss -208093.38 tv loss 4025.137
next layer loss target loss 0.0 other loss 10124.481
result 1 [11.61  8.23  1.64] neuron -639.8662 -0.21859257
e 470 loss -7.525112 target loss -2166.6106 other loss -208106.73 tv loss 4025.0986
next layer loss target loss 0.0 other loss 10126.572
result 1 [11.6   8.23  1.64] neuron -639.73987 -0.21823353
e 480 loss -7.5253925 target loss -2166.4875 other loss -208118.45 tv loss 4025.2603
next layer loss target loss 0.0 other loss 10127.926
result 1 [11.6   8.23  1.64] neuron -639.68494 -0.21800819
e 490 loss -7.5256653 target loss -2166.361 other loss -208122.14 tv loss 4025.2512
next layer loss target loss 0.0 other loss 10128.475
result 1 [11.6   8.23  1.64] neuron -639.62524 -0.21783094
e 500 loss -7.5259304 target loss -2166.2073 other loss -208135.61 tv loss 4025.356
next layer loss target loss 0.0 other loss 10129.943
result 1 [11.6   8.24  1.64] neuron -639.5565 -0.21757951
e 510 loss -7.52619 target loss -2166.1367 other loss -208140.98 tv loss 4025.4692
next layer loss target loss 0.0 other loss 10130.458
result 1 [11.6   8.24  1.64] neuron -639.52747 -0.21744065
e 520 loss -7.526451 target loss -2166.0535 other loss -208149.1 tv loss 4025.586
next layer loss target loss 0.0 other loss 10131.204
result 1 [11.6   8.24  1.64] neuron -639.487 -0.21730259
e 530 loss -7.526705 target loss -2165.9253 other loss -208153.19 tv loss 4025.5862
next layer loss target loss 0.0 other loss 10131.832
result 1 [11.6   8.24  1.64] neuron -639.4247 -0.21711403
e 540 loss -7.5269527 target loss -2165.8599 other loss -208161.73 tv loss 4025.6301
next layer loss target loss 0.0 other loss 10132.608
result 1 [11.6   8.24  1.64] neuron -639.40967 -0.21699394
e 550 loss -7.5271854 target loss -2165.8591 other loss -208167.95 tv loss 4025.7517
next layer loss target loss 0.0 other loss 10133.016
result 1 [11.6   8.24  1.64] neuron -639.425 -0.21695952
e 560 loss -7.527424 target loss -2165.8232 other loss -208176.77 tv loss 4025.7856
next layer loss target loss 0.0 other loss 10134.012
result 1 [11.6   8.24  1.64] neuron -639.4243 -0.2168658
e 570 loss -7.5276566 target loss -2165.749 other loss -208180.33 tv loss 4025.7725
next layer loss target loss 0.0 other loss 10134.465
result 1 [11.6   8.24  1.64] neuron -639.3945 -0.21674089
e 580 loss -7.5278835 target loss -2165.695 other loss -208182.23 tv loss 4025.786
next layer loss target loss 0.0 other loss 10134.78
result 1 [11.59  8.24  1.64] neuron -639.3644 -0.21664687
e 590 loss -7.5281067 target loss -2165.7195 other loss -208185.81 tv loss 4025.886
next layer loss target loss 0.0 other loss 10134.76
result 1 [11.59  8.24  1.64] neuron -639.38464 -0.2166297
e 600 loss -7.528322 target loss -2165.7156 other loss -208186.66 tv loss 4025.8755
next layer loss target loss 0.0 other loss 10134.637
result 1 [11.59  8.24  1.64] neuron -639.38574 -0.21660905
e 610 loss -7.5285397 target loss -2165.6914 other loss -208188.03 tv loss 4025.9062
next layer loss target loss 0.0 other loss 10134.7705
result 1 [11.59  8.24  1.64] neuron -639.3712 -0.21655133
e 620 loss -7.5287495 target loss -2165.692 other loss -208188.11 tv loss 4025.8677
next layer loss target loss 0.0 other loss 10134.843
result 1 [11.59  8.24  1.64] neuron -639.37134 -0.21651597
e 630 loss -7.528948 target loss -2165.6985 other loss -208188.98 tv loss 4025.8823
next layer loss target loss 0.0 other loss 10134.896
result 1 [11.59  8.24  1.64] neuron -639.3767 -0.21651024
e 640 loss -7.5291557 target loss -2165.6836 other loss -208190.38 tv loss 4025.9312
next layer loss target loss 0.0 other loss 10135.096
result 1 [11.59  8.24  1.64] neuron -639.37036 -0.21647723
e 650 loss -7.529358 target loss -2165.624 other loss -208192.47 tv loss 4025.9526
next layer loss target loss 0.0 other loss 10135.399
result 1 [11.59  8.24  1.64] neuron -639.3325 -0.21640164
e 660 loss -7.5295563 target loss -2165.6045 other loss -208202.53 tv loss 4026.266
next layer loss target loss 0.0 other loss 10136.264
result 1 [11.59  8.24  1.64] neuron -639.322 -0.21634361
e 670 loss -7.529745 target loss -2165.5906 other loss -208200.95 tv loss 4026.2603
next layer loss target loss 0.0 other loss 10136.2295
result 1 [11.59  8.24  1.64] neuron -639.3113 -0.21632724
e 680 loss -7.5299473 target loss -2165.5996 other loss -208203.22 tv loss 4026.267
next layer loss target loss 0.0 other loss 10136.464
result 1 [11.59  8.24  1.64] neuron -639.3213 -0.21632215
e 690 loss -7.53014 target loss -2165.585 other loss -208205.4 tv loss 4026.2666
next layer loss target loss 0.0 other loss 10136.705
result 1 [11.59  8.24  1.64] neuron -639.3148 -0.21630351
e 700 loss -7.5302544 target loss -2165.5928 other loss -208188.72 tv loss 4026.2246
next layer loss target loss 0.0 other loss 10135.377
result 1 [11.59  8.23  1.64] neuron -639.30896 -0.21629858
e 710 loss -7.5301476 target loss -2165.3613 other loss -208213.72 tv loss 4025.6047
next layer loss target loss 0.0 other loss 10137.363
result 1 [11.6   8.24  1.64] neuron -639.18933 -0.21621223
e 720 loss -7.5304775 target loss -2165.3677 other loss -208228.23 tv loss 4026.1174
next layer loss target loss 0.0 other loss 10139.184
result 1 [11.59  8.24  1.64] neuron -639.19604 -0.21612787
e 730 loss -7.5306797 target loss -2165.292 other loss -208226.53 tv loss 4025.9836
next layer loss target loss 0.0 other loss 10139.222
result 1 [11.59  8.24  1.64] neuron -639.1616 -0.21607986
e 740 loss -7.5309944 target loss -2165.3623 other loss -208217.31 tv loss 4026.0613
next layer loss target loss 0.0 other loss 10138.309
result 1 [11.59  8.24  1.64] neuron -639.1912 -0.21613976
e 750 loss -7.531233 target loss -2165.422 other loss -208198.55 tv loss 4025.8228
next layer loss target loss 0.0 other loss 10136.389
result 1 [11.59  8.24  1.64] neuron -639.2196 -0.21624774
e 760 loss -7.53141 target loss -2165.3718 other loss -208205.47 tv loss 4026.086
next layer loss target loss 0.0 other loss 10137.136
result 1 [11.59  8.24  1.64] neuron -639.1862 -0.21617113
e 770 loss -7.531584 target loss -2165.312 other loss -208228.06 tv loss 4026.4915
next layer loss target loss 0.0 other loss 10139.278
result 1 [11.59  8.24  1.64] neuron -639.16486 -0.21608093
e 780 loss -7.5317345 target loss -2165.3022 other loss -208222.89 tv loss 4026.364
next layer loss target loss 0.0 other loss 10138.91
result 1 [11.59  8.24  1.64] neuron -639.15295 -0.21610072
e 790 loss -7.5319157 target loss -2165.2515 other loss -208228.19 tv loss 4026.4585
next layer loss target loss 0.0 other loss 10139.523
result 1 [11.59  8.24  1.64] neuron -639.1275 -0.2160553
e 800 loss -7.5320816 target loss -2165.2607 other loss -208235.16 tv loss 4026.6206
next layer loss target loss 0.0 other loss 10140.1045
result 1 [11.59  8.24  1.64] neuron -639.1358 -0.2160589
e 810 loss -7.5322456 target loss -2165.2378 other loss -208235.6 tv loss 4026.589
next layer loss target loss 0.0 other loss 10140.201
result 1 [11.59  8.24  1.64] neuron -639.12524 -0.21605387
e 820 loss -7.5323715 target loss -2165.1665 other loss -208232.4 tv loss 4026.4817
next layer loss target loss 0.0 other loss 10140.065
result 1 [11.59  8.24  1.64] neuron -639.07965 -0.21600236
e 830 loss -7.5325146 target loss -2165.0696 other loss -208243.16 tv loss 4026.5396
next layer loss target loss 0.0 other loss 10141.271
result 1 [11.59  8.24  1.64] neuron -639.03094 -0.2158932
e 840 loss -7.532709 target loss -2165.0356 other loss -208241.3 tv loss 4026.544
next layer loss target loss 0.0 other loss 10141.277
result 1 [11.59  8.24  1.64] neuron -639.007 -0.21585417
e 850 loss -7.532917 target loss -2164.9873 other loss -208244.16 tv loss 4026.6948
next layer loss target loss 0.0 other loss 10141.634
result 1 [11.58  8.24  1.64] neuron -638.9867 -0.21580067
e 860 loss -7.5331078 target loss -2164.9404 other loss -208244.7 tv loss 4026.788
next layer loss target loss 0.0 other loss 10141.75
result 1 [11.58  8.23  1.64] neuron -638.9563 -0.21573359
e 870 loss -7.5332794 target loss -2164.9102 other loss -208251.7 tv loss 4026.9792
next layer loss target loss 0.0 other loss 10142.376
result 1 [11.58  8.23  1.64] neuron -638.9446 -0.2157034
e 880 loss -7.5334625 target loss -2164.8958 other loss -208257.66 tv loss 4027.2188
next layer loss target loss 0.0 other loss 10142.899
result 1 [11.58  8.23  1.64] neuron -638.9396 -0.21566324
e 890 loss -7.5336246 target loss -2164.8728 other loss -208261.48 tv loss 4027.414
next layer loss target loss 0.0 other loss 10143.28
result 1 [11.58  8.23  1.64] neuron -638.925 -0.21561965
e 900 loss -7.533798 target loss -2164.8516 other loss -208257.92 tv loss 4027.4197
next layer loss target loss 0.0 other loss 10142.954
result 1 [11.58  8.23  1.64] neuron -638.91724 -0.2155981
e 910 loss -7.5339565 target loss -2164.814 other loss -208263.8 tv loss 4027.7153
next layer loss target loss 0.0 other loss 10143.521
result 1 [11.58  8.23  1.64] neuron -638.9015 -0.21555036
e 920 loss -7.534109 target loss -2164.7515 other loss -208276.69 tv loss 4027.843
next layer loss target loss 0.0 other loss 10144.716
result 1 [11.58  8.23  1.64] neuron -638.8756 -0.21549748
e 930 loss -7.5342674 target loss -2164.7192 other loss -208277.9 tv loss 4027.9668
next layer loss target loss 0.0 other loss 10144.863
result 1 [11.58  8.23  1.64] neuron -638.86487 -0.21546404
e 940 loss -7.53442 target loss -2164.7 other loss -208283.47 tv loss 4028.0342
next layer loss target loss 0.0 other loss 10145.197
result 1 [11.58  8.23  1.64] neuron -638.8601 -0.21546067
e 950 loss -7.5345764 target loss -2164.677 other loss -208287.0 tv loss 4028.1414
next layer loss target loss 0.0 other loss 10145.516
result 1 [11.58  8.23  1.64] neuron -638.8559 -0.21544553
e 960 loss -7.534729 target loss -2164.6604 other loss -208290.6 tv loss 4028.1838
next layer loss target loss 0.0 other loss 10145.794
result 1 [11.58  8.23  1.64] neuron -638.85254 -0.21544862
e 970 loss -7.534872 target loss -2164.6528 other loss -208293.22 tv loss 4028.266
next layer loss target loss 0.0 other loss 10145.923
result 1 [11.58  8.23  1.64] neuron -638.8484 -0.21544896
e 980 loss -7.535017 target loss -2164.6418 other loss -208298.95 tv loss 4028.3535
next layer loss target loss 0.0 other loss 10146.475
result 1 [11.58  8.23  1.64] neuron -638.8474 -0.21543507
e 990 loss -7.535166 target loss -2164.634 other loss -208300.75 tv loss 4028.4878
next layer loss target loss 0.0 other loss 10146.628
result 1 [11.58  8.23  1.64] neuron -638.84644 -0.21543732
RE filter conv2d_3 64 RE acc 0.3333333333333333
e 0 loss -10.653753 target loss -1963.0587 other loss -205017.45 tv loss 3976.1335
next layer loss target loss 26.474726 other loss 9091.278
result 1 [12.2   8.22  1.93] neuron -605.349 0.458169
e 10 loss -10.963724 target loss -1922.1185 other loss -207902.78 tv loss 4046.5808
next layer loss target loss 30.41512 other loss 9455.7295
result 1 [12.35  8.69  1.91] neuron -591.40735 0.4950597
e 20 loss -11.106129 target loss -1895.1483 other loss -211274.02 tv loss 4112.3735
next layer loss target loss 33.610886 other loss 9755.589
result 1 [12.34  9.03  1.95] neuron -581.3036 0.50957215
e 30 loss -11.168781 target loss -1876.4916 other loss -213791.75 tv loss 4163.06
next layer loss target loss 36.15164 other loss 9993.716
result 1 [12.31  9.18  1.97] neuron -574.2167 0.5124364
e 40 loss -11.208143 target loss -1867.5535 other loss -215259.4 tv loss 4201.1914
next layer loss target loss 37.826042 other loss 10144.248
result 1 [12.32  9.17  1.98] neuron -570.24915 0.5119821
e 50 loss -11.234694 target loss -1864.0405 other loss -216173.92 tv loss 4231.4316
next layer loss target loss 38.808353 other loss 10225.913
result 1 [12.35  9.11  1.99] neuron -568.38904 0.52240026
e 60 loss -11.251051 target loss -1860.7511 other loss -216842.19 tv loss 4252.693
next layer loss target loss 39.661877 other loss 10289.799
result 1 [12.37  9.08  2.  ] neuron -566.83075 0.532308
e 70 loss -11.263176 target loss -1856.5696 other loss -217427.84 tv loss 4266.533
next layer loss target loss 40.419445 other loss 10344.286
result 1 [12.39  9.1   2.02] neuron -565.21497 0.5409136
e 80 loss -11.27318 target loss -1852.8198 other loss -217948.84 tv loss 4276.788
next layer loss target loss 41.06149 other loss 10388.424
result 1 [12.41  9.14  2.03] neuron -563.86597 0.5483135
e 90 loss -11.281628 target loss -1850.5125 other loss -218235.23 tv loss 4282.821
next layer loss target loss 41.47431 other loss 10413.373
result 1 [12.42  9.16  2.04] neuron -563.0792 0.55209076
e 100 loss -11.288996 target loss -1849.345 other loss -218369.84 tv loss 4285.6367
next layer loss target loss 41.681606 other loss 10423.683
result 1 [12.43  9.17  2.06] neuron -562.72784 0.55349517
e 110 loss -11.295439 target loss -1848.3754 other loss -218469.05 tv loss 4286.645
next layer loss target loss 41.82494 other loss 10429.405
result 1 [12.44  9.18  2.07] neuron -562.4779 0.55448055
e 120 loss -11.301067 target loss -1847.3806 other loss -218566.86 tv loss 4287.292
next layer loss target loss 41.95883 other loss 10434.9795
result 1 [12.45  9.2   2.08] neuron -562.2378 0.5555867
e 130 loss -11.305996 target loss -1846.3052 other loss -218661.72 tv loss 4288.016
next layer loss target loss 42.10823 other loss 10441.101
result 1 [12.46  9.22  2.09] neuron -561.9737 0.55673873
e 140 loss -11.310295 target loss -1845.4714 other loss -218742.25 tv loss 4288.9834
next layer loss target loss 42.237934 other loss 10446.087
result 1 [12.47  9.23  2.1 ] neuron -561.77075 0.55753636
e 150 loss -11.314083 target loss -1844.7472 other loss -218814.75 tv loss 4289.658
next layer loss target loss 42.351128 other loss 10450.2705
result 1 [12.48  9.24  2.11] neuron -561.58307 0.5581591
e 160 loss -11.317488 target loss -1843.978 other loss -218894.48 tv loss 4290.4053
next layer loss target loss 42.475883 other loss 10455.3
result 1 [12.48  9.26  2.12] neuron -561.4004 0.5590465
e 170 loss -11.320526 target loss -1843.1434 other loss -218973.44 tv loss 4291.1953
next layer loss target loss 42.609276 other loss 10460.863
result 1 [12.49  9.28  2.12] neuron -561.20056 0.56002843
e 180 loss -11.3232765 target loss -1842.4999 other loss -219022.61 tv loss 4291.5195
next layer loss target loss 42.70798 other loss 10463.902
result 1 [12.49  9.29  2.13] neuron -561.05054 0.5603781
e 190 loss -11.325769 target loss -1842.0505 other loss -219051.2 tv loss 4291.7275
next layer loss target loss 42.78914 other loss 10465.079
result 1 [12.49  9.31  2.14] neuron -560.98267 0.56049776
e 200 loss -11.328047 target loss -1841.5281 other loss -219074.84 tv loss 4291.4585
next layer loss target loss 42.856785 other loss 10466.461
result 1 [12.49  9.32  2.14] neuron -560.9024 0.56065583
e 210 loss -11.330105 target loss -1840.9277 other loss -219121.2 tv loss 4291.418
next layer loss target loss 42.932545 other loss 10469.854
result 1 [12.5   9.33  2.15] neuron -560.77527 0.5611309
e 220 loss -11.331963 target loss -1840.509 other loss -219164.75 tv loss 4291.6646
next layer loss target loss 42.989357 other loss 10472.618
result 1 [12.5   9.34  2.15] neuron -560.68097 0.56139505
e 230 loss -11.333666 target loss -1840.0739 other loss -219221.17 tv loss 4292.2305
next layer loss target loss 43.060703 other loss 10476.096
result 1 [12.5   9.35  2.16] neuron -560.55475 0.56172204
e 240 loss -11.335239 target loss -1839.4507 other loss -219295.27 tv loss 4293.0645
next layer loss target loss 43.153904 other loss 10481.939
result 1 [12.5   9.36  2.16] neuron -560.3633 0.5623878
e 250 loss -11.336693 target loss -1838.9958 other loss -219347.03 tv loss 4293.515
next layer loss target loss 43.211338 other loss 10486.409
result 1 [12.5   9.37  2.17] neuron -560.2195 0.56278396
e 260 loss -11.338011 target loss -1838.5665 other loss -219392.58 tv loss 4293.9873
next layer loss target loss 43.265285 other loss 10490.752
result 1 [12.51  9.38  2.17] neuron -560.08374 0.5631219
e 270 loss -11.33927 target loss -1837.9879 other loss -219471.33 tv loss 4294.6006
next layer loss target loss 43.334393 other loss 10497.133
result 1 [12.51  9.38  2.18] neuron -559.87646 0.56381273
e 280 loss -11.340441 target loss -1837.5559 other loss -219527.62 tv loss 4295.168
next layer loss target loss 43.386765 other loss 10502.282
result 1 [12.51  9.39  2.18] neuron -559.7218 0.56418717
e 290 loss -11.341534 target loss -1837.2794 other loss -219560.94 tv loss 4295.729
next layer loss target loss 43.431503 other loss 10505.524
result 1 [12.51  9.39  2.18] neuron -559.63354 0.5642772
e 300 loss -11.342562 target loss -1836.9268 other loss -219603.39 tv loss 4296.0435
next layer loss target loss 43.476795 other loss 10509.151
result 1 [12.52  9.4   2.19] neuron -559.5171 0.564461
e 310 loss -11.343531 target loss -1836.6167 other loss -219641.02 tv loss 4296.2974
next layer loss target loss 43.50915 other loss 10512.732
result 1 [12.52  9.4   2.19] neuron -559.4095 0.56458473
e 320 loss -11.344463 target loss -1836.2008 other loss -219691.2 tv loss 4296.78
next layer loss target loss 43.560986 other loss 10517.363
result 1 [12.52  9.41  2.19] neuron -559.26355 0.56490433
e 330 loss -11.345358 target loss -1835.88 other loss -219731.3 tv loss 4297.338
next layer loss target loss 43.612675 other loss 10521.059
result 1 [12.52  9.41  2.19] neuron -559.1429 0.56502914
e 340 loss -11.346214 target loss -1835.6396 other loss -219766.56 tv loss 4297.8706
next layer loss target loss 43.65184 other loss 10524.019
result 1 [12.52  9.42  2.2 ] neuron -559.0464 0.56504
e 350 loss -11.347017 target loss -1835.2924 other loss -219810.94 tv loss 4298.2905
next layer loss target loss 43.700024 other loss 10527.883
result 1 [12.52  9.42  2.2 ] neuron -558.91174 0.5652174
e 360 loss -11.347799 target loss -1835.0559 other loss -219846.11 tv loss 4298.7783
next layer loss target loss 43.732933 other loss 10531.09
result 1 [12.52  9.42  2.2 ] neuron -558.8164 0.5652962
e 370 loss -11.3485565 target loss -1834.8062 other loss -219880.4 tv loss 4299.1543
next layer loss target loss 43.762196 other loss 10534.508
result 1 [12.52  9.42  2.2 ] neuron -558.7136 0.5653677
e 380 loss -11.349262 target loss -1834.5771 other loss -219910.83 tv loss 4299.52
next layer loss target loss 43.79274 other loss 10537.2295
result 1 [12.52  9.43  2.2 ] neuron -558.6262 0.56537294
e 390 loss -11.349941 target loss -1834.3295 other loss -219939.56 tv loss 4300.059
next layer loss target loss 43.839745 other loss 10539.685
result 1 [12.52  9.43  2.2 ] neuron -558.53735 0.5653628
e 400 loss -11.350607 target loss -1834.0988 other loss -219960.19 tv loss 4300.292
next layer loss target loss 43.877907 other loss 10541.393
result 1 [12.52  9.43  2.2 ] neuron -558.45544 0.56523764
e 410 loss -11.3512745 target loss -1834.0555 other loss -219951.39 tv loss 4299.9844
next layer loss target loss 43.88726 other loss 10540.119
result 1 [12.52  9.44  2.2 ] neuron -558.46313 0.5647143
e 420 loss -11.351917 target loss -1834.0566 other loss -219933.16 tv loss 4299.5483
next layer loss target loss 43.89128 other loss 10538.27
result 1 [12.52  9.45  2.21] neuron -558.4934 0.5641229
e 430 loss -11.352509 target loss -1833.8485 other loss -219954.88 tv loss 4299.609
next layer loss target loss 43.91619 other loss 10540.504
result 1 [12.52  9.45  2.21] neuron -558.4182 0.5641109
e 440 loss -11.353086 target loss -1833.6505 other loss -219981.52 tv loss 4300.0405
next layer loss target loss 43.940678 other loss 10543.444
result 1 [12.52  9.45  2.21] neuron -558.33954 0.5641742
e 450 loss -11.353634 target loss -1833.5017 other loss -220010.94 tv loss 4300.4644
next layer loss target loss 43.961514 other loss 10546.022
result 1 [12.52  9.45  2.21] neuron -558.26764 0.5642023
e 460 loss -11.354141 target loss -1833.3091 other loss -220037.45 tv loss 4300.852
next layer loss target loss 43.983856 other loss 10548.818
result 1 [12.52  9.45  2.21] neuron -558.19165 0.5642841
e 470 loss -11.354643 target loss -1833.1891 other loss -220058.05 tv loss 4301.1304
next layer loss target loss 43.99888 other loss 10551.035
result 1 [12.52  9.45  2.21] neuron -558.1334 0.564224
e 480 loss -11.355125 target loss -1833.0646 other loss -220077.9 tv loss 4301.379
next layer loss target loss 44.01243 other loss 10553.073
result 1 [12.52  9.45  2.21] neuron -558.07526 0.5641515
e 490 loss -11.355589 target loss -1832.8768 other loss -220101.34 tv loss 4301.5215
next layer loss target loss 44.029533 other loss 10555.64
result 1 [12.52  9.45  2.21] neuron -557.9997 0.5641563
e 500 loss -11.356037 target loss -1832.7251 other loss -220125.83 tv loss 4301.8506
next layer loss target loss 44.045597 other loss 10558.135
result 1 [12.52  9.45  2.21] neuron -557.9297 0.5641409
e 510 loss -11.356466 target loss -1832.5614 other loss -220152.75 tv loss 4302.245
next layer loss target loss 44.06765 other loss 10560.781
result 1 [12.52  9.45  2.21] neuron -557.8526 0.56416047
e 520 loss -11.356876 target loss -1832.3994 other loss -220172.78 tv loss 4302.6626
next layer loss target loss 44.095943 other loss 10562.877
result 1 [12.52  9.46  2.21] neuron -557.7893 0.5641624
e 530 loss -11.357273 target loss -1832.2426 other loss -220193.22 tv loss 4303.034
next layer loss target loss 44.12285 other loss 10564.926
result 1 [12.52  9.46  2.21] neuron -557.72595 0.56415963
e 540 loss -11.357651 target loss -1832.099 other loss -220209.38 tv loss 4303.2866
next layer loss target loss 44.147263 other loss 10566.48
result 1 [12.52  9.46  2.21] neuron -557.67456 0.5640948
e 550 loss -11.358021 target loss -1831.9678 other loss -220224.58 tv loss 4303.483
next layer loss target loss 44.16596 other loss 10568.087
result 1 [12.52  9.46  2.21] neuron -557.6277 0.5640372
e 560 loss -11.358374 target loss -1831.8843 other loss -220239.22 tv loss 4303.783
next layer loss target loss 44.182774 other loss 10569.489
result 1 [12.52  9.46  2.21] neuron -557.5902 0.56393373
e 570 loss -11.358707 target loss -1831.781 other loss -220252.9 tv loss 4304.1445
next layer loss target loss 44.2028 other loss 10571.01
result 1 [12.52  9.46  2.21] neuron -557.5508 0.56386256
e 580 loss -11.359041 target loss -1831.6847 other loss -220267.38 tv loss 4304.4204
next layer loss target loss 44.2178 other loss 10572.408
result 1 [12.52  9.46  2.21] neuron -557.5067 0.5637444
e 590 loss -11.359346 target loss -1831.5999 other loss -220282.6 tv loss 4304.738
next layer loss target loss 44.233776 other loss 10573.918
result 1 [12.52  9.46  2.21] neuron -557.4654 0.563673
e 600 loss -11.359655 target loss -1831.4418 other loss -220301.27 tv loss 4304.9834
next layer loss target loss 44.25716 other loss 10575.812
result 1 [12.52  9.47  2.21] neuron -557.4045 0.5636896
e 610 loss -11.3599415 target loss -1831.314 other loss -220315.19 tv loss 4305.208
next layer loss target loss 44.27609 other loss 10577.209
result 1 [12.52  9.47  2.21] neuron -557.36096 0.56367636
e 620 loss -11.360207 target loss -1831.2013 other loss -220330.19 tv loss 4305.384
next layer loss target loss 44.291237 other loss 10578.646
result 1 [12.52  9.47  2.21] neuron -557.3191 0.56367505
e 630 loss -11.360483 target loss -1831.1158 other loss -220343.52 tv loss 4305.632
next layer loss target loss 44.30156 other loss 10580.029
result 1 [12.51  9.47  2.21] neuron -557.2811 0.5636157
e 640 loss -11.360739 target loss -1831.0269 other loss -220359.73 tv loss 4305.9307
next layer loss target loss 44.31578 other loss 10581.623
result 1 [12.51  9.47  2.21] neuron -557.2412 0.5636089
e 650 loss -11.361004 target loss -1830.9606 other loss -220361.62 tv loss 4306.0703
next layer loss target loss 44.33102 other loss 10581.807
result 1 [12.51  9.47  2.21] neuron -557.22485 0.56340265
e 660 loss -11.361248 target loss -1830.9335 other loss -220363.9 tv loss 4306.1035
next layer loss target loss 44.34734 other loss 10581.38
result 1 [12.51  9.48  2.21] neuron -557.22156 0.56315005
e 670 loss -11.361504 target loss -1830.9233 other loss -220358.34 tv loss 4306.2188
next layer loss target loss 44.35739 other loss 10580.775
result 1 [12.51  9.48  2.21] neuron -557.22595 0.562866
e 680 loss -11.361748 target loss -1830.8584 other loss -220359.45 tv loss 4306.199
next layer loss target loss 44.36053 other loss 10581.386
result 1 [12.51  9.48  2.21] neuron -557.2158 0.5629995
e 690 loss -11.361979 target loss -1830.794 other loss -220365.22 tv loss 4306.3076
next layer loss target loss 44.36783 other loss 10582.164
result 1 [12.51  9.48  2.21] neuron -557.1959 0.5631404
e 700 loss -11.362213 target loss -1830.7523 other loss -220366.1 tv loss 4306.3276
next layer loss target loss 44.37907 other loss 10582.058
result 1 [12.51  9.48  2.21] neuron -557.1803 0.5636066
e 710 loss -11.362471 target loss -1831.127 other loss -220299.27 tv loss 4306.373
next layer loss target loss 44.371117 other loss 10576.136
result 1 [12.51  9.48  2.21] neuron -557.3478 0.5645139
e 720 loss -11.362709 target loss -1831.1113 other loss -220288.53 tv loss 4306.0244
next layer loss target loss 44.385704 other loss 10574.394
result 1 [12.51  9.49  2.21] neuron -557.3657 0.56534433
e 730 loss -11.362923 target loss -1831.0303 other loss -220295.77 tv loss 4306.0806
next layer loss target loss 44.389454 other loss 10575.454
result 1 [12.51  9.49  2.21] neuron -557.34534 0.5654061
e 740 loss -11.363129 target loss -1830.9703 other loss -220300.62 tv loss 4306.2725
next layer loss target loss 44.393894 other loss 10576.402
result 1 [12.51  9.48  2.21] neuron -557.32385 0.5655415
e 750 loss -11.363342 target loss -1830.9006 other loss -220311.02 tv loss 4306.501
next layer loss target loss 44.40518 other loss 10577.485
result 1 [12.5   9.48  2.21] neuron -557.2975 0.565632
e 760 loss -11.363548 target loss -1830.877 other loss -220313.75 tv loss 4306.647
next layer loss target loss 44.410404 other loss 10577.953
result 1 [12.5   9.48  2.21] neuron -557.2925 0.5657718
e 770 loss -11.363745 target loss -1830.8143 other loss -220318.69 tv loss 4306.654
next layer loss target loss 44.418827 other loss 10578.322
result 1 [12.5   9.49  2.21] neuron -557.2743 0.5660914
e 780 loss -11.363935 target loss -1830.7742 other loss -220322.45 tv loss 4306.7344
next layer loss target loss 44.421463 other loss 10579.051
result 1 [12.5   9.49  2.21] neuron -557.2599 0.5661409
e 790 loss -11.36413 target loss -1830.6791 other loss -220336.73 tv loss 4306.944
next layer loss target loss 44.43389 other loss 10580.365
result 1 [12.5   9.49  2.21] neuron -557.22626 0.566316
e 800 loss -11.364309 target loss -1830.6265 other loss -220346.36 tv loss 4307.1
next layer loss target loss 44.439247 other loss 10581.214
result 1 [12.5   9.49  2.21] neuron -557.20575 0.56639373
e 810 loss -11.364479 target loss -1830.5409 other loss -220355.84 tv loss 4307.258
next layer loss target loss 44.453262 other loss 10582.115
result 1 [12.5   9.49  2.21] neuron -557.178 0.56667864
e 820 loss -11.364658 target loss -1830.4923 other loss -220363.06 tv loss 4307.454
next layer loss target loss 44.462463 other loss 10582.801
result 1 [12.5   9.49  2.21] neuron -557.161 0.56683886
e 830 loss -11.364843 target loss -1830.4053 other loss -220373.38 tv loss 4307.6934
next layer loss target loss 44.478 other loss 10583.965
result 1 [12.5   9.49  2.2 ] neuron -557.12836 0.5670155
e 840 loss -11.3650055 target loss -1830.3635 other loss -220379.52 tv loss 4307.9424
next layer loss target loss 44.488354 other loss 10584.743
result 1 [12.5   9.49  2.2 ] neuron -557.1126 0.5671674
e 850 loss -11.36517 target loss -1830.2914 other loss -220389.83 tv loss 4308.1533
next layer loss target loss 44.49961 other loss 10585.686
result 1 [12.5   9.49  2.2 ] neuron -557.0857 0.5673188
e 860 loss -11.365335 target loss -1830.2372 other loss -220395.4 tv loss 4308.4023
next layer loss target loss 44.51181 other loss 10586.3955
result 1 [12.5   9.49  2.2 ] neuron -557.0708 0.56746423
e 870 loss -11.365494 target loss -1830.1938 other loss -220399.98 tv loss 4308.5522
next layer loss target loss 44.518024 other loss 10587.096
result 1 [12.5   9.49  2.2 ] neuron -557.058 0.56752527
e 880 loss -11.365643 target loss -1830.1261 other loss -220407.06 tv loss 4308.6387
next layer loss target loss 44.52621 other loss 10587.725
result 1 [12.5   9.49  2.2 ] neuron -557.04016 0.5676892
e 890 loss -11.365801 target loss -1830.1008 other loss -220407.2 tv loss 4308.692
next layer loss target loss 44.529984 other loss 10587.948
result 1 [12.5   9.49  2.2 ] neuron -557.0363 0.56780326
e 900 loss -11.365955 target loss -1830.0669 other loss -220413.06 tv loss 4308.8633
next layer loss target loss 44.53878 other loss 10588.408
result 1 [12.5   9.49  2.2 ] neuron -557.02795 0.5679592
e 910 loss -11.366104 target loss -1830.0244 other loss -220419.31 tv loss 4309.0063
next layer loss target loss 44.54685 other loss 10588.958
result 1 [12.5   9.49  2.2 ] neuron -557.0167 0.5681019
e 920 loss -11.366253 target loss -1829.9708 other loss -220426.6 tv loss 4309.188
next layer loss target loss 44.555313 other loss 10589.728
result 1 [12.5   9.49  2.2 ] neuron -557.00037 0.5681995
e 930 loss -11.366396 target loss -1829.9102 other loss -220433.95 tv loss 4309.371
next layer loss target loss 44.56581 other loss 10590.3545
result 1 [12.5   9.49  2.2 ] neuron -556.98206 0.5684079
e 940 loss -11.366535 target loss -1829.884 other loss -220439.38 tv loss 4309.4893
next layer loss target loss 44.57503 other loss 10590.502
result 1 [12.49  9.49  2.2 ] neuron -556.97614 0.5687089
e 950 loss -11.36668 target loss -1829.8636 other loss -220443.11 tv loss 4309.644
next layer loss target loss 44.58328 other loss 10590.773
result 1 [12.49  9.49  2.2 ] neuron -556.9707 0.56887186
e 960 loss -11.366802 target loss -1829.8278 other loss -220449.33 tv loss 4309.8354
next layer loss target loss 44.59036 other loss 10591.589
result 1 [12.49  9.49  2.2 ] neuron -556.95795 0.56890035
e 970 loss -11.36693 target loss -1829.763 other loss -220457.47 tv loss 4310.0845
next layer loss target loss 44.603065 other loss 10592.594
result 1 [12.49  9.49  2.2 ] neuron -556.9398 0.56898344
e 980 loss -11.367067 target loss -1829.6758 other loss -220465.27 tv loss 4310.15
next layer loss target loss 44.612465 other loss 10593.427
result 1 [12.49  9.49  2.2 ] neuron -556.9158 0.5691056
e 990 loss -11.367193 target loss -1829.634 other loss -220470.62 tv loss 4310.304
next layer loss target loss 44.61999 other loss 10593.952
result 1 [12.49  9.49  2.2 ] neuron -556.9082 0.56926596
RE filter conv2d_3 52 RE acc 0.3333333333333333
e 0 loss -14.191797 target loss -1597.0911 other loss -28567.803 tv loss 3976.1335
next layer loss target loss 16.985151 other loss 100005.93
result 1 [12.2   8.22  1.93] neuron -449.94666 0.34333497
e 10 loss -14.621736 target loss -1525.3589 other loss -29620.867 tv loss 4001.0562
next layer loss target loss 22.999714 other loss 101908.21
result 1 [12.25  8.58  1.86] neuron -420.6134 0.39049727
e 20 loss -14.748161 target loss -1504.7866 other loss -30963.787 tv loss 4049.75
next layer loss target loss 25.715298 other loss 104074.09
result 1 [12.19  8.85  1.83] neuron -408.47302 0.39794308
e 30 loss -14.800558 target loss -1479.71 other loss -31459.566 tv loss 4079.314
next layer loss target loss 28.027798 other loss 105316.97
result 1 [12.06  8.97  1.82] neuron -398.15076 0.41285115
e 40 loss -14.830221 target loss -1478.8789 other loss -31729.2 tv loss 4108.1772
next layer loss target loss 28.554731 other loss 106040.57
result 1 [12.03  9.02  1.82] neuron -396.67282 0.41713256
e 50 loss -14.851637 target loss -1470.93 other loss -31615.281 tv loss 4125.782
next layer loss target loss 29.404112 other loss 106241.97
result 1 [11.99  9.    1.81] neuron -395.0888 0.4278562
e 60 loss -14.868055 target loss -1469.9268 other loss -31519.547 tv loss 4136.155
next layer loss target loss 29.789875 other loss 106300.55
result 1 [11.96  8.97  1.8 ] neuron -395.21216 0.4358197
e 70 loss -14.884612 target loss -1463.3109 other loss -31373.986 tv loss 4137.6377
next layer loss target loss 30.503256 other loss 106259.766
result 1 [11.91  8.95  1.78] neuron -393.753 0.4484651
e 80 loss -14.921936 target loss -1452.8771 other loss -31035.53 tv loss 4133.411
next layer loss target loss 31.656813 other loss 105974.55
result 1 [11.8   8.89  1.74] neuron -392.2226 0.46892303
e 90 loss -15.021435 target loss -1424.1401 other loss -30361.271 tv loss 4127.4185
next layer loss target loss 36.062164 other loss 105433.56
result 1 [11.44  8.57  1.64] neuron -387.43018 0.50959796
e 100 loss -15.205443 target loss -1370.412 other loss -29584.848 tv loss 4114.4473
next layer loss target loss 45.81779 other loss 105229.22
result 1 [10.84  8.15  1.53] neuron -373.1513 0.5596207
e 110 loss -15.50135 target loss -1279.7365 other loss -28924.648 tv loss 4073.8699
next layer loss target loss 64.67967 other loss 106091.23
result 1 [10.01  7.32  1.45] neuron -343.59628 0.6219948
e 120 loss -15.950534 target loss -1150.3364 other loss -28498.547 tv loss 4006.2632
next layer loss target loss 97.04817 other loss 108661.91
result 1 [8.88 6.23 1.36] neuron -298.65988 0.69659203
e 130 loss -16.43358 target loss -1025.689 other loss -28766.266 tv loss 3938.6118
next layer loss target loss 134.14185 other loss 112532.36
result 1 [8.36 5.16 1.3 ] neuron -252.56503 0.73256356
e 140 loss -16.797405 target loss -932.18115 other loss -29261.828 tv loss 3886.6863
next layer loss target loss 161.56895 other loss 115903.0
result 1 [8.07 4.75 1.24] neuron -216.46974 0.7587159
e 150 loss -17.092386 target loss -852.23474 other loss -29587.943 tv loss 3838.4358
next layer loss target loss 182.94377 other loss 118590.65
result 1 [8.03 4.71 1.24] neuron -186.68369 0.78477687
e 160 loss -17.357492 target loss -771.04944 other loss -29682.684 tv loss 3780.9773
next layer loss target loss 201.7914 other loss 120606.59
result 1 [7.89 4.54 1.29] neuron -160.26237 0.81278485
e 170 loss -17.618244 target loss -690.84045 other loss -29832.52 tv loss 3716.1604
next layer loss target loss 217.76244 other loss 122234.69
result 1 [7.78 4.14 1.45] neuron -138.11105 0.82834786
e 180 loss -17.899591 target loss -616.08826 other loss -30008.475 tv loss 3647.9927
next layer loss target loss 231.94452 other loss 123548.65
result 1 [7.71 3.73 1.69] neuron -120.76504 0.82830805
e 190 loss -18.17073 target loss -546.3068 other loss -30131.328 tv loss 3585.7297
next layer loss target loss 245.46872 other loss 124854.195
result 1 [7.64 3.26 1.97] neuron -106.85473 0.8234914
e 200 loss -18.451336 target loss -481.9156 other loss -30199.459 tv loss 3537.3032
next layer loss target loss 259.41434 other loss 126313.68
result 1 [7.71 2.95 2.25] neuron -94.73088 0.81153995
e 210 loss -18.774794 target loss -419.54077 other loss -30351.367 tv loss 3501.6323
next layer loss target loss 275.57068 other loss 128068.68
result 1 [7.88 2.77 2.52] neuron -84.056984 0.7837674
e 220 loss -17.760763 target loss -493.94852 other loss -34217.105 tv loss 3556.927
next layer loss target loss 252.07959 other loss 129901.37
result 1 [8.9  3.11 2.37] neuron -105.8004 0.73556
e 230 loss -17.564466 target loss -551.2152 other loss -34469.582 tv loss 3585.4492
next layer loss target loss 230.17172 other loss 130573.664
result 1 [8.76 2.84 1.82] neuron -118.278625 0.7119333
e 240 loss -17.01511 target loss -570.40967 other loss -34560.406 tv loss 3591.5742
next layer loss target loss 223.47565 other loss 130857.94
result 1 [8.72 2.82 1.65] neuron -122.11887 0.702993
e 250 loss -16.852097 target loss -575.70557 other loss -34557.95 tv loss 3593.3813
next layer loss target loss 221.92667 other loss 130935.69
result 1 [8.71 2.82 1.6 ] neuron -122.79923 0.6991573
e 260 loss -16.83968 target loss -576.0303 other loss -34512.598 tv loss 3593.6624
next layer loss target loss 222.1631 other loss 130927.266
result 1 [8.7  2.82 1.58] neuron -122.34281 0.69848007
e 270 loss -16.881237 target loss -574.5768 other loss -34451.426 tv loss 3593.409
next layer loss target loss 223.03564 other loss 130887.87
result 1 [8.68 2.82 1.57] neuron -121.48648 0.69890124
e 280 loss -16.941086 target loss -572.4999 other loss -34385.453 tv loss 3592.963
next layer loss target loss 224.13226 other loss 130838.375
result 1 [8.67 2.81 1.57] neuron -120.49324 0.69973785
e 290 loss -17.006361 target loss -570.2185 other loss -34318.83 tv loss 3592.453
next layer loss target loss 225.30208 other loss 130786.16
result 1 [8.65 2.81 1.56] neuron -119.457596 0.7007173
e 300 loss -17.07252 target loss -567.8816 other loss -34253.15 tv loss 3591.917
next layer loss target loss 226.49016 other loss 130733.97
result 1 [8.64 2.8  1.56] neuron -118.4135 0.70174426
e 310 loss -17.137915 target loss -565.5465 other loss -34189.234 tv loss 3591.361
next layer loss target loss 227.67732 other loss 130683.28
result 1 [8.62 2.8  1.56] neuron -117.37439 0.7027852
e 320 loss -17.202005 target loss -563.2378 other loss -34127.453 tv loss 3590.788
next layer loss target loss 228.8542 other loss 130634.66
result 1 [8.61 2.79 1.56] neuron -116.345795 0.703824
e 330 loss -17.264753 target loss -560.9624 other loss -34067.996 tv loss 3590.1833
next layer loss target loss 230.01556 other loss 130588.06
result 1 [8.6  2.79 1.55] neuron -115.33264 0.7048555
e 340 loss -17.326372 target loss -558.71814 other loss -34010.8 tv loss 3589.575
next layer loss target loss 231.16043 other loss 130543.695
result 1 [8.59 2.78 1.55] neuron -114.33078 0.705877
e 350 loss -17.387001 target loss -556.5028 other loss -33955.5 tv loss 3588.9658
next layer loss target loss 232.29575 other loss 130500.92
result 1 [8.57 2.78 1.55] neuron -113.34478 0.7068097
e 360 loss -17.44679 target loss -554.3137 other loss -33901.906 tv loss 3588.326
next layer loss target loss 233.42166 other loss 130459.484
result 1 [8.56 2.77 1.54] neuron -112.37124 0.70769864
e 370 loss -17.50588 target loss -552.1489 other loss -33849.953 tv loss 3587.6804
next layer loss target loss 234.53854 other loss 130419.53
result 1 [8.55 2.77 1.54] neuron -111.410194 0.7085838
e 380 loss -17.564438 target loss -550.0029 other loss -33799.543 tv loss 3587.0217
next layer loss target loss 235.6525 other loss 130381.125
result 1 [8.55 2.77 1.54] neuron -110.45532 0.7100406
e 390 loss -17.622646 target loss -547.8684 other loss -33750.5 tv loss 3586.3264
next layer loss target loss 236.7684 other loss 130343.81
result 1 [8.54 2.76 1.54] neuron -109.50581 0.7132326
e 400 loss -17.680368 target loss -545.7482 other loss -33702.906 tv loss 3585.601
next layer loss target loss 237.88387 other loss 130307.984
result 1 [8.53 2.76 1.53] neuron -108.56292 0.7164263
e 410 loss -17.737461 target loss -543.6537 other loss -33656.86 tv loss 3584.8408
next layer loss target loss 238.98752 other loss 130273.58
result 1 [8.52 2.76 1.53] neuron -107.63391 0.7196227
e 420 loss -17.793846 target loss -541.5742 other loss -33612.777 tv loss 3584.0361
next layer loss target loss 240.08278 other loss 130241.516
result 1 [8.51 2.76 1.53] neuron -106.71222 0.7228069
e 430 loss -17.849194 target loss -539.51855 other loss -33570.816 tv loss 3583.185
next layer loss target loss 241.1709 other loss 130211.73
result 1 [8.5  2.76 1.53] neuron -105.79945 0.7259676
e 440 loss -17.903133 target loss -537.497 other loss -33531.46 tv loss 3582.3083
next layer loss target loss 242.24515 other loss 130184.44
result 1 [8.5  2.76 1.52] neuron -104.90239 0.7291115
e 450 loss -17.955154 target loss -535.5228 other loss -33495.074 tv loss 3581.3887
next layer loss target loss 243.29343 other loss 130159.984
result 1 [8.49 2.76 1.52] neuron -104.0275 0.73222166
e 460 loss -18.004873 target loss -533.61206 other loss -33462.46 tv loss 3580.4316
next layer loss target loss 244.31049 other loss 130138.836
result 1 [8.49 2.75 1.52] neuron -103.182556 0.7352852
e 470 loss -18.052124 target loss -531.77576 other loss -33434.055 tv loss 3579.4385
next layer loss target loss 245.28793 other loss 130121.2
result 1 [8.48 2.75 1.52] neuron -102.370834 0.7382894
e 480 loss -18.096897 target loss -530.0202 other loss -33410.305 tv loss 3578.4072
next layer loss target loss 246.22318 other loss 130107.57
result 1 [8.48 2.75 1.51] neuron -101.594955 0.7412277
e 490 loss -18.139301 target loss -528.35156 other loss -33391.145 tv loss 3577.3682
next layer loss target loss 247.11472 other loss 130097.68
result 1 [8.48 2.75 1.51] neuron -100.86171 0.7440824
e 500 loss -18.179407 target loss -526.7678 other loss -33376.547 tv loss 3576.2803
next layer loss target loss 247.9618 other loss 130091.63
result 1 [8.47 2.75 1.51] neuron -100.17103 0.746851
e 510 loss -18.217625 target loss -525.2676 other loss -33366.367 tv loss 3575.1655
next layer loss target loss 248.76787 other loss 130089.266
result 1 [8.48 2.75 1.51] neuron -99.521164 0.7495406
e 520 loss -18.254066 target loss -523.8397 other loss -33360.42 tv loss 3573.997
next layer loss target loss 249.53773 other loss 130090.44
result 1 [8.48 2.75 1.5 ] neuron -98.909485 0.75202733
e 530 loss -18.288872 target loss -522.48596 other loss -33358.31 tv loss 3572.8198
next layer loss target loss 250.27167 other loss 130094.63
result 1 [8.48 2.75 1.5 ] neuron -98.33634 0.7544479
e 540 loss -18.322214 target loss -521.1918 other loss -33359.68 tv loss 3571.5923
next layer loss target loss 250.96979 other loss 130102.0
result 1 [8.49 2.76 1.5 ] neuron -97.79217 0.75681275
e 550 loss -18.35417 target loss -519.9603 other loss -33363.84 tv loss 3570.3657
next layer loss target loss 251.63445 other loss 130111.41
result 1 [8.5  2.76 1.5 ] neuron -97.28022 0.7591179
e 560 loss -18.385002 target loss -518.7639 other loss -33370.617 tv loss 3569.0867
next layer loss target loss 252.28415 other loss 130123.69
result 1 [8.5  2.76 1.49] neuron -96.789795 0.76139146
e 570 loss -18.41457 target loss -517.59546 other loss -33379.543 tv loss 3567.7432
next layer loss target loss 252.91049 other loss 130138.586
result 1 [8.51 2.77 1.49] neuron -96.319534 0.76363057
e 580 loss -18.44281 target loss -516.4556 other loss -33389.867 tv loss 3566.3762
next layer loss target loss 253.51224 other loss 130155.555
result 1 [8.52 2.77 1.49] neuron -95.87262 0.7658177
e 590 loss -18.469963 target loss -515.3291 other loss -33401.188 tv loss 3564.975
next layer loss target loss 254.09277 other loss 130174.42
result 1 [8.53 2.77 1.49] neuron -95.43887 0.76787823
e 600 loss -18.495924 target loss -514.21533 other loss -33413.11 tv loss 3563.5142
next layer loss target loss 254.65 other loss 130194.66
result 1 [8.54 2.78 1.49] neuron -95.01671 0.76981014
e 610 loss -18.52071 target loss -513.1031 other loss -33425.33 tv loss 3562.0146
next layer loss target loss 255.19498 other loss 130216.305
result 1 [8.55 2.78 1.48] neuron -94.60552 0.7717144
e 620 loss -18.544292 target loss -511.99435 other loss -33437.625 tv loss 3560.5005
next layer loss target loss 255.72415 other loss 130239.32
result 1 [8.55 2.78 1.48] neuron -94.20403 0.77359
e 630 loss -18.566698 target loss -510.88046 other loss -33449.703 tv loss 3558.9697
next layer loss target loss 256.24463 other loss 130263.7
result 1 [8.56 2.78 1.48] neuron -93.81329 0.77543694
e 640 loss -18.588097 target loss -509.75436 other loss -33461.4 tv loss 3557.373
next layer loss target loss 256.7572 other loss 130289.31
result 1 [8.57 2.78 1.48] neuron -93.42886 0.7772564
e 650 loss -18.608574 target loss -508.60968 other loss -33472.53 tv loss 3555.6997
next layer loss target loss 257.27097 other loss 130316.234
result 1 [8.58 2.78 1.47] neuron -93.04804 0.7790578
e 660 loss -18.628086 target loss -507.44235 other loss -33482.883 tv loss 3553.9675
next layer loss target loss 257.7809 other loss 130344.25
result 1 [8.59 2.78 1.47] neuron -92.66889 0.7808524
e 670 loss -18.646519 target loss -506.25787 other loss -33492.24 tv loss 3552.2058
next layer loss target loss 258.28305 other loss 130373.164
result 1 [8.6  2.78 1.47] neuron -92.293365 0.7826331
e 680 loss -18.664007 target loss -505.05197 other loss -33500.484 tv loss 3550.415
next layer loss target loss 258.78183 other loss 130403.23
result 1 [8.6  2.78 1.47] neuron -91.919685 0.7844028
e 690 loss -18.680689 target loss -503.8192 other loss -33507.344 tv loss 3548.5786
next layer loss target loss 259.27774 other loss 130434.086
result 1 [8.61 2.78 1.47] neuron -91.54443 0.78616875
e 700 loss -18.696615 target loss -502.55923 other loss -33512.87 tv loss 3546.6814
next layer loss target loss 259.77374 other loss 130465.69
result 1 [8.62 2.78 1.47] neuron -91.16478 0.7879382
e 710 loss -18.711798 target loss -501.2745 other loss -33517.164 tv loss 3544.7412
next layer loss target loss 260.2684 other loss 130498.25
result 1 [8.62 2.78 1.46] neuron -90.78305 0.7897106
e 720 loss -18.726336 target loss -499.96368 other loss -33520.32 tv loss 3542.79
next layer loss target loss 260.76413 other loss 130532.086
result 1 [8.63 2.79 1.46] neuron -90.40094 0.79148275
e 730 loss -18.740282 target loss -498.62683 other loss -33522.195 tv loss 3540.8354
next layer loss target loss 261.2619 other loss 130566.94
result 1 [8.64 2.79 1.46] neuron -90.01875 0.7932556
e 740 loss -18.75377 target loss -497.26334 other loss -33522.824 tv loss 3538.8496
next layer loss target loss 261.76633 other loss 130602.56
result 1 [8.64 2.79 1.46] neuron -89.63475 0.79503673
e 750 loss -18.76685 target loss -495.87546 other loss -33522.344 tv loss 3536.8198
next layer loss target loss 262.27682 other loss 130639.11
result 1 [8.65 2.79 1.46] neuron -89.25066 0.7968351
e 760 loss -18.77947 target loss -494.47034 other loss -33520.58 tv loss 3534.776
next layer loss target loss 262.78717 other loss 130676.03
result 1 [8.65 2.79 1.46] neuron -88.87083 0.79866284
e 770 loss -18.791721 target loss -493.04538 other loss -33517.355 tv loss 3532.724
next layer loss target loss 263.30396 other loss 130712.805
result 1 [8.65 2.79 1.46] neuron -88.49548 0.80054766
e 780 loss -18.80364 target loss -491.60382 other loss -33513.04 tv loss 3530.6829
next layer loss target loss 263.8229 other loss 130749.87
result 1 [8.66 2.79 1.46] neuron -88.12134 0.8024381
e 790 loss -18.815254 target loss -490.1477 other loss -33507.68 tv loss 3528.6753
next layer loss target loss 264.34314 other loss 130787.33
result 1 [8.66 2.79 1.46] neuron -87.75119 0.80431324
e 800 loss -18.826614 target loss -488.67584 other loss -33501.508 tv loss 3526.7122
next layer loss target loss 264.8603 other loss 130825.47
result 1 [8.66 2.79 1.46] neuron -87.38246 0.80617446
e 810 loss -18.837727 target loss -487.1941 other loss -33494.645 tv loss 3524.7876
next layer loss target loss 265.37213 other loss 130864.15
result 1 [8.66 2.79 1.46] neuron -87.01881 0.80802745
e 820 loss -18.848751 target loss -485.69843 other loss -33487.176 tv loss 3522.8662
next layer loss target loss 265.88324 other loss 130903.516
result 1 [8.66 2.79 1.46] neuron -86.65702 0.8098752
e 830 loss -18.859634 target loss -484.18973 other loss -33479.16 tv loss 3520.961
next layer loss target loss 266.39413 other loss 130943.47
result 1 [8.67 2.79 1.46] neuron -86.298676 0.81171733
e 840 loss -18.870428 target loss -482.66986 other loss -33470.625 tv loss 3519.0635
next layer loss target loss 266.90622 other loss 130983.516
result 1 [8.67 2.79 1.46] neuron -85.94411 0.81361765
e 850 loss -18.881584 target loss -481.1473 other loss -33461.883 tv loss 3517.1467
next layer loss target loss 267.4206 other loss 131023.98
result 1 [8.67 2.79 1.46] neuron -85.593 0.815576
e 860 loss -18.892702 target loss -479.61386 other loss -33453.082 tv loss 3515.1528
next layer loss target loss 267.93713 other loss 131064.98
result 1 [8.67 2.79 1.46] neuron -85.24211 0.8176065
e 870 loss -18.903795 target loss -478.07788 other loss -33444.113 tv loss 3513.153
next layer loss target loss 268.4573 other loss 131106.39
result 1 [8.67 2.79 1.46] neuron -84.89302 0.8197977
e 880 loss -18.914894 target loss -476.5324 other loss -33434.934 tv loss 3511.1504
next layer loss target loss 268.97873 other loss 131148.19
result 1 [8.67 2.79 1.46] neuron -84.543564 0.822007
e 890 loss -18.926098 target loss -474.9687 other loss -33425.668 tv loss 3509.1238
next layer loss target loss 269.50366 other loss 131190.67
result 1 [8.67 2.79 1.46] neuron -84.19289 0.824246
e 900 loss -18.937258 target loss -473.39566 other loss -33416.418 tv loss 3507.0793
next layer loss target loss 270.03296 other loss 131233.86
result 1 [8.68 2.8  1.46] neuron -83.84268 0.8265056
e 910 loss -18.948458 target loss -471.82394 other loss -33407.18 tv loss 3505.0352
next layer loss target loss 270.55942 other loss 131277.56
result 1 [8.68 2.8  1.46] neuron -83.49194 0.82878584
e 920 loss -18.959616 target loss -470.2492 other loss -33398.098 tv loss 3502.9922
next layer loss target loss 271.08652 other loss 131321.97
result 1 [8.68 2.8  1.46] neuron -83.14483 0.83108264
e 930 loss -18.97065 target loss -468.6774 other loss -33389.05 tv loss 3500.9595
next layer loss target loss 271.61218 other loss 131366.66
result 1 [8.68 2.8  1.46] neuron -82.80359 0.83337766
e 940 loss -18.981676 target loss -467.10175 other loss -33379.797 tv loss 3498.9365
next layer loss target loss 272.13907 other loss 131411.44
result 1 [8.68 2.8  1.46] neuron -82.46503 0.8356733
e 950 loss -18.992542 target loss -465.5297 other loss -33370.35 tv loss 3496.9294
next layer loss target loss 272.66498 other loss 131456.34
result 1 [8.68 2.8  1.46] neuron -82.13083 0.83790153
e 960 loss -19.003414 target loss -463.9622 other loss -33360.957 tv loss 3494.9243
next layer loss target loss 273.1902 other loss 131501.25
result 1 [8.68 2.8  1.46] neuron -81.8074 0.8396043
e 970 loss -19.014389 target loss -462.39038 other loss -33351.65 tv loss 3492.9268
next layer loss target loss 273.71884 other loss 131546.78
result 1 [8.68 2.8  1.46] neuron -81.48917 0.8414418
e 980 loss -19.025473 target loss -460.80536 other loss -33342.496 tv loss 3490.915
next layer loss target loss 274.25275 other loss 131593.28
result 1 [8.68 2.81 1.46] neuron -81.170456 0.8432991
e 990 loss -19.036592 target loss -459.2083 other loss -33333.473 tv loss 3488.9014
next layer loss target loss 274.7937 other loss 131640.69
result 1 [8.68 2.81 1.46] neuron -80.85217 0.845174
RE filter conv2d_2 104 RE acc 0.3333333333333333
e 0 loss -14.124797 target loss -1718.9917 other loss -28445.904 tv loss 3976.1335
next layer loss target loss 132.18582 other loss 99890.73
result 1 [12.2   8.22  1.93] neuron -607.8583 1.6482164
e 10 loss -14.322015 target loss -1700.3517 other loss -28480.777 tv loss 4047.991
next layer loss target loss 143.83281 other loss 101086.58
result 1 [12.11  8.41  1.91] neuron -601.51685 1.7475868
e 20 loss -14.482782 target loss -1689.0747 other loss -28782.375 tv loss 4115.55
next layer loss target loss 152.69263 other loss 102280.59
result 1 [12.08  8.51  1.86] neuron -600.2848 1.8236297
e 30 loss -14.605589 target loss -1678.922 other loss -28657.246 tv loss 4159.821
next layer loss target loss 161.43112 other loss 102816.05
result 1 [11.98  8.59  1.82] neuron -599.3508 1.895389
e 40 loss -14.708092 target loss -1668.8604 other loss -28318.658 tv loss 4187.9834
next layer loss target loss 169.73216 other loss 102985.664
result 1 [11.79  8.72  1.76] neuron -598.91144 1.9634272
e 50 loss -14.8481865 target loss -1649.5679 other loss -27573.969 tv loss 4173.971
next layer loss target loss 179.67305 other loss 102502.16
result 1 [11.42  8.76  1.64] neuron -597.8715 2.0249536
e 60 loss -15.0496645 target loss -1610.9834 other loss -26599.73 tv loss 4143.4336
next layer loss target loss 193.40744 other loss 101974.22
result 1 [10.76  8.64  1.49] neuron -590.66174 2.0759108
e 70 loss -15.230814 target loss -1567.3905 other loss -25967.578 tv loss 4121.9766
next layer loss target loss 207.75964 other loss 102268.984
result 1 [10.25  8.49  1.38] neuron -579.11945 2.130732
e 80 loss -15.375548 target loss -1537.2854 other loss -26040.271 tv loss 4133.6523
next layer loss target loss 219.10095 other loss 103303.766
result 1 [10.04  8.23  1.34] neuron -570.99084 2.193319
e 90 loss -15.497175 target loss -1519.0107 other loss -26332.373 tv loss 4162.323
next layer loss target loss 227.86237 other loss 104354.14
result 1 [9.94 8.04 1.3 ] neuron -566.20087 2.253373
e 100 loss -15.601298 target loss -1504.4475 other loss -26426.22 tv loss 4188.4463
next layer loss target loss 235.82246 other loss 105091.95
result 1 [9.87 7.91 1.29] neuron -561.8692 2.309309
e 110 loss -15.691278 target loss -1490.36 other loss -26409.512 tv loss 4210.482
next layer loss target loss 243.36055 other loss 105690.21
result 1 [9.79 7.8  1.28] neuron -557.3226 2.3617644
e 120 loss -15.770606 target loss -1477.731 other loss -26441.893 tv loss 4231.956
next layer loss target loss 250.45651 other loss 106290.94
result 1 [9.71 7.72 1.27] neuron -553.4691 2.411914
e 130 loss -15.841707 target loss -1465.4286 other loss -26501.18 tv loss 4252.256
next layer loss target loss 257.1371 other loss 106907.17
result 1 [9.64 7.65 1.26] neuron -549.8699 2.460249
e 140 loss -15.908606 target loss -1449.2878 other loss -26541.852 tv loss 4267.0
next layer loss target loss 263.99713 other loss 107616.94
result 1 [9.5  7.54 1.24] neuron -544.9432 2.5061736
e 150 loss -15.971463 target loss -1433.3822 other loss -26631.637 tv loss 4282.506
next layer loss target loss 270.46793 other loss 108365.766
result 1 [9.37 7.44 1.24] neuron -540.249 2.5506732
e 160 loss -16.033518 target loss -1418.3098 other loss -26785.824 tv loss 4299.1885
next layer loss target loss 276.52332 other loss 109167.24
result 1 [9.26 7.35 1.22] neuron -536.0147 2.5943482
e 170 loss -16.095852 target loss -1400.5092 other loss -26949.314 tv loss 4311.971
next layer loss target loss 282.7323 other loss 110067.13
result 1 [9.1  7.23 1.21] neuron -530.8281 2.6359377
e 180 loss -16.159311 target loss -1381.7308 other loss -27144.656 tv loss 4322.0117
next layer loss target loss 288.75815 other loss 111044.92
result 1 [8.93 7.08 1.2 ] neuron -525.33594 2.6765487
e 190 loss -16.223366 target loss -1361.4639 other loss -27367.512 tv loss 4330.2886
next layer loss target loss 294.89377 other loss 112126.43
result 1 [8.75 6.94 1.21] neuron -519.36847 2.7146368
e 200 loss -16.28222 target loss -1347.0873 other loss -27502.006 tv loss 4341.8364
next layer loss target loss 300.83902 other loss 112890.66
result 1 [8.63 6.84 1.21] neuron -515.37933 2.7568698
e 210 loss -16.336222 target loss -1337.3064 other loss -27612.486 tv loss 4356.887
next layer loss target loss 305.7597 other loss 113479.71
result 1 [8.58 6.75 1.21] neuron -512.7988 2.7992964
e 220 loss -16.387182 target loss -1324.3022 other loss -27765.09 tv loss 4367.6514
next layer loss target loss 310.44836 other loss 114243.695
result 1 [8.51 6.63 1.2 ] neuron -509.10788 2.8373117
e 230 loss -16.437061 target loss -1308.3651 other loss -27987.564 tv loss 4375.1323
next layer loss target loss 315.0117 other loss 115205.234
result 1 [8.42 6.48 1.2 ] neuron -504.56033 2.86648
e 240 loss -16.484577 target loss -1293.4624 other loss -28171.19 tv loss 4382.9673
next layer loss target loss 319.76743 other loss 116078.0
result 1 [8.36 6.36 1.2 ] neuron -500.36584 2.8935776
e 250 loss -16.530497 target loss -1279.8987 other loss -28370.91 tv loss 4390.5234
next layer loss target loss 323.97864 other loss 116933.21
result 1 [8.31 6.24 1.19] neuron -496.5626 2.9200575
e 260 loss -16.583511 target loss -1261.9048 other loss -28653.662 tv loss 4390.365
next layer loss target loss 327.95242 other loss 118074.57
result 1 [8.3  6.1  1.19] neuron -491.22363 2.9366176
e 270 loss -16.64259 target loss -1240.3827 other loss -29002.254 tv loss 4386.1504
next layer loss target loss 332.4925 other loss 119419.0
result 1 [8.3  5.96 1.2 ] neuron -484.95352 2.9402542
e 280 loss -16.701607 target loss -1222.2878 other loss -29323.268 tv loss 4385.628
next layer loss target loss 336.5301 other loss 120624.22
result 1 [8.32 5.84 1.2 ] neuron -479.8209 2.945238
e 290 loss -16.756636 target loss -1207.2388 other loss -29506.32 tv loss 4388.4062
next layer loss target loss 341.2207 other loss 121522.086
result 1 [8.32 5.76 1.2 ] neuron -475.68234 2.9578226
e 300 loss -16.80751 target loss -1198.3306 other loss -29616.678 tv loss 4398.4224
next layer loss target loss 345.49884 other loss 122092.734
result 1 [8.34 5.72 1.19] neuron -473.46133 2.976221
e 310 loss -16.854942 target loss -1189.8853 other loss -29735.078 tv loss 4406.2124
next layer loss target loss 349.41986 other loss 122657.55
result 1 [8.37 5.69 1.18] neuron -471.12347 2.9894698
e 320 loss -16.90651 target loss -1176.9025 other loss -29967.615 tv loss 4407.116
next layer loss target loss 353.1186 other loss 123531.33
result 1 [8.39 5.65 1.18] neuron -467.18823 2.99617
e 330 loss -16.970272 target loss -1157.2727 other loss -30336.615 tv loss 4398.2363
next layer loss target loss 356.65445 other loss 124827.34
result 1 [8.38 5.61 1.21] neuron -460.9334 2.9961536
e 340 loss -17.035316 target loss -1137.1921 other loss -30726.902 tv loss 4388.4272
next layer loss target loss 359.67224 other loss 126172.484
result 1 [8.35 5.59 1.26] neuron -454.50934 2.995245
e 350 loss -17.101795 target loss -1118.9805 other loss -31067.762 tv loss 4380.563
next layer loss target loss 362.16687 other loss 127391.16
result 1 [8.31 5.58 1.31] neuron -448.58395 2.9938293
e 360 loss -17.159634 target loss -1104.0568 other loss -31383.54 tv loss 4376.2764
next layer loss target loss 365.05066 other loss 128416.41
result 1 [8.3  5.57 1.39] neuron -444.0382 2.996832
e 370 loss -17.206043 target loss -1094.9323 other loss -31515.006 tv loss 4379.1787
next layer loss target loss 368.1627 other loss 129021.484
result 1 [8.29 5.56 1.41] neuron -441.10583 3.0044556
e 380 loss -17.249846 target loss -1090.0918 other loss -31571.809 tv loss 4388.811
next layer loss target loss 370.98956 other loss 129375.17
result 1 [8.29 5.55 1.4 ] neuron -439.5741 3.015505
e 390 loss -17.29163 target loss -1086.3777 other loss -31594.16 tv loss 4399.442
next layer loss target loss 374.0044 other loss 129639.64
result 1 [8.3  5.55 1.38] neuron -438.42838 3.0279305
e 400 loss -17.331331 target loss -1082.7466 other loss -31656.537 tv loss 4409.6777
next layer loss target loss 377.06958 other loss 129923.47
result 1 [8.32 5.54 1.38] neuron -437.4538 3.040544
e 410 loss -17.368244 target loss -1078.0046 other loss -31732.11 tv loss 4417.067
next layer loss target loss 379.79846 other loss 130279.25
result 1 [8.32 5.52 1.37] neuron -436.02716 3.0503068
e 420 loss -17.4043 target loss -1071.6946 other loss -31830.305 tv loss 4421.6016
next layer loss target loss 382.57794 other loss 130717.59
result 1 [8.31 5.51 1.38] neuron -434.125 3.0587366
e 430 loss -17.441954 target loss -1064.2865 other loss -31975.525 tv loss 4422.497
next layer loss target loss 384.88065 other loss 131263.6
result 1 [8.3  5.5  1.38] neuron -431.8899 3.0623858
e 440 loss -17.487183 target loss -1053.5627 other loss -32194.375 tv loss 4416.9
next layer loss target loss 387.05795 other loss 132011.95
result 1 [8.28 5.5  1.4 ] neuron -428.68506 3.0624566
e 450 loss -17.547585 target loss -1039.7891 other loss -32530.021 tv loss 4407.9287
next layer loss target loss 389.08005 other loss 133003.72
result 1 [8.24 5.5  1.44] neuron -424.7111 3.0577745
e 460 loss -17.61765 target loss -1022.2862 other loss -32869.332 tv loss 4394.3164
next layer loss target loss 392.0718 other loss 134159.9
result 1 [8.16 5.5  1.51] neuron -419.4655 3.0503778
e 470 loss -17.684525 target loss -1006.3435 other loss -33204.957 tv loss 4383.7124
next layer loss target loss 395.33438 other loss 135214.06
result 1 [8.1  5.49 1.57] neuron -414.94678 3.0459585
e 480 loss -17.752943 target loss -991.63385 other loss -33495.04 tv loss 4375.7085
next layer loss target loss 398.89227 other loss 136193.67
result 1 [8.06 5.48 1.63] neuron -410.7461 3.0435152
e 490 loss -17.826178 target loss -977.55725 other loss -33822.92 tv loss 4368.2734
next layer loss target loss 403.16437 other loss 137131.84
result 1 [8.03 5.46 1.72] neuron -407.26334 3.0444338
e 500 loss -17.893354 target loss -964.24225 other loss -34119.6 tv loss 4358.52
next layer loss target loss 407.18866 other loss 138046.12
result 1 [8.   5.44 1.8 ] neuron -404.1646 3.0431883
e 510 loss -17.954521 target loss -953.0371 other loss -34381.43 tv loss 4350.9326
next layer loss target loss 411.42834 other loss 138825.53
result 1 [8.   5.41 1.88] neuron -401.887 3.0454323
e 520 loss -18.003357 target loss -944.519 other loss -34616.566 tv loss 4346.1562
next layer loss target loss 414.97702 other loss 139458.22
result 1 [8.02 5.39 1.93] neuron -400.61285 3.0502152
e 530 loss -18.045084 target loss -937.1907 other loss -34774.023 tv loss 4342.0806
next layer loss target loss 418.3278 other loss 139965.17
result 1 [8.02 5.36 1.99] neuron -399.52905 3.056571
e 540 loss -18.08319 target loss -931.8671 other loss -34913.582 tv loss 4343.7363
next layer loss target loss 421.66614 other loss 140334.08
result 1 [8.03 5.32 2.04] neuron -399.06088 3.0639992
e 550 loss -18.120111 target loss -926.46466 other loss -35016.953 tv loss 4345.3774
next layer loss target loss 424.5713 other loss 140704.88
result 1 [8.03 5.3  2.07] neuron -398.36963 3.0680993
e 560 loss -18.156042 target loss -920.6863 other loss -35092.938 tv loss 4343.9404
next layer loss target loss 427.00714 other loss 141111.6
result 1 [8.03 5.28 2.08] neuron -397.35434 3.0697827
e 570 loss -18.190939 target loss -916.5121 other loss -35175.992 tv loss 4347.785
next layer loss target loss 429.64722 other loss 141418.88
result 1 [8.02 5.26 2.09] neuron -396.9002 3.0739274
e 580 loss -18.225285 target loss -912.4644 other loss -35235.3 tv loss 4351.743
next layer loss target loss 432.39893 other loss 141700.89
result 1 [8.02 5.24 2.09] neuron -396.3558 3.078434
e 590 loss -18.25825 target loss -909.453 other loss -35287.707 tv loss 4354.528
next layer loss target loss 434.34808 other loss 141964.48
result 1 [8.01 5.22 2.08] neuron -395.96005 3.0811095
e 600 loss -18.290615 target loss -906.7821 other loss -35325.316 tv loss 4359.6943
next layer loss target loss 436.5495 other loss 142181.78
result 1 [8.01 5.19 2.07] neuron -395.5942 3.085409
e 610 loss -18.321974 target loss -904.1269 other loss -35351.008 tv loss 4365.403
next layer loss target loss 438.7763 other loss 142383.55
result 1 [7.99 5.16 2.06] neuron -395.17523 3.09055
e 620 loss -18.35268 target loss -901.3004 other loss -35377.715 tv loss 4368.515
next layer loss target loss 440.70178 other loss 142611.73
result 1 [7.99 5.15 2.05] neuron -394.71393 3.0942187
e 630 loss -18.383059 target loss -898.73883 other loss -35435.05 tv loss 4372.9536
next layer loss target loss 442.77432 other loss 142834.17
result 1 [7.98 5.12 2.05] neuron -394.56787 3.0968895
e 640 loss -18.413725 target loss -895.30084 other loss -35488.293 tv loss 4376.3174
next layer loss target loss 445.09644 other loss 143085.86
result 1 [7.98 5.1  2.05] neuron -394.2176 3.099386
e 650 loss -18.443249 target loss -892.08044 other loss -35541.594 tv loss 4377.127
next layer loss target loss 446.81406 other loss 143349.8
result 1 [7.98 5.08 2.04] neuron -393.9086 3.100367
e 660 loss -18.460638 target loss -889.84454 other loss -35547.11 tv loss 4378.593
next layer loss target loss 448.23718 other loss 143473.4
result 1 [7.97 5.07 2.03] neuron -393.6018 3.1009645
e 670 loss -18.477621 target loss -888.3933 other loss -35569.22 tv loss 4380.224
next layer loss target loss 449.09747 other loss 143595.28
result 1 [7.97 5.06 2.02] neuron -393.53735 3.1006835
e 680 loss -18.494331 target loss -886.4252 other loss -35563.58 tv loss 4378.8623
next layer loss target loss 449.80096 other loss 143734.72
result 1 [7.96 5.06 2.01] neuron -393.1639 3.0993276
e 690 loss -18.5121 target loss -884.4983 other loss -35583.45 tv loss 4378.3213
next layer loss target loss 450.5749 other loss 143883.94
result 1 [7.95 5.06 1.99] neuron -393.00247 3.0980995
e 700 loss -18.53048 target loss -882.2189 other loss -35619.453 tv loss 4378.498
next layer loss target loss 451.70624 other loss 144042.88
result 1 [7.95 5.06 1.99] neuron -392.92966 3.0974653
e 710 loss -18.548998 target loss -879.76953 other loss -35662.656 tv loss 4378.1616
next layer loss target loss 452.86288 other loss 144217.7
result 1 [7.94 5.05 1.99] neuron -392.87473 3.0967796
e 720 loss -18.567186 target loss -877.308 other loss -35698.81 tv loss 4377.4746
next layer loss target loss 453.87958 other loss 144398.0
result 1 [7.93 5.05 1.99] neuron -392.75803 3.0957053
e 730 loss -18.584255 target loss -875.0316 other loss -35716.363 tv loss 4376.926
next layer loss target loss 454.78308 other loss 144564.98
result 1 [7.92 5.05 1.97] neuron -392.54333 3.0943084
e 740 loss -18.601086 target loss -872.81213 other loss -35729.89 tv loss 4377.093
next layer loss target loss 455.7648 other loss 144721.97
result 1 [7.91 5.05 1.96] neuron -392.3159 3.0934517
e 750 loss -18.61746 target loss -871.13916 other loss -35759.895 tv loss 4379.168
next layer loss target loss 456.83047 other loss 144855.42
result 1 [7.9  5.04 1.95] neuron -392.31857 3.0932014
e 760 loss -18.633879 target loss -868.7506 other loss -35780.418 tv loss 4379.306
next layer loss target loss 457.93515 other loss 145018.58
result 1 [7.89 5.04 1.94] neuron -392.11047 3.0925496
e 770 loss -18.650536 target loss -866.165 other loss -35817.953 tv loss 4379.76
next layer loss target loss 459.25403 other loss 145192.6
result 1 [7.88 5.03 1.94] neuron -391.975 3.0921757
e 780 loss -18.666336 target loss -863.91516 other loss -35853.223 tv loss 4379.218
next layer loss target loss 460.2011 other loss 145368.94
result 1 [7.87 5.03 1.94] neuron -391.89883 3.0911715
e 790 loss -18.676447 target loss -862.5367 other loss -35874.11 tv loss 4377.5444
next layer loss target loss 460.5734 other loss 145501.1
result 1 [7.87 5.03 1.93] neuron -391.82983 3.0901985
e 800 loss -18.685232 target loss -861.6768 other loss -35901.58 tv loss 4381.0005
next layer loss target loss 461.77032 other loss 145564.42
result 1 [7.87 5.01 1.94] neuron -391.87613 3.0916014
e 810 loss -18.693893 target loss -860.4679 other loss -35907.367 tv loss 4381.2305
next layer loss target loss 462.20218 other loss 145673.34
result 1 [7.86 5.01 1.93] neuron -391.70563 3.0914848
e 820 loss -18.70255 target loss -859.63824 other loss -35922.082 tv loss 4383.4604
next layer loss target loss 463.04504 other loss 145743.97
result 1 [7.86 5.   1.93] neuron -391.68283 3.0921314
e 830 loss -18.711329 target loss -858.50354 other loss -35935.01 tv loss 4384.8066
next layer loss target loss 463.76807 other loss 145838.66
result 1 [7.85 4.99 1.93] neuron -391.58542 3.0925374
e 840 loss -18.721207 target loss -856.88806 other loss -35949.434 tv loss 4383.63
next layer loss target loss 464.3006 other loss 145969.95
result 1 [7.85 5.   1.93] neuron -391.43143 3.0920992
e 850 loss -18.73435 target loss -854.2552 other loss -35987.117 tv loss 4377.9365
next layer loss target loss 464.70132 other loss 146178.61
result 1 [7.86 5.02 1.93] neuron -391.30423 3.0903258
e 860 loss -18.748508 target loss -851.34875 other loss -36058.633 tv loss 4374.2803
next layer loss target loss 465.72882 other loss 146384.2
result 1 [7.87 5.03 1.95] neuron -391.3447 3.089286
e 870 loss -18.758005 target loss -848.56494 other loss -36139.17 tv loss 4367.3584
next layer loss target loss 466.2415 other loss 146590.64
result 1 [7.9  5.04 1.97] neuron -391.46667 3.0855854
e 880 loss -18.764965 target loss -846.8666 other loss -36199.945 tv loss 4361.6987
next layer loss target loss 466.472 other loss 146733.83
result 1 [7.92 5.06 1.97] neuron -391.67474 3.0808234
e 890 loss -18.771349 target loss -845.0491 other loss -36226.754 tv loss 4359.167
next layer loss target loss 467.0912 other loss 146843.03
result 1 [7.91 5.06 1.98] neuron -391.59396 3.0784407
e 900 loss -18.777517 target loss -843.7595 other loss -36250.52 tv loss 4357.9727
next layer loss target loss 467.34222 other loss 146943.23
result 1 [7.91 5.07 1.98] neuron -391.6034 3.0756962
e 910 loss -18.7838 target loss -842.6789 other loss -36273.188 tv loss 4357.6846
next layer loss target loss 467.57727 other loss 147035.78
result 1 [7.91 5.08 1.97] neuron -391.62943 3.0731106
e 920 loss -18.790306 target loss -841.50146 other loss -36293.137 tv loss 4358.6953
next layer loss target loss 468.0409 other loss 147124.5
result 1 [7.9  5.08 1.97] neuron -391.5954 3.0714786
e 930 loss -18.79723 target loss -840.236 other loss -36313.27 tv loss 4358.9023
next layer loss target loss 468.3979 other loss 147224.6
result 1 [7.89 5.09 1.97] neuron -391.5514 3.0690002
e 940 loss -18.804237 target loss -838.54004 other loss -36322.383 tv loss 4358.8335
next layer loss target loss 469.00806 other loss 147328.94
result 1 [7.88 5.09 1.97] neuron -391.3324 3.0666773
e 950 loss -18.811413 target loss -837.3042 other loss -36345.008 tv loss 4358.0005
next layer loss target loss 469.361 other loss 147431.03
result 1 [7.87 5.1  1.97] neuron -391.33014 3.0633383
e 960 loss -18.818502 target loss -835.88055 other loss -36361.906 tv loss 4357.445
next layer loss target loss 469.91632 other loss 147527.98
result 1 [7.86 5.1  1.97] neuron -391.24573 3.0607138
e 970 loss -18.825397 target loss -834.6007 other loss -36373.125 tv loss 4357.856
next layer loss target loss 470.36908 other loss 147624.36
result 1 [7.84 5.11 1.96] neuron -391.13727 3.0582354
e 980 loss -18.832348 target loss -833.5079 other loss -36378.96 tv loss 4358.7163
next layer loss target loss 470.83368 other loss 147705.0
result 1 [7.83 5.11 1.96] neuron -391.0373 3.0559113
e 990 loss -18.83946 target loss -832.52924 other loss -36390.848 tv loss 4359.4893
next layer loss target loss 471.11884 other loss 147794.92
result 1 [7.81 5.12 1.95] neuron -391.00125 3.0529788
RE filter conv2d_2 157 RE acc 0.3333333333333333
e 0 loss -21.998734 target loss -1105.2922 other loss -29059.604 tv loss 3976.1335
next layer loss target loss 305.87234 other loss 99717.04
result 1 [12.2   8.22  1.93] neuron -194.64705 2.225985
e 10 loss -23.426878 target loss -893.6188 other loss -31751.531 tv loss 3979.0752
next layer loss target loss 346.4219 other loss 102260.34
result 1 [12.38  8.66  1.88] neuron -115.37055 2.2368197
e 20 loss -24.366367 target loss -807.69617 other loss -33701.63 tv loss 4015.2227
next layer loss target loss 371.58353 other loss 104888.74
result 1 [12.1   8.89  1.81] neuron -79.47325 2.2676396
e 30 loss -25.043234 target loss -714.03094 other loss -35918.742 tv loss 4039.6738
next layer loss target loss 402.35507 other loss 107596.3
result 1 [11.79  8.97  1.73] neuron -37.978848 2.3179946
e 40 loss -25.69909 target loss -598.6432 other loss -37967.4 tv loss 4073.823
next layer loss target loss 445.7912 other loss 110283.67
result 1 [11.62  8.98  1.71] neuron 8.720101 2.400327
e 50 loss -26.483614 target loss -470.6715 other loss -39825.133 tv loss 4093.6382
next layer loss target loss 499.43918 other loss 113065.055
result 1 [11.29  8.84  1.74] neuron 60.391327 2.4731846
e 60 loss -27.511835 target loss -328.22305 other loss -41532.734 tv loss 4078.5845
next layer loss target loss 566.7634 other loss 116063.945
result 1 [10.93  7.93  1.73] neuron 117.211845 2.5429506
e 70 loss -28.792154 target loss -175.2507 other loss -42944.625 tv loss 4009.78
next layer loss target loss 647.6213 other loss 119297.7
result 1 [10.61  6.75  1.78] neuron 176.07549 2.5986643
e 80 loss -29.991236 target loss -39.939667 other loss -43896.7 tv loss 3910.1592
next layer loss target loss 715.97766 other loss 122154.62
result 1 [10.05  6.06  1.88] neuron 227.07452 2.6115775
e 90 loss -30.961918 target loss 74.200226 other loss -44649.215 tv loss 3813.6792
next layer loss target loss 771.57916 other loss 124693.72
result 1 [9.7  5.46 2.03] neuron 269.46527 2.6039252
e 100 loss -31.647465 target loss 162.19809 other loss -45216.734 tv loss 3728.6926
next layer loss target loss 812.4187 other loss 126764.21
result 1 [9.61 5.14 2.12] neuron 300.51035 2.5895307
e 110 loss -32.1211 target loss 224.44836 other loss -45636.715 tv loss 3671.2046
next layer loss target loss 841.5421 other loss 128367.59
result 1 [9.52 5.02 2.19] neuron 323.002 2.5759919
e 120 loss -32.5112 target loss 270.95508 other loss -45957.19 tv loss 3631.665
next layer loss target loss 863.4459 other loss 129684.42
result 1 [9.46 4.89 2.2 ] neuron 339.135 2.5621972
e 130 loss -32.8387 target loss 308.92804 other loss -46209.28 tv loss 3599.6987
next layer loss target loss 881.4157 other loss 130798.21
result 1 [9.4  4.82 2.21] neuron 351.966 2.5505197
e 140 loss -33.127945 target loss 341.9648 other loss -46415.52 tv loss 3569.1929
next layer loss target loss 896.6355 other loss 131758.55
result 1 [9.3  4.8  2.22] neuron 362.29352 2.5242617
e 150 loss -33.409077 target loss 374.5168 other loss -46616.016 tv loss 3538.576
next layer loss target loss 911.1409 other loss 132697.03
result 1 [9.23 4.79 2.25] neuron 371.12482 2.5033584
e 160 loss -33.67338 target loss 406.48135 other loss -46812.5 tv loss 3511.9282
next layer loss target loss 924.4464 other loss 133640.11
result 1 [9.22 4.82 2.31] neuron 378.36325 2.4886787
e 170 loss -33.92248 target loss 437.82257 other loss -47023.004 tv loss 3489.0564
next layer loss target loss 936.9428 other loss 134593.47
result 1 [9.23 4.88 2.39] neuron 384.23044 2.4691277
e 180 loss -20001.947 target loss 469.54532 other loss -47242.69 tv loss 3466.6538
next layer loss target loss 949.04834 other loss 135589.1
result 1 [9.27 4.97 2.47] neuron 388.9839 2.4505978
e 190 loss -30.909313 target loss 254.29216 other loss -39564.383 tv loss 3552.032
next layer loss target loss 825.1875 other loss 130221.52
result 1 [8.29 3.22 1.78] neuron 323.1316 2.4676573
e 200 loss -31.184647 target loss 221.72331 other loss -41628.72 tv loss 3578.1328
next layer loss target loss 821.5577 other loss 128752.7
result 1 [8.4  3.75 1.51] neuron 319.57452 2.4962347
e 210 loss -30.915041 target loss 226.47783 other loss -43474.71 tv loss 3585.0713
next layer loss target loss 832.7804 other loss 128627.47
result 1 [8.6  4.4  1.42] neuron 324.80548 2.5290382
e 220 loss -30.813763 target loss 230.68958 other loss -44175.18 tv loss 3585.9565
next layer loss target loss 838.18805 other loss 128698.305
result 1 [8.69 4.68 1.39] neuron 327.58984 2.552543
e 230 loss -30.825115 target loss 234.28891 other loss -44451.79 tv loss 3585.6455
next layer loss target loss 841.28766 other loss 128799.45
result 1 [8.72 4.78 1.38] neuron 329.37897 2.5598762
e 240 loss -30.881285 target loss 237.64337 other loss -44575.34 tv loss 3584.878
next layer loss target loss 843.5475 other loss 128906.37
result 1 [8.74 4.8  1.38] neuron 330.79846 2.5614254
e 250 loss -30.955036 target loss 240.93347 other loss -44643.906 tv loss 3583.934
next layer loss target loss 845.5197 other loss 129016.164
result 1 [8.75 4.81 1.37] neuron 332.09418 2.5604742
e 260 loss -31.03643 target loss 244.23526 other loss -44692.766 tv loss 3582.9314
next layer loss target loss 847.4118 other loss 129128.78
result 1 [8.76 4.8  1.37] neuron 333.3589 2.5587497
e 270 loss -31.1219 target loss 247.57797 other loss -44734.438 tv loss 3581.9116
next layer loss target loss 849.2988 other loss 129244.22
result 1 [8.77 4.79 1.37] neuron 334.6286 2.55683
e 280 loss -31.210007 target loss 250.9638 other loss -44773.523 tv loss 3580.8838
next layer loss target loss 851.19934 other loss 129362.375
result 1 [8.78 4.78 1.37] neuron 335.91016 2.554771
e 290 loss -31.300072 target loss 254.38147 other loss -44811.582 tv loss 3579.8516
next layer loss target loss 853.11694 other loss 129482.89
result 1 [8.78 4.77 1.37] neuron 337.2016 2.5526438
e 300 loss -31.391785 target loss 257.83575 other loss -44849.246 tv loss 3578.819
next layer loss target loss 855.04865 other loss 129605.36
result 1 [8.79 4.76 1.37] neuron 338.50122 2.5505705
e 310 loss -31.48545 target loss 261.34506 other loss -44886.79 tv loss 3577.7947
next layer loss target loss 857.01575 other loss 129730.695
result 1 [8.8  4.75 1.37] neuron 339.81592 2.5485792
e 320 loss -31.580969 target loss 264.90424 other loss -44924.293 tv loss 3576.7632
next layer loss target loss 859.017 other loss 129858.88
result 1 [8.8  4.73 1.37] neuron 341.14584 2.5465474
e 330 loss -31.678383 target loss 268.5044 other loss -44961.297 tv loss 3575.7065
next layer loss target loss 861.0407 other loss 129989.484
result 1 [8.81 4.72 1.37] neuron 342.4911 2.544627
e 340 loss -31.777649 target loss 272.15115 other loss -44998.125 tv loss 3574.627
next layer loss target loss 863.10236 other loss 130122.99
result 1 [8.82 4.7  1.37] neuron 343.85507 2.5431032
e 350 loss -31.878819 target loss 275.85846 other loss -45035.11 tv loss 3573.539
next layer loss target loss 865.20844 other loss 130259.89
result 1 [8.82 4.69 1.36] neuron 345.24374 2.5416403
e 360 loss -31.981905 target loss 279.62903 other loss -45072.11 tv loss 3572.4443
next layer loss target loss 867.35767 other loss 130400.05
result 1 [8.83 4.68 1.36] neuron 346.65634 2.5403368
e 370 loss -32.086197 target loss 283.4522 other loss -45109.01 tv loss 3571.2808
next layer loss target loss 869.5321 other loss 130542.91
result 1 [8.84 4.67 1.36] neuron 348.0868 2.5397496
e 380 loss -32.191265 target loss 287.30933 other loss -45145.734 tv loss 3570.0312
next layer loss target loss 871.7191 other loss 130687.695
result 1 [8.85 4.65 1.36] neuron 349.5294 2.5391374
e 390 loss -32.296856 target loss 291.1839 other loss -45182.35 tv loss 3568.7722
next layer loss target loss 873.9145 other loss 130834.31
result 1 [8.86 4.64 1.36] neuron 350.97955 2.5385249
e 400 loss -32.40292 target loss 295.09195 other loss -45219.176 tv loss 3567.4878
next layer loss target loss 876.1289 other loss 130983.266
result 1 [8.88 4.63 1.36] neuron 352.4418 2.5379047
e 410 loss -32.509464 target loss 299.02478 other loss -45255.938 tv loss 3566.182
next layer loss target loss 878.3656 other loss 131134.47
result 1 [8.89 4.61 1.36] neuron 353.9115 2.5372803
e 420 loss -32.616142 target loss 302.97726 other loss -45292.53 tv loss 3564.8394
next layer loss target loss 880.6216 other loss 131287.48
result 1 [8.9  4.6  1.36] neuron 355.3904 2.5366526
e 430 loss -32.72264 target loss 306.94485 other loss -45328.64 tv loss 3563.4233
next layer loss target loss 882.89325 other loss 131441.97
result 1 [8.91 4.59 1.36] neuron 356.87653 2.5360067
e 440 loss -32.828785 target loss 310.92676 other loss -45364.07 tv loss 3561.999
next layer loss target loss 885.1743 other loss 131598.45
result 1 [8.93 4.57 1.36] neuron 358.36307 2.5353522
e 450 loss -32.93416 target loss 314.91852 other loss -45399.062 tv loss 3560.563
next layer loss target loss 887.4727 other loss 131756.6
result 1 [8.94 4.56 1.36] neuron 359.84885 2.534704
e 460 loss -33.038 target loss 318.8994 other loss -45433.344 tv loss 3559.1274
next layer loss target loss 889.7678 other loss 131915.73
result 1 [8.96 4.54 1.35] neuron 361.3283 2.5340474
e 470 loss -33.14019 target loss 322.87683 other loss -45467.008 tv loss 3557.7148
next layer loss target loss 892.0723 other loss 132076.02
result 1 [8.98 4.53 1.35] neuron 362.8057 2.533388
e 480 loss -33.24007 target loss 326.84933 other loss -45500.465 tv loss 3556.3123
next layer loss target loss 894.3805 other loss 132237.25
result 1 [9.   4.51 1.35] neuron 364.2785 2.5327234
e 490 loss -33.33698 target loss 330.80313 other loss -45533.688 tv loss 3554.9287
next layer loss target loss 896.6824 other loss 132399.11
result 1 [9.02 4.5  1.35] neuron 365.7398 2.5321615
e 500 loss -33.430183 target loss 334.72656 other loss -45567.008 tv loss 3553.5513
next layer loss target loss 898.9749 other loss 132560.94
result 1 [9.04 4.48 1.35] neuron 367.182 2.5320218
e 510 loss -33.51899 target loss 338.62164 other loss -45601.324 tv loss 3552.1853
next layer loss target loss 901.2681 other loss 132722.77
result 1 [9.06 4.47 1.35] neuron 368.606 2.5319712
e 520 loss -33.602688 target loss 342.4877 other loss -45637.305 tv loss 3550.8066
next layer loss target loss 903.5504 other loss 132884.25
result 1 [9.08 4.46 1.34] neuron 370.01196 2.5320268
e 530 loss -33.68058 target loss 346.31427 other loss -45675.656 tv loss 3549.4045
next layer loss target loss 905.8077 other loss 133044.62
result 1 [9.1  4.45 1.34] neuron 371.39728 2.5323157
e 540 loss -33.75194 target loss 350.07285 other loss -45717.08 tv loss 3547.9678
next layer loss target loss 908.023 other loss 133202.61
result 1 [9.11 4.44 1.34] neuron 372.74792 2.5325992
e 550 loss -33.81668 target loss 353.7539 other loss -45762.29 tv loss 3546.5078
next layer loss target loss 910.19403 other loss 133357.22
result 1 [9.13 4.44 1.34] neuron 374.0628 2.5328758
e 560 loss -33.87524 target loss 357.3454 other loss -45811.48 tv loss 3545.0273
next layer loss target loss 912.32404 other loss 133507.66
result 1 [9.15 4.43 1.34] neuron 375.3385 2.5331318
e 570 loss -33.92804 target loss 360.85922 other loss -45864.36 tv loss 3543.518
next layer loss target loss 914.4145 other loss 133654.27
result 1 [9.17 4.43 1.33] neuron 376.57214 2.5333543
e 580 loss -33.975224 target loss 364.2671 other loss -45920.156 tv loss 3541.9946
next layer loss target loss 916.438 other loss 133796.02
result 1 [9.19 4.43 1.33] neuron 377.75244 2.5335572
e 590 loss -34.01705 target loss 367.54123 other loss -45978.12 tv loss 3540.5198
next layer loss target loss 918.38086 other loss 133932.16
result 1 [9.2  4.43 1.33] neuron 378.87137 2.5337563
e 600 loss -34.054188 target loss 370.68774 other loss -46037.688 tv loss 3539.062
next layer loss target loss 920.24445 other loss 134062.61
result 1 [9.22 4.43 1.33] neuron 379.9275 2.5339506
e 610 loss -34.087097 target loss 373.69824 other loss -46098.188 tv loss 3537.6665
next layer loss target loss 922.0192 other loss 134187.1
result 1 [9.23 4.44 1.33] neuron 380.91772 2.5341482
e 620 loss -34.116596 target loss 376.588 other loss -46159.0 tv loss 3536.3066
next layer loss target loss 923.7193 other loss 134306.47
result 1 [9.25 4.44 1.33] neuron 381.8484 2.5343466
e 630 loss -34.143097 target loss 379.35486 other loss -46219.734 tv loss 3534.9958
next layer loss target loss 925.33673 other loss 134421.05
result 1 [9.26 4.44 1.32] neuron 382.71808 2.534568
e 640 loss -34.16703 target loss 381.99683 other loss -46279.62 tv loss 3533.7236
next layer loss target loss 926.86865 other loss 134530.66
result 1 [9.27 4.45 1.32] neuron 383.52637 2.5348225
e 650 loss -34.188866 target loss 384.5157 other loss -46337.89 tv loss 3532.481
next layer loss target loss 928.31915 other loss 134635.4
result 1 [9.29 4.45 1.32] neuron 384.27496 2.535081
e 660 loss -34.208965 target loss 386.91907 other loss -46394.227 tv loss 3531.2754
next layer loss target loss 929.69073 other loss 134735.89
result 1 [9.3  4.46 1.32] neuron 384.96588 2.535345
e 670 loss -34.227642 target loss 389.21484 other loss -46448.445 tv loss 3530.1062
next layer loss target loss 930.985 other loss 134832.39
result 1 [9.31 4.46 1.32] neuron 385.60004 2.5350811
e 680 loss -34.24508 target loss 391.40735 other loss -46500.43 tv loss 3528.9917
next layer loss target loss 932.20496 other loss 134925.02
result 1 [9.32 4.46 1.32] neuron 386.18036 2.5347576
e 690 loss -34.26168 target loss 393.50906 other loss -46550.047 tv loss 3527.9268
next layer loss target loss 933.3633 other loss 135014.4
result 1 [9.33 4.47 1.32] neuron 386.71378 2.534444
e 700 loss -34.277946 target loss 395.53656 other loss -46597.336 tv loss 3526.9087
next layer loss target loss 934.47095 other loss 135101.28
result 1 [9.34 4.47 1.31] neuron 387.2054 2.5341158
e 710 loss -34.293648 target loss 397.4951 other loss -46642.367 tv loss 3525.898
next layer loss target loss 935.52454 other loss 135185.81
result 1 [9.35 4.47 1.31] neuron 387.65543 2.5337813
e 720 loss -34.308784 target loss 399.37762 other loss -46685.094 tv loss 3524.9175
next layer loss target loss 936.51666 other loss 135267.5
result 1 [9.35 4.48 1.31] neuron 388.06747 2.533459
e 730 loss -34.323368 target loss 401.1856 other loss -46725.516 tv loss 3523.9844
next layer loss target loss 937.45306 other loss 135346.11
result 1 [9.36 4.48 1.31] neuron 388.44244 2.5331528
e 740 loss -34.337555 target loss 402.932 other loss -46763.92 tv loss 3523.0889
next layer loss target loss 938.3438 other loss 135422.4
result 1 [9.37 4.49 1.31] neuron 388.78787 2.532871
e 750 loss -34.351532 target loss 404.6299 other loss -46800.477 tv loss 3522.2231
next layer loss target loss 939.1968 other loss 135497.16
result 1 [9.37 4.49 1.31] neuron 389.10846 2.5326042
e 760 loss -34.365223 target loss 406.2763 other loss -46835.43 tv loss 3521.4072
next layer loss target loss 940.0139 other loss 135570.17
result 1 [9.38 4.49 1.3 ] neuron 389.40247 2.5323555
e 770 loss -34.378708 target loss 407.88245 other loss -46868.91 tv loss 3520.6555
next layer loss target loss 940.79956 other loss 135641.6
result 1 [9.38 4.49 1.3 ] neuron 389.6713 2.5321364
e 780 loss -34.39211 target loss 409.464 other loss -46901.023 tv loss 3519.9402
next layer loss target loss 941.563 other loss 135712.08
result 1 [9.39 4.5  1.3 ] neuron 389.92218 2.531937
e 790 loss -34.40548 target loss 411.0252 other loss -46931.863 tv loss 3519.2578
next layer loss target loss 942.30786 other loss 135781.88
result 1 [9.39 4.5  1.3 ] neuron 390.15546 2.5317543
e 800 loss -34.41879 target loss 412.56702 other loss -46961.61 tv loss 3518.6038
next layer loss target loss 943.035 other loss 135851.08
result 1 [9.4 4.5 1.3] neuron 390.37366 2.5315914
e 810 loss -34.432007 target loss 414.09235 other loss -46990.36 tv loss 3517.9866
next layer loss target loss 943.7443 other loss 135919.7
result 1 [9.4 4.5 1.3] neuron 390.57782 2.531451
e 820 loss -34.445236 target loss 415.6058 other loss -47018.188 tv loss 3517.3828
next layer loss target loss 944.44495 other loss 135987.8
result 1 [9.4 4.5 1.3] neuron 390.77197 2.53132
e 830 loss -34.458366 target loss 417.10776 other loss -47045.3 tv loss 3516.801
next layer loss target loss 945.1308 other loss 136055.27
result 1 [9.41 4.51 1.29] neuron 390.95416 2.5312102
e 840 loss -34.471527 target loss 418.60687 other loss -47071.84 tv loss 3516.2495
next layer loss target loss 945.8108 other loss 136122.56
result 1 [9.41 4.51 1.29] neuron 391.1288 2.5311155
e 850 loss -34.48474 target loss 420.10287 other loss -47097.766 tv loss 3515.7173
next layer loss target loss 946.48224 other loss 136189.6
result 1 [9.42 4.51 1.29] neuron 391.2973 2.5310283
e 860 loss -34.497963 target loss 421.59485 other loss -47123.055 tv loss 3515.207
next layer loss target loss 947.1445 other loss 136256.56
result 1 [9.42 4.51 1.29] neuron 391.45856 2.5309622
e 870 loss -34.511276 target loss 423.09186 other loss -47147.93 tv loss 3514.7158
next layer loss target loss 947.80505 other loss 136323.66
result 1 [9.42 4.51 1.29] neuron 391.61444 2.5309105
e 880 loss -34.52466 target loss 424.5949 other loss -47172.45 tv loss 3514.242
next layer loss target loss 948.46265 other loss 136390.73
result 1 [9.43 4.52 1.29] neuron 391.7644 2.53087
e 890 loss -34.538094 target loss 426.09653 other loss -47196.523 tv loss 3513.7886
next layer loss target loss 949.11664 other loss 136457.53
result 1 [9.43 4.52 1.29] neuron 391.90652 2.5308394
e 900 loss -34.551666 target loss 427.60748 other loss -47220.375 tv loss 3513.3467
next layer loss target loss 949.77057 other loss 136524.56
result 1 [9.43 4.52 1.29] neuron 392.0448 2.5308223
e 910 loss -34.565323 target loss 429.12878 other loss -47244.03 tv loss 3512.9126
next layer loss target loss 950.424 other loss 136591.92
result 1 [9.44 4.52 1.29] neuron 392.17914 2.5308087
e 920 loss -34.579082 target loss 430.65836 other loss -47267.46 tv loss 3512.4905
next layer loss target loss 951.07825 other loss 136659.48
result 1 [9.44 4.53 1.29] neuron 392.3097 2.5308042
e 930 loss -34.593002 target loss 432.20218 other loss -47290.742 tv loss 3512.0642
next layer loss target loss 951.73804 other loss 136727.47
result 1 [9.44 4.53 1.29] neuron 392.4381 2.530808
e 940 loss -34.607082 target loss 433.76144 other loss -47313.832 tv loss 3511.6406
next layer loss target loss 952.4074 other loss 136796.0
result 1 [9.45 4.53 1.29] neuron 392.56546 2.5308301
e 950 loss -34.621284 target loss 435.3328 other loss -47336.66 tv loss 3511.2266
next layer loss target loss 953.08026 other loss 136864.98
result 1 [9.45 4.54 1.29] neuron 392.69104 2.5308642
e 960 loss -34.635735 target loss 436.927 other loss -47359.53 tv loss 3510.813
next layer loss target loss 953.7665 other loss 136934.69
result 1 [9.45 4.54 1.29] neuron 392.81647 2.5309048
e 970 loss -34.650394 target loss 438.54175 other loss -47382.555 tv loss 3510.413
next layer loss target loss 954.4645 other loss 137005.28
result 1 [9.46 4.54 1.29] neuron 392.9399 2.5309467
e 980 loss -34.66503 target loss 440.15674 other loss -47405.516 tv loss 3510.0203
next layer loss target loss 955.16327 other loss 137076.03
result 1 [9.46 4.55 1.3 ] neuron 393.05862 2.531009
e 990 loss -34.679813 target loss 441.78546 other loss -47428.277 tv loss 3509.6294
next layer loss target loss 955.8681 other loss 137147.12
result 1 [9.47 4.55 1.3 ] neuron 393.17657 2.5310895
RE filter conv2d_2 132 RE acc 0.3333333333333333
e 0 loss -24.21112 target loss -591.3963 other loss -97920.84 tv loss 3976.1335
next layer loss target loss 11.707861 other loss 17872.146
result 0 [0.82 1.03 7.83] neuron -179.05264 0.79556704
e 10 loss -24.340948 target loss -569.4118 other loss -93095.59 tv loss 3796.7622
next layer loss target loss 10.725937 other loss 17391.738
result 0 [0.76 1.02 7.79] neuron -173.97998 0.7450207
e 20 loss -24.397411 target loss -556.01294 other loss -90875.63 tv loss 3700.6855
next layer loss target loss 10.027645 other loss 17108.285
result 0 [0.76 1.12 7.72] neuron -170.56627 0.7236379
e 30 loss -24.413864 target loss -549.826 other loss -90040.37 tv loss 3652.9336
next layer loss target loss 9.671338 other loss 16976.992
result 0 [0.74 1.19 7.72] neuron -168.8515 0.71400326
e 40 loss -24.420113 target loss -548.7108 other loss -90007.08 tv loss 3643.727
next layer loss target loss 9.595362 other loss 16952.227
result 0 [0.72 1.21 7.72] neuron -168.46504 0.7131244
e 50 loss -24.427118 target loss -549.3757 other loss -90192.06 tv loss 3652.397
next layer loss target loss 9.671852 other loss 16985.754
result 0 [0.72 1.21 7.72] neuron -168.58524 0.71509916
e 60 loss -24.432642 target loss -549.19965 other loss -90079.95 tv loss 3653.5354
next layer loss target loss 9.7218685 other loss 16984.11
result 0 [0.72 1.19 7.7 ] neuron -168.68564 0.7159838
e 70 loss -24.436798 target loss -548.8137 other loss -89990.97 tv loss 3651.5264
next layer loss target loss 9.7074375 other loss 16973.277
result 0 [0.73 1.18 7.69] neuron -168.80014 0.7160764
e 80 loss -24.440166 target loss -548.457 other loss -89944.05 tv loss 3650.156
next layer loss target loss 9.704269 other loss 16971.09
result 0 [0.73 1.17 7.69] neuron -168.76257 0.71599835
e 90 loss -24.442995 target loss -547.84424 other loss -89860.06 tv loss 3647.6948
next layer loss target loss 9.696402 other loss 16964.102
result 0 [0.73 1.17 7.69] neuron -168.578 0.71531355
e 100 loss -24.445343 target loss -547.0365 other loss -89722.16 tv loss 3642.3394
next layer loss target loss 9.671303 other loss 16949.135
result 0 [0.72 1.18 7.68] neuron -168.40884 0.71412367
e 110 loss -24.447285 target loss -546.5254 other loss -89648.4 tv loss 3640.1365
next layer loss target loss 9.659633 other loss 16942.918
result 0 [0.73 1.17 7.68] neuron -168.31833 0.71392184
e 120 loss -24.448887 target loss -546.1632 other loss -89592.86 tv loss 3638.4248
next layer loss target loss 9.656224 other loss 16937.688
result 0 [0.73 1.17 7.68] neuron -168.25916 0.7138869
e 130 loss -24.450209 target loss -545.865 other loss -89554.19 tv loss 3637.2222
next layer loss target loss 9.661152 other loss 16934.078
result 0 [0.72 1.17 7.67] neuron -168.1986 0.7142393
e 140 loss -24.451355 target loss -545.54944 other loss -89508.81 tv loss 3635.563
next layer loss target loss 9.658658 other loss 16929.297
result 0 [0.72 1.17 7.67] neuron -168.14525 0.71427524
e 150 loss -24.45231 target loss -545.23804 other loss -89465.75 tv loss 3634.277
next layer loss target loss 9.65617 other loss 16926.379
result 0 [0.72 1.17 7.67] neuron -168.09314 0.71434385
e 160 loss -24.453117 target loss -544.939 other loss -89421.75 tv loss 3632.7322
next layer loss target loss 9.652983 other loss 16922.348
result 0 [0.72 1.17 7.67] neuron -168.045 0.7143969
e 170 loss -24.453804 target loss -544.6713 other loss -89381.305 tv loss 3631.4612
next layer loss target loss 9.65104 other loss 16919.639
result 0 [0.72 1.17 7.67] neuron -167.9974 0.7143901
e 180 loss -24.454374 target loss -544.46606 other loss -89355.03 tv loss 3630.517
next layer loss target loss 9.655323 other loss 16918.312
result 0 [0.72 1.17 7.67] neuron -167.95135 0.7145451
e 190 loss -24.454872 target loss -544.25366 other loss -89324.03 tv loss 3629.44
next layer loss target loss 9.648298 other loss 16915.828
result 0 [0.72 1.17 7.67] neuron -167.90831 0.71425503
e 200 loss -24.455303 target loss -544.0748 other loss -89304.36 tv loss 3628.5347
next layer loss target loss 9.653991 other loss 16914.633
result 0 [0.72 1.17 7.67] neuron -167.87613 0.7148612
e 210 loss -24.455734 target loss -543.8854 other loss -89279.13 tv loss 3627.764
next layer loss target loss 9.641985 other loss 16910.98
result 0 [0.72 1.17 7.67] neuron -167.84909 0.7145167
e 220 loss -24.45607 target loss -543.7898 other loss -89276.586 tv loss 3627.71
next layer loss target loss 9.641498 other loss 16911.652
result 0 [0.72 1.17 7.67] neuron -167.84164 0.7147588
e 230 loss -24.456387 target loss -543.64453 other loss -89256.14 tv loss 3627.1152
next layer loss target loss 9.646114 other loss 16910.568
result 0 [0.72 1.17 7.67] neuron -167.80502 0.7151273
e 240 loss -24.456636 target loss -543.4878 other loss -89243.266 tv loss 3626.2883
next layer loss target loss 9.641481 other loss 16908.736
result 0 [0.72 1.17 7.67] neuron -167.76779 0.715242
e 250 loss -24.456871 target loss -543.36926 other loss -89223.57 tv loss 3625.619
next layer loss target loss 9.641412 other loss 16906.994
result 0 [0.72 1.17 7.67] neuron -167.73676 0.7152128
e 260 loss -24.457085 target loss -543.3541 other loss -89230.086 tv loss 3625.8203
next layer loss target loss 9.647221 other loss 16908.47
result 0 [0.72 1.17 7.67] neuron -167.72873 0.7155941
e 270 loss -24.45728 target loss -543.285 other loss -89219.555 tv loss 3625.4727
next layer loss target loss 9.650221 other loss 16907.742
result 0 [0.72 1.17 7.67] neuron -167.70938 0.71572024
e 280 loss -24.457457 target loss -543.21484 other loss -89214.06 tv loss 3625.288
next layer loss target loss 9.650108 other loss 16907.781
result 0 [0.72 1.17 7.67] neuron -167.68768 0.7157816
e 290 loss -24.457624 target loss -543.1328 other loss -89202.58 tv loss 3624.8481
next layer loss target loss 9.649851 other loss 16906.662
result 0 [0.72 1.17 7.67] neuron -167.66298 0.71584755
e 300 loss -24.457771 target loss -543.047 other loss -89190.51 tv loss 3624.3616
next layer loss target loss 9.650979 other loss 16905.562
result 0 [0.72 1.17 7.67] neuron -167.63504 0.71590436
e 310 loss -24.457909 target loss -542.99225 other loss -89183.39 tv loss 3624.1245
next layer loss target loss 9.651783 other loss 16905.404
result 0 [0.71 1.17 7.68] neuron -167.61783 0.71588093
e 320 loss -24.458046 target loss -542.95496 other loss -89180.03 tv loss 3624.0024
next layer loss target loss 9.650885 other loss 16905.162
result 0 [0.71 1.17 7.68] neuron -167.61026 0.7158725
e 330 loss -24.458157 target loss -542.91797 other loss -89174.53 tv loss 3623.8567
next layer loss target loss 9.649405 other loss 16904.684
result 0 [0.71 1.17 7.68] neuron -167.60211 0.7158276
e 340 loss -24.458271 target loss -542.8627 other loss -89164.68 tv loss 3623.541
next layer loss target loss 9.646372 other loss 16903.26
result 0 [0.71 1.17 7.68] neuron -167.58928 0.71576124
e 350 loss -24.45838 target loss -542.8596 other loss -89168.34 tv loss 3623.6143
next layer loss target loss 9.652805 other loss 16904.576
result 0 [0.71 1.17 7.68] neuron -167.58234 0.71611094
e 360 loss -24.458485 target loss -542.85315 other loss -89171.266 tv loss 3623.694
next layer loss target loss 9.650465 other loss 16904.424
result 0 [0.71 1.17 7.68] neuron -167.58026 0.71612537
e 370 loss -24.458578 target loss -542.828 other loss -89166.36 tv loss 3623.587
next layer loss target loss 9.65123 other loss 16904.09
result 0 [0.71 1.17 7.68] neuron -167.56973 0.7161994
e 380 loss -24.458675 target loss -542.8291 other loss -89170.84 tv loss 3623.7075
next layer loss target loss 9.650894 other loss 16904.754
result 0 [0.71 1.17 7.68] neuron -167.56693 0.71625966
e 390 loss -24.458763 target loss -542.79034 other loss -89164.86 tv loss 3623.467
next layer loss target loss 9.648155 other loss 16903.832
result 0 [0.71 1.17 7.69] neuron -167.5581 0.7162563
e 400 loss -24.458858 target loss -542.7785 other loss -89162.43 tv loss 3623.437
next layer loss target loss 9.649599 other loss 16904.021
result 0 [0.71 1.17 7.69] neuron -167.55182 0.7162958
e 410 loss -24.458939 target loss -542.76514 other loss -89163.05 tv loss 3623.3982
next layer loss target loss 9.650815 other loss 16904.332
result 0 [0.71 1.17 7.69] neuron -167.54778 0.7164498
e 420 loss -24.45902 target loss -542.7278 other loss -89156.94 tv loss 3623.2485
next layer loss target loss 9.65093 other loss 16904.115
result 0 [0.71 1.17 7.69] neuron -167.53363 0.7163784
e 430 loss -24.459093 target loss -542.73505 other loss -89159.5 tv loss 3623.3235
next layer loss target loss 9.648768 other loss 16904.154
result 0 [0.71 1.17 7.69] neuron -167.53476 0.7163701
e 440 loss -24.459164 target loss -542.7379 other loss -89162.81 tv loss 3623.52
next layer loss target loss 9.647627 other loss 16904.473
result 0 [0.71 1.17 7.69] neuron -167.53549 0.716387
e 450 loss -24.459244 target loss -542.7392 other loss -89163.875 tv loss 3623.5476
next layer loss target loss 9.65396 other loss 16905.121
result 0 [0.71 1.17 7.69] neuron -167.53503 0.7168649
e 460 loss -24.45932 target loss -542.73645 other loss -89169.41 tv loss 3623.679
next layer loss target loss 9.65074 other loss 16905.236
result 0 [0.71 1.17 7.69] neuron -167.53061 0.71679807
e 470 loss -24.459396 target loss -542.68225 other loss -89160.4 tv loss 3623.3457
next layer loss target loss 9.648188 other loss 16904.07
result 0 [0.71 1.17 7.69] neuron -167.51266 0.7167545
e 480 loss -24.459469 target loss -542.6756 other loss -89164.36 tv loss 3623.3823
next layer loss target loss 9.647625 other loss 16904.213
result 0 [0.71 1.17 7.69] neuron -167.50998 0.71688545
e 490 loss -24.459545 target loss -542.6333 other loss -89158.66 tv loss 3623.1602
next layer loss target loss 9.646128 other loss 16903.584
result 0 [0.71 1.17 7.7 ] neuron -167.50221 0.7168584
e 500 loss -24.459616 target loss -542.6328 other loss -89160.52 tv loss 3623.2417
next layer loss target loss 9.645743 other loss 16903.805
result 0 [0.71 1.17 7.7 ] neuron -167.49837 0.71685755
e 510 loss -24.459694 target loss -542.59644 other loss -89156.664 tv loss 3623.0425
next layer loss target loss 9.646061 other loss 16903.46
result 0 [0.71 1.17 7.7 ] neuron -167.48602 0.7169368
e 520 loss -24.459757 target loss -542.5724 other loss -89155.17 tv loss 3622.9817
next layer loss target loss 9.644872 other loss 16903.656
result 0 [0.71 1.17 7.7 ] neuron -167.47726 0.7169262
e 530 loss -24.459826 target loss -542.55896 other loss -89155.625 tv loss 3622.921
next layer loss target loss 9.642802 other loss 16903.303
result 0 [0.71 1.17 7.7 ] neuron -167.47153 0.7169692
e 540 loss -24.45989 target loss -542.54285 other loss -89154.12 tv loss 3622.9595
next layer loss target loss 9.642981 other loss 16903.182
result 0 [0.71 1.17 7.7 ] neuron -167.46332 0.7169882
e 550 loss -24.45996 target loss -542.57874 other loss -89175.6 tv loss 3623.4524
next layer loss target loss 9.64043 other loss 16904.104
result 0 [0.71 1.17 7.7 ] neuron -167.47672 0.7173014
e 560 loss -24.460018 target loss -542.48755 other loss -89158.28 tv loss 3622.7754
next layer loss target loss 9.638636 other loss 16902.467
result 0 [0.71 1.17 7.7 ] neuron -167.4542 0.7171745
e 570 loss -24.460083 target loss -542.4835 other loss -89158.86 tv loss 3622.768
next layer loss target loss 9.639752 other loss 16902.645
result 0 [0.71 1.17 7.71] neuron -167.44844 0.71724516
e 580 loss -24.460138 target loss -542.4682 other loss -89157.875 tv loss 3622.7427
next layer loss target loss 9.638341 other loss 16902.447
result 0 [0.71 1.17 7.71] neuron -167.44302 0.71723956
e 590 loss -24.460186 target loss -542.4402 other loss -89152.016 tv loss 3622.5745
next layer loss target loss 9.63933 other loss 16902.21
result 0 [0.71 1.17 7.71] neuron -167.43118 0.7172862
e 600 loss -24.46025 target loss -542.43146 other loss -89151.66 tv loss 3622.6
next layer loss target loss 9.636032 other loss 16901.746
result 0 [0.71 1.17 7.71] neuron -167.42639 0.717165
e 610 loss -24.4603 target loss -542.4054 other loss -89148.95 tv loss 3622.4546
next layer loss target loss 9.636951 other loss 16901.535
result 0 [0.71 1.17 7.71] neuron -167.41638 0.7172622
e 620 loss -24.460344 target loss -542.4176 other loss -89156.45 tv loss 3622.6067
next layer loss target loss 9.635135 other loss 16902.29
result 0 [0.71 1.17 7.71] neuron -167.41803 0.717281
e 630 loss -24.460405 target loss -542.389 other loss -89149.77 tv loss 3622.4802
next layer loss target loss 9.633112 other loss 16901.775
result 0 [0.71 1.17 7.71] neuron -167.40927 0.7171866
e 640 loss -24.460445 target loss -542.38794 other loss -89151.34 tv loss 3622.4602
next layer loss target loss 9.633404 other loss 16901.838
result 0 [0.71 1.17 7.71] neuron -167.40651 0.71727264
e 650 loss -24.460491 target loss -542.4081 other loss -89160.47 tv loss 3622.7039
next layer loss target loss 9.63196 other loss 16902.512
result 0 [0.71 1.17 7.71] neuron -167.41158 0.7173943
e 660 loss -24.46054 target loss -542.39355 other loss -89158.945 tv loss 3622.6475
next layer loss target loss 9.631136 other loss 16902.393
result 0 [0.71 1.17 7.71] neuron -167.40767 0.7174427
e 670 loss -24.46059 target loss -542.3911 other loss -89160.47 tv loss 3622.6587
next layer loss target loss 9.628183 other loss 16901.926
result 0 [0.71 1.17 7.71] neuron -167.4072 0.7174225
e 680 loss -24.460634 target loss -542.39276 other loss -89162.02 tv loss 3622.7432
next layer loss target loss 9.62968 other loss 16902.27
result 0 [0.71 1.17 7.71] neuron -167.40364 0.7175897
e 690 loss -24.460672 target loss -542.36694 other loss -89157.23 tv loss 3622.588
next layer loss target loss 9.627998 other loss 16901.797
result 0 [0.71 1.17 7.72] neuron -167.3968 0.71754825
e 700 loss -24.460716 target loss -542.35956 other loss -89155.39 tv loss 3622.5967
next layer loss target loss 9.624949 other loss 16901.469
result 0 [0.71 1.17 7.72] neuron -167.39401 0.71744895
e 710 loss -24.460762 target loss -542.3612 other loss -89158.22 tv loss 3622.6382
next layer loss target loss 9.625683 other loss 16901.768
result 0 [0.71 1.17 7.72] neuron -167.39175 0.7175709
e 720 loss -24.460794 target loss -542.3536 other loss -89155.484 tv loss 3622.6086
next layer loss target loss 9.627443 other loss 16901.773
result 0 [0.71 1.17 7.72] neuron -167.38422 0.7176709
e 730 loss -24.460835 target loss -542.3573 other loss -89159.25 tv loss 3622.7173
next layer loss target loss 9.62397 other loss 16901.848
result 0 [0.71 1.17 7.72] neuron -167.38518 0.7176034
e 740 loss -24.46088 target loss -542.3174 other loss -89149.97 tv loss 3622.421
next layer loss target loss 9.624797 other loss 16901.273
result 0 [0.71 1.17 7.72] neuron -167.37479 0.7176759
e 750 loss -24.460918 target loss -542.34204 other loss -89156.69 tv loss 3622.6792
next layer loss target loss 9.623421 other loss 16901.71
result 0 [0.71 1.17 7.72] neuron -167.37996 0.717684
e 760 loss -24.460947 target loss -542.3285 other loss -89154.766 tv loss 3622.6216
next layer loss target loss 9.625473 other loss 16901.844
result 0 [0.71 1.17 7.72] neuron -167.37292 0.7178274
e 770 loss -24.460985 target loss -542.3023 other loss -89151.83 tv loss 3622.4668
next layer loss target loss 9.6224575 other loss 16901.64
result 0 [0.71 1.17 7.72] neuron -167.36783 0.7177249
e 780 loss -24.461021 target loss -542.30023 other loss -89149.43 tv loss 3622.4734
next layer loss target loss 9.620089 other loss 16901.162
result 0 [0.71 1.17 7.72] neuron -167.36449 0.7176221
e 790 loss -24.461056 target loss -542.2798 other loss -89147.625 tv loss 3622.3723
next layer loss target loss 9.618087 other loss 16900.748
result 0 [0.71 1.17 7.72] neuron -167.36156 0.71762896
e 800 loss -24.461086 target loss -542.2809 other loss -89147.42 tv loss 3622.3667
next layer loss target loss 9.618333 other loss 16900.654
result 0 [0.71 1.17 7.72] neuron -167.36066 0.71765405
e 810 loss -24.46112 target loss -542.26044 other loss -89142.08 tv loss 3622.2507
next layer loss target loss 9.619347 other loss 16900.771
result 0 [0.71 1.17 7.72] neuron -167.35234 0.7176723
e 820 loss -24.46115 target loss -542.2689 other loss -89146.33 tv loss 3622.3428
next layer loss target loss 9.618326 other loss 16901.133
result 0 [0.71 1.17 7.72] neuron -167.35529 0.71777505
e 830 loss -24.461185 target loss -542.2656 other loss -89148.59 tv loss 3622.354
next layer loss target loss 9.619174 other loss 16901.29
result 0 [0.71 1.17 7.72] neuron -167.354 0.7179325
e 840 loss -24.461216 target loss -542.2392 other loss -89139.72 tv loss 3622.1836
next layer loss target loss 9.616905 other loss 16900.393
result 0 [0.71 1.17 7.72] neuron -167.3449 0.7178167
e 850 loss -24.46125 target loss -542.2406 other loss -89140.5 tv loss 3622.2837
next layer loss target loss 9.61665 other loss 16900.45
result 0 [0.71 1.17 7.72] neuron -167.34189 0.717782
e 860 loss -24.461226 target loss -542.2237 other loss -89140.5 tv loss 3622.277
next layer loss target loss 9.604847 other loss 16900.316
result 0 [0.71 1.17 7.72] neuron -167.34341 0.7172439
e 870 loss -24.461222 target loss -542.1433 other loss -89121.48 tv loss 3621.5386
next layer loss target loss 9.593955 other loss 16897.262
result 0 [0.71 1.17 7.72] neuron -167.32297 0.7168079
e 880 loss -24.461317 target loss -542.146 other loss -89130.94 tv loss 3621.5544
next layer loss target loss 9.610357 other loss 16898.27
result 0 [0.71 1.17 7.72] neuron -167.307 0.7177805
e 890 loss -24.461308 target loss -542.34186 other loss -89193.266 tv loss 3623.665
next layer loss target loss 9.611129 other loss 16906.523
result 0 [0.71 1.17 7.73] neuron -167.35175 0.7179487
e 900 loss -24.461353 target loss -542.0653 other loss -89133.31 tv loss 3621.1921
next layer loss target loss 9.60748 other loss 16899.518
result 0 [0.71 1.17 7.72] neuron -167.26698 0.7179298
e 910 loss -24.461403 target loss -542.2379 other loss -89174.484 tv loss 3622.4878
next layer loss target loss 9.60553 other loss 16901.996
result 0 [0.71 1.17 7.73] neuron -167.31088 0.71807224
e 920 loss -24.461435 target loss -542.1766 other loss -89150.54 tv loss 3622.1375
next layer loss target loss 9.6057625 other loss 16900.814
result 0 [0.71 1.17 7.73] neuron -167.29874 0.7177807
e 930 loss -24.461468 target loss -542.1521 other loss -89129.17 tv loss 3621.8438
next layer loss target loss 9.607619 other loss 16898.738
result 0 [0.71 1.17 7.72] neuron -167.30316 0.71772856
e 940 loss -24.461441 target loss -542.21484 other loss -89145.54 tv loss 3622.4482
next layer loss target loss 9.597285 other loss 16899.96
result 0 [0.71 1.17 7.73] neuron -167.31769 0.717179
e 950 loss -24.461489 target loss -542.1188 other loss -89154.4 tv loss 3622.199
next layer loss target loss 9.595154 other loss 16901.0
result 0 [0.71 1.17 7.73] neuron -167.26288 0.7173595
e 960 loss -24.461536 target loss -542.25476 other loss -89181.305 tv loss 3623.1904
next layer loss target loss 9.603954 other loss 16905.115
result 0 [0.71 1.17 7.73] neuron -167.29962 0.717956
e 970 loss -24.461565 target loss -542.1256 other loss -89131.28 tv loss 3621.749
next layer loss target loss 9.599024 other loss 16898.836
result 0 [0.71 1.17 7.72] neuron -167.28937 0.7176965
e 980 loss -24.461563 target loss -542.1935 other loss -89142.84 tv loss 3622.4768
next layer loss target loss 9.5963955 other loss 16900.059
result 0 [0.71 1.17 7.73] neuron -167.30945 0.7173441
e 990 loss -24.461594 target loss -542.1159 other loss -89158.33 tv loss 3622.246
next layer loss target loss 9.595159 other loss 16901.83
result 0 [0.71 1.17 7.73] neuron -167.26138 0.7175197
RE filter conv2d_4 173 RE acc 0.0
e 0 loss -20.988865 target loss -917.0657 other loss -97595.18 tv loss 3976.1335
next layer loss target loss 15.154787 other loss 17868.7
result 0 [0.82 1.03 7.83] neuron -322.7529 1.6078033
e 10 loss -21.50447 target loss -847.3327 other loss -92707.016 tv loss 3849.2827
next layer loss target loss 17.129562 other loss 17621.105
result 0 [0.77 0.75 7.45] neuron -296.34872 1.624185
e 20 loss -21.73388 target loss -807.2008 other loss -89570.305 tv loss 3739.488
next layer loss target loss 17.650444 other loss 17302.758
result 0 [0.68 0.63 7.06] neuron -280.99335 1.5927114
e 30 loss -21.829529 target loss -784.6371 other loss -87703.875 tv loss 3656.5938
next layer loss target loss 17.793839 other loss 17086.275
result 0 [0.59 0.6  6.82] neuron -272.69 1.5545907
e 40 loss -21.8713 target loss -771.8771 other loss -86754.67 tv loss 3605.239
next layer loss target loss 17.825203 other loss 16987.213
result 0 [0.52 0.6  6.71] neuron -267.6908 1.5349139
e 50 loss -21.88286 target loss -766.35223 other loss -86259.41 tv loss 3576.7244
next layer loss target loss 17.87138 other loss 16945.406
result 0 [0.5  0.61 6.69] neuron -265.59094 1.5246603
e 60 loss -21.887321 target loss -762.5393 other loss -85971.9 tv loss 3564.0432
next layer loss target loss 17.948862 other loss 16922.602
result 0 [0.5  0.61 6.68] neuron -264.06024 1.5216863
e 70 loss -21.891916 target loss -761.1147 other loss -85916.31 tv loss 3563.0056
next layer loss target loss 17.958652 other loss 16914.875
result 0 [0.51 0.61 6.67] neuron -263.48868 1.521871
e 80 loss -21.895702 target loss -761.8137 other loss -85969.016 tv loss 3567.292
next layer loss target loss 17.965641 other loss 16924.945
result 0 [0.52 0.61 6.68] neuron -263.7236 1.5251055
e 90 loss -21.898811 target loss -762.86914 other loss -86019.28 tv loss 3571.564
next layer loss target loss 17.97308 other loss 16936.465
result 0 [0.53 0.62 6.69] neuron -264.08414 1.5286009
e 100 loss -21.901487 target loss -762.8951 other loss -86010.61 tv loss 3572.7417
next layer loss target loss 17.970858 other loss 16935.834
result 0 [0.53 0.62 6.69] neuron -264.08984 1.5296745
e 110 loss -21.90393 target loss -762.6213 other loss -85987.67 tv loss 3572.8357
next layer loss target loss 17.966667 other loss 16930.445
result 0 [0.53 0.62 6.69] neuron -264.0192 1.5296067
e 120 loss -21.90608 target loss -762.3608 other loss -85965.95 tv loss 3573.017
next layer loss target loss 17.986298 other loss 16928.734
result 0 [0.53 0.62 6.68] neuron -263.9317 1.5296843
e 130 loss -21.908043 target loss -762.16815 other loss -85953.08 tv loss 3573.3008
next layer loss target loss 17.99785 other loss 16927.13
result 0 [0.53 0.62 6.67] neuron -263.87543 1.5296654
e 140 loss -21.909779 target loss -762.04395 other loss -85950.34 tv loss 3574.0493
next layer loss target loss 18.011787 other loss 16927.723
result 0 [0.53 0.62 6.67] neuron -263.82452 1.5300753
e 150 loss -21.91135 target loss -761.79535 other loss -85933.04 tv loss 3574.4045
next layer loss target loss 18.032646 other loss 16927.14
result 0 [0.54 0.62 6.66] neuron -263.7358 1.5304403
e 160 loss -21.91273 target loss -761.6042 other loss -85921.41 tv loss 3574.7712
next layer loss target loss 18.052517 other loss 16926.922
result 0 [0.54 0.62 6.66] neuron -263.66937 1.5306665
e 170 loss -21.913944 target loss -761.4375 other loss -85908.76 tv loss 3574.9805
next layer loss target loss 18.066528 other loss 16926.887
result 0 [0.54 0.62 6.65] neuron -263.60977 1.5308546
e 180 loss -21.915037 target loss -761.22534 other loss -85879.53 tv loss 3574.729
next layer loss target loss 18.070284 other loss 16923.75
result 0 [0.54 0.62 6.65] neuron -263.55154 1.5309194
e 190 loss -21.916039 target loss -760.9414 other loss -85859.69 tv loss 3574.5972
next layer loss target loss 18.082596 other loss 16922.137
result 0 [0.54 0.62 6.64] neuron -263.44943 1.5308716
e 200 loss -21.916952 target loss -760.66345 other loss -85843.625 tv loss 3574.6416
next layer loss target loss 18.101326 other loss 16921.082
result 0 [0.54 0.62 6.63] neuron -263.347 1.5308851
e 210 loss -21.9178 target loss -760.4199 other loss -85833.336 tv loss 3574.7485
next layer loss target loss 18.120468 other loss 16921.082
result 0 [0.54 0.62 6.63] neuron -263.25427 1.530855
e 220 loss -21.918556 target loss -760.15894 other loss -85823.125 tv loss 3574.8506
next layer loss target loss 18.138348 other loss 16920.938
result 0 [0.54 0.62 6.62] neuron -263.15125 1.530844
e 230 loss -21.919231 target loss -759.82043 other loss -85814.06 tv loss 3574.7476
next layer loss target loss 18.16066 other loss 16921.031
result 0 [0.54 0.62 6.62] neuron -263.0105 1.5307866
e 240 loss -21.91985 target loss -759.7671 other loss -85808.75 tv loss 3574.9934
next layer loss target loss 18.167517 other loss 16921.95
result 0 [0.54 0.62 6.62] neuron -262.97507 1.5311841
e 250 loss -21.920412 target loss -759.6627 other loss -85801.83 tv loss 3575.197
next layer loss target loss 18.175177 other loss 16921.78
result 0 [0.54 0.62 6.61] neuron -262.93085 1.5313624
e 260 loss -21.920938 target loss -759.53174 other loss -85792.516 tv loss 3575.2646
next layer loss target loss 18.182297 other loss 16921.05
result 0 [0.54 0.62 6.61] neuron -262.8722 1.5314386
e 270 loss -21.921432 target loss -759.29553 other loss -85781.266 tv loss 3575.2397
next layer loss target loss 18.186506 other loss 16919.074
result 0 [0.54 0.62 6.6 ] neuron -262.7825 1.5311437
e 280 loss -21.921879 target loss -759.2007 other loss -85773.125 tv loss 3575.247
next layer loss target loss 18.19471 other loss 16918.482
result 0 [0.54 0.62 6.6 ] neuron -262.7431 1.5311279
e 290 loss -21.922314 target loss -759.1173 other loss -85768.07 tv loss 3575.4866
next layer loss target loss 18.200264 other loss 16918.254
result 0 [0.54 0.62 6.6 ] neuron -262.70422 1.5312009
e 300 loss -21.92273 target loss -758.89624 other loss -85760.42 tv loss 3575.6128
next layer loss target loss 18.21791 other loss 16919.195
result 0 [0.54 0.62 6.59] neuron -262.60406 1.5313731
e 310 loss -21.923111 target loss -758.877 other loss -85760.88 tv loss 3575.9048
next layer loss target loss 18.221874 other loss 16919.293
result 0 [0.54 0.62 6.59] neuron -262.58563 1.5315056
e 320 loss -21.923447 target loss -758.72644 other loss -85755.33 tv loss 3575.918
next layer loss target loss 18.235651 other loss 16919.826
result 0 [0.54 0.62 6.59] neuron -262.51352 1.531647
e 330 loss -21.923775 target loss -758.6256 other loss -85744.79 tv loss 3575.8853
next layer loss target loss 18.238266 other loss 16918.943
result 0 [0.54 0.62 6.59] neuron -262.47604 1.5316561
e 340 loss -21.924068 target loss -758.50183 other loss -85738.16 tv loss 3575.791
next layer loss target loss 18.241333 other loss 16917.809
result 0 [0.54 0.62 6.58] neuron -262.42804 1.5315163
e 350 loss -21.924356 target loss -758.3553 other loss -85733.62 tv loss 3575.8262
next layer loss target loss 18.258718 other loss 16918.719
result 0 [0.54 0.62 6.58] neuron -262.36176 1.5316191
e 360 loss -21.92464 target loss -758.3152 other loss -85738.81 tv loss 3576.134
next layer loss target loss 18.271252 other loss 16919.953
result 0 [0.54 0.62 6.58] neuron -262.33627 1.5318096
e 370 loss -21.924883 target loss -758.349 other loss -85747.13 tv loss 3576.6729
next layer loss target loss 18.279491 other loss 16921.74
result 0 [0.54 0.62 6.58] neuron -262.3387 1.5320934
e 380 loss -21.925133 target loss -758.30566 other loss -85740.94 tv loss 3576.6907
next layer loss target loss 18.281761 other loss 16921.15
result 0 [0.54 0.62 6.58] neuron -262.3266 1.5322092
e 390 loss -21.92536 target loss -758.2168 other loss -85729.99 tv loss 3576.488
next layer loss target loss 18.28569 other loss 16920.316
result 0 [0.54 0.62 6.58] neuron -262.29517 1.5322038
e 400 loss -21.925564 target loss -758.1029 other loss -85721.67 tv loss 3576.2886
next layer loss target loss 18.290073 other loss 16919.635
result 0 [0.54 0.62 6.58] neuron -262.24768 1.5321158
e 410 loss -21.925774 target loss -758.0774 other loss -85716.86 tv loss 3576.2178
next layer loss target loss 18.290775 other loss 16918.898
result 0 [0.54 0.62 6.58] neuron -262.23712 1.5321939
e 420 loss -21.925964 target loss -757.9635 other loss -85720.19 tv loss 3576.4521
next layer loss target loss 18.30357 other loss 16919.58
result 0 [0.54 0.62 6.58] neuron -262.1848 1.532317
e 430 loss -21.926155 target loss -757.92957 other loss -85720.94 tv loss 3576.607
next layer loss target loss 18.3092 other loss 16919.594
result 0 [0.54 0.62 6.58] neuron -262.1684 1.5324268
e 440 loss -21.926338 target loss -757.735 other loss -85705.78 tv loss 3576.231
next layer loss target loss 18.317928 other loss 16918.086
result 0 [0.54 0.62 6.58] neuron -262.1013 1.5323466
e 450 loss -21.926521 target loss -757.5084 other loss -85718.08 tv loss 3576.5352
next layer loss target loss 18.34475 other loss 16919.777
result 0 [0.54 0.62 6.58] neuron -261.998 1.5323719
e 460 loss -21.926693 target loss -757.4971 other loss -85719.055 tv loss 3576.5625
next layer loss target loss 18.341583 other loss 16918.781
result 0 [0.54 0.62 6.58] neuron -261.9904 1.532555
e 470 loss -21.926853 target loss -757.45996 other loss -85725.19 tv loss 3577.0105
next layer loss target loss 18.356113 other loss 16920.639
result 0 [0.54 0.62 6.58] neuron -261.97394 1.5329565
e 480 loss -21.92701 target loss -757.4728 other loss -85724.984 tv loss 3577.0703
next layer loss target loss 18.355267 other loss 16919.953
result 0 [0.54 0.62 6.58] neuron -261.98407 1.533032
e 490 loss -21.927166 target loss -757.4048 other loss -85721.24 tv loss 3576.9597
next layer loss target loss 18.358944 other loss 16918.988
result 0 [0.54 0.62 6.58] neuron -261.96118 1.5330181
e 500 loss -21.9273 target loss -757.38586 other loss -85723.14 tv loss 3577.087
next layer loss target loss 18.366642 other loss 16919.385
result 0 [0.54 0.62 6.58] neuron -261.95404 1.5331249
e 510 loss -21.927448 target loss -757.4092 other loss -85726.86 tv loss 3577.3071
next layer loss target loss 18.3732 other loss 16919.941
result 0 [0.54 0.62 6.58] neuron -261.96317 1.5333077
e 520 loss -21.927578 target loss -757.47253 other loss -85730.73 tv loss 3577.5732
next layer loss target loss 18.377546 other loss 16920.752
result 0 [0.54 0.62 6.58] neuron -261.9937 1.5335178
e 530 loss -21.927708 target loss -757.5298 other loss -85733.05 tv loss 3577.8535
next layer loss target loss 18.383816 other loss 16922.295
result 0 [0.54 0.62 6.58] neuron -262.01544 1.5338728
e 540 loss -21.92784 target loss -757.5747 other loss -85738.52 tv loss 3578.1768
next layer loss target loss 18.391796 other loss 16923.598
result 0 [0.54 0.62 6.58] neuron -262.03522 1.5341522
e 550 loss -21.927969 target loss -757.55286 other loss -85744.03 tv loss 3578.419
next layer loss target loss 18.401482 other loss 16924.387
result 0 [0.54 0.62 6.58] neuron -262.02475 1.5342915
e 560 loss -21.928085 target loss -757.5552 other loss -85745.08 tv loss 3578.548
next layer loss target loss 18.406502 other loss 16924.705
result 0 [0.54 0.62 6.58] neuron -262.02203 1.5344433
e 570 loss -21.928207 target loss -757.5697 other loss -85741.625 tv loss 3578.5447
next layer loss target loss 18.4048 other loss 16924.125
result 0 [0.54 0.62 6.58] neuron -262.02887 1.5345309
e 580 loss -21.928314 target loss -757.5046 other loss -85739.53 tv loss 3578.5825
next layer loss target loss 18.410488 other loss 16923.664
result 0 [0.54 0.62 6.58] neuron -262.00412 1.5345818
e 590 loss -21.92843 target loss -757.4927 other loss -85741.016 tv loss 3578.6367
next layer loss target loss 18.41735 other loss 16924.508
result 0 [0.55 0.62 6.58] neuron -261.99634 1.5347388
e 600 loss -21.928532 target loss -757.4385 other loss -85740.31 tv loss 3578.6367
next layer loss target loss 18.426758 other loss 16925.139
result 0 [0.55 0.62 6.58] neuron -261.9731 1.5348383
e 610 loss -21.92863 target loss -757.41943 other loss -85737.7 tv loss 3578.7007
next layer loss target loss 18.427837 other loss 16924.559
result 0 [0.55 0.62 6.58] neuron -261.9778 1.5348468
e 620 loss -21.928724 target loss -757.4337 other loss -85739.61 tv loss 3578.8699
next layer loss target loss 18.430534 other loss 16924.768
result 0 [0.55 0.62 6.58] neuron -261.98895 1.5349616
e 630 loss -21.928814 target loss -757.3257 other loss -85734.69 tv loss 3578.7622
next layer loss target loss 18.430374 other loss 16923.686
result 0 [0.55 0.62 6.58] neuron -261.94592 1.5349573
e 640 loss -21.928917 target loss -757.3212 other loss -85728.555 tv loss 3578.6226
next layer loss target loss 18.431618 other loss 16923.666
result 0 [0.55 0.62 6.58] neuron -261.9364 1.5352002
e 650 loss -21.929008 target loss -757.3318 other loss -85727.9 tv loss 3578.798
next layer loss target loss 18.434057 other loss 16924.105
result 0 [0.55 0.62 6.58] neuron -261.94733 1.535283
e 660 loss -21.929096 target loss -757.3446 other loss -85729.7 tv loss 3578.974
next layer loss target loss 18.438435 other loss 16924.484
result 0 [0.55 0.62 6.58] neuron -261.94983 1.5354207
e 670 loss -21.929176 target loss -757.2999 other loss -85729.7 tv loss 3579.042
next layer loss target loss 18.446507 other loss 16925.123
result 0 [0.55 0.62 6.58] neuron -261.93005 1.5355419
e 680 loss -21.929241 target loss -757.3136 other loss -85728.91 tv loss 3579.2126
next layer loss target loss 18.443935 other loss 16925.064
result 0 [0.55 0.62 6.59] neuron -261.94934 1.5356061
e 690 loss -21.929325 target loss -757.28156 other loss -85730.664 tv loss 3579.2612
next layer loss target loss 18.45099 other loss 16925.523
result 0 [0.55 0.62 6.59] neuron -261.92767 1.5356587
e 700 loss -21.92938 target loss -757.22064 other loss -85727.45 tv loss 3579.0977
next layer loss target loss 18.461182 other loss 16925.71
result 0 [0.55 0.62 6.59] neuron -261.90015 1.5356886
e 710 loss -21.92945 target loss -757.3281 other loss -85729.164 tv loss 3579.2476
next layer loss target loss 18.445234 other loss 16924.53
result 0 [0.55 0.62 6.59] neuron -261.96857 1.5356278
e 720 loss -21.929506 target loss -757.24023 other loss -85734.73 tv loss 3579.334
next layer loss target loss 18.470629 other loss 16926.809
result 0 [0.55 0.62 6.59] neuron -261.9076 1.5359106
e 730 loss -21.929565 target loss -757.3169 other loss -85742.05 tv loss 3579.604
next layer loss target loss 18.466383 other loss 16926.84
result 0 [0.55 0.62 6.59] neuron -261.94598 1.5358926
e 740 loss -21.929628 target loss -757.30566 other loss -85742.08 tv loss 3579.7178
next layer loss target loss 18.46577 other loss 16926.254
result 0 [0.55 0.62 6.59] neuron -261.9539 1.5359048
e 750 loss -21.929678 target loss -757.29126 other loss -85745.29 tv loss 3579.8164
next layer loss target loss 18.473536 other loss 16927.188
result 0 [0.55 0.62 6.59] neuron -261.94064 1.5360506
e 760 loss -21.929722 target loss -757.24146 other loss -85746.09 tv loss 3579.824
next layer loss target loss 18.481846 other loss 16927.488
result 0 [0.55 0.62 6.59] neuron -261.90964 1.5361189
e 770 loss -21.929781 target loss -757.2634 other loss -85748.836 tv loss 3579.9922
next layer loss target loss 18.480894 other loss 16927.576
result 0 [0.55 0.62 6.59] neuron -261.92096 1.5361372
e 780 loss -21.92984 target loss -757.243 other loss -85747.04 tv loss 3580.143
next layer loss target loss 18.4776 other loss 16926.57
result 0 [0.55 0.62 6.59] neuron -261.91522 1.5361538
e 790 loss -21.929863 target loss -757.2134 other loss -85748.234 tv loss 3580.2007
next layer loss target loss 18.486952 other loss 16927.42
result 0 [0.55 0.62 6.59] neuron -261.89157 1.5362692
e 800 loss -21.929903 target loss -757.23975 other loss -85745.65 tv loss 3580.1626
next layer loss target loss 18.483198 other loss 16926.41
result 0 [0.55 0.62 6.59] neuron -261.91223 1.536234
e 810 loss -21.92996 target loss -757.187 other loss -85741.8 tv loss 3580.1177
next layer loss target loss 18.482712 other loss 16926.148
result 0 [0.55 0.62 6.59] neuron -261.89084 1.536205
e 820 loss -21.929995 target loss -757.2023 other loss -85744.54 tv loss 3580.2656
next layer loss target loss 18.485113 other loss 16926.293
result 0 [0.55 0.62 6.59] neuron -261.89014 1.5363562
e 830 loss -21.930035 target loss -757.1841 other loss -85742.8 tv loss 3580.2817
next layer loss target loss 18.484257 other loss 16925.812
result 0 [0.55 0.62 6.59] neuron -261.8936 1.5362526
e 840 loss -21.930077 target loss -757.14197 other loss -85742.78 tv loss 3580.2944
next layer loss target loss 18.492516 other loss 16926.715
result 0 [0.55 0.62 6.59] neuron -261.86847 1.5363839
e 850 loss -21.930119 target loss -757.1173 other loss -85737.375 tv loss 3580.1318
next layer loss target loss 18.486282 other loss 16924.898
result 0 [0.55 0.62 6.59] neuron -261.8731 1.5362129
e 860 loss -21.930153 target loss -757.07385 other loss -85734.586 tv loss 3580.1228
next layer loss target loss 18.498043 other loss 16925.691
result 0 [0.55 0.62 6.6 ] neuron -261.85736 1.5362483
e 870 loss -21.930182 target loss -757.07227 other loss -85736.09 tv loss 3580.2173
next layer loss target loss 18.499031 other loss 16925.707
result 0 [0.55 0.62 6.6 ] neuron -261.87573 1.5360619
e 880 loss -21.930182 target loss -757.10583 other loss -85739.06 tv loss 3579.959
next layer loss target loss 18.504433 other loss 16924.791
result 0 [0.55 0.62 6.59] neuron -261.87543 1.535999
e 890 loss -21.930246 target loss -757.0525 other loss -85728.61 tv loss 3579.8896
next layer loss target loss 18.494139 other loss 16923.496
result 0 [0.55 0.62 6.6 ] neuron -261.87643 1.5358698
e 900 loss -21.930285 target loss -757.062 other loss -85732.016 tv loss 3579.999
next layer loss target loss 18.500263 other loss 16924.09
result 0 [0.55 0.62 6.6 ] neuron -261.86978 1.536037
e 910 loss -21.930302 target loss -757.0187 other loss -85736.516 tv loss 3580.036
next layer loss target loss 18.507996 other loss 16924.422
result 0 [0.55 0.62 6.6 ] neuron -261.84314 1.5360149
e 920 loss -21.930317 target loss -756.95715 other loss -85727.5 tv loss 3579.9907
next layer loss target loss 18.508137 other loss 16924.742
result 0 [0.55 0.62 6.6 ] neuron -261.83398 1.5360147
e 930 loss -21.930326 target loss -757.03125 other loss -85736.56 tv loss 3579.9849
next layer loss target loss 18.516052 other loss 16924.953
result 0 [0.55 0.62 6.6 ] neuron -261.83856 1.5361451
e 940 loss -21.930376 target loss -756.9491 other loss -85728.66 tv loss 3580.0132
next layer loss target loss 18.508331 other loss 16924.184
result 0 [0.55 0.62 6.6 ] neuron -261.83707 1.5358855
e 950 loss -21.930367 target loss -756.9949 other loss -85737.08 tv loss 3579.9678
next layer loss target loss 18.523344 other loss 16924.771
result 0 [0.55 0.62 6.59] neuron -261.81165 1.5362109
e 960 loss -21.930439 target loss -756.9645 other loss -85726.734 tv loss 3580.0554
next layer loss target loss 18.505226 other loss 16923.066
result 0 [0.55 0.62 6.6 ] neuron -261.84094 1.5359778
e 970 loss -21.930462 target loss -756.9788 other loss -85733.67 tv loss 3580.1284
next layer loss target loss 18.512344 other loss 16923.408
result 0 [0.55 0.62 6.6 ] neuron -261.82648 1.5359994
e 980 loss -21.930498 target loss -756.9447 other loss -85731.59 tv loss 3580.0176
next layer loss target loss 18.517334 other loss 16923.527
result 0 [0.55 0.62 6.6 ] neuron -261.8094 1.5360745
e 990 loss -21.930504 target loss -756.94336 other loss -85728.93 tv loss 3580.0234
next layer loss target loss 18.510895 other loss 16923.295
result 0 [0.55 0.62 6.6 ] neuron -261.82886 1.535921
RE filter conv2d_4 69 RE acc 0.0
-1.9892148 2.126796
./models/nin_trojan_yellow_square_2_3.h5 filter check 0.3
./models/nin_trojan_yellow_square_2_3.h5 both filter and mask check 1.0
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_94_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_94_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_94_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_54_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_54_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_54_64_0']
reasr info [0.6, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_2_97_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_2_97_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_2_97_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_20_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_20_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_20_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_2_74_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_2_74_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_2_74_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_4_37_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_4_37_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_4_37_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_63_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_63_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_63_64_0']
reasr info [0.6, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_40_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_40_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_40_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_62_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_62_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_62_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_64_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_64_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_64_64_0']
reasr info [0.7, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_3_52_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_3_52_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_3_52_64_0']
reasr info [1.0, 'mask', '0', './imgs/nin_trojan_yellow_square_2_3_model_conv2d_2_104_64_0.png', './masks/nin_trojan_yellow_square_2_3_model_conv2d_2_104_64_0', './deltas/nin_trojan_yellow_square_2_3_model_conv2d_2_104_64_0']
reasr info [0.3, 'filter', '0', './imgs/filter_nin_trojan_yellow_square_2_3_model_conv2d_3_40_64_0.png', './deltas/filter_nin_trojan_yellow_square_2_3_model_conv2d_3_40_64_0']
